{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wk12 Demo - Streaming in Spark - Online Learning\n",
    "**MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Summer 2018**\n",
    "\n",
    "Throughout the course we've focused on batch learning. Where we take data in a batch and process it in order to train a model and provide predictions. Online learning instead focuses on streaming data in and training a model as we get more data. There are trade-offs between batch and online model training such as the amount of effort required to maintain state in Spark. Databricks and the general Spark community have spent a large amount of effort to bring Structured Streaming to Spark in a clean API.\n",
    "\n",
    "This class will have less theory and we'll focus on online learning for two algorithms we've covered so far. Naive Bayes and K-means.\n",
    "\n",
    "By the end of today's demo you should be able to:\n",
    "\n",
    "- ... **describe** a situation where you would want to leverage online learning\n",
    "- ... **implement** a simple streaming pipeline.\n",
    "- ... **explain** the complexities that come along with streaming processes\n",
    "\n",
    "**NOTE** None\n",
    "\n",
    "**Additional Resources:** This notebook was based on the following references:\n",
    "\n",
    "- [Real-Time End-to-End Integration with Apache Kafka in Apache Sparkâ€™s Structured Streaming](https://databricks.com/blog/2017/04/04/real-time-end-to-end-integration-with-apache-kafka-in-apache-sparks-structured-streaming.html)\n",
    "- [Introducing Stream-Stream Joins in Apache Spark 2.3](https://databricks.com/blog/2018/03/13/introducing-stream-stream-joins-in-apache-spark-2-3.html)\n",
    "- [Streaming K-means Example](https://github.com/apache/spark/blob/master/examples/src/main/python/mllib/streaming_k_means_example.py)\n",
    "- https://www.kaggle.com/c/avazu-ctr-prediction/data\n",
    "- https://community.cloudera.com/t5/Data-Ingestion-Integration/No-brokers-found-in-ZK/td-p/40952\n",
    "- https://github.com/dpkp/kafka-python\n",
    "\n",
    "\n",
    "**Spark summit 2019** - PySpark streaming video tutorial:\n",
    "- https://databricks.com/session/writing-continuous-applications-with-structured-streaming-pyspark-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics in Streaming\n",
    "\n",
    "- continuous vs minibatch\n",
    "- latency vs throughput\n",
    "    - real-time\n",
    "    - near real-time\n",
    "    - some-time\n",
    "    \n",
    "\n",
    "- processing time vs event time\n",
    "    - triggers\n",
    "    - watermarks\n",
    "    \n",
    "\n",
    "- windows\n",
    "    - fixed\n",
    "    - sliding\n",
    "    - sessions\n",
    "    \n",
    "\n",
    "- joins\n",
    "    - stream-stream joins\n",
    "    - stream-static joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.clustering import StreamingKMeans\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This version causes problems: org.apache.spark:spark-sql-kafka-0-10_2.12:2.4.4\n",
    "This does not appear to  be needed org.apache.kafka:kafka-clients:0.10.1.0\n",
    "This does the trick: org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "PACKAGES = ['org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4']\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f\"--packages {','.join(PACKAGES)} pyspark-shell\"\n",
    "print(os.environ['PYSPARK_SUBMIT_ARGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Kafka Server (kafka-server):\u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n",
      "Kafka Server is running\u001b[60G[\u001b[0;32m  OK  \u001b[0;39m]\n"
     ]
    }
   ],
   "source": [
    "!sudo service kafka-server start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root     26741 26678 44 18:48 ?        00:00:19 /usr/java/jdk1.8.0_131/bin/java -cp /opt/spark/conf/:/opt/spark/jars/* -Xmx1g org.apache.spark.deploy.SparkSubmit --conf spark.master=local[*] --conf spark.app.name=wk13_demo --packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.4 pyspark-shell\n",
      "root     26847 26678  0 18:49 pts/1    00:00:00 /bin/sh -c ps -ef|grep spark-sql-kafka\n",
      "root     26849 26847  0 18:49 pts/1    00:00:00 grep spark-sql-kafka\n"
     ]
    }
   ],
   "source": [
    "!ps -ef|grep spark-sql-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "app_name = \"wk13_demo\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://docker.w261:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>wk13_demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdcf5c27e10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Brokers and the Pub/Sub model(Kafka)\n",
    "\n",
    "Message brokers break apart dependencies between applications by creating an asynchronous queue between potions of the application. This can be powerful for breaking machine learning functionality away from the core components of an application.\n",
    "\n",
    "In this model your application sends event messages to a message broker over some protocol such as TCP or UDP. In most cases you want to use TCP so you have acknowledgement of receipt.\n",
    "\n",
    "By breaking away the model from the application you can offload the compute associated with predictions and many other possibilites in case you don't need predictions right away.\n",
    "\n",
    "Here the application is your publisher while your model code acts as a subscriber waiting for new data, thus the name Pub/Sub.\n",
    "\n",
    "One of the most popular frameworks for implemeneting Pub/Sub capabilities is Kafka. It is part of the Apache Software Foundation and integrates well with the rest of the Apache projects such as Spark.\n",
    "\n",
    "Some of the managed cloud alternatives would be Kinesis (AWS), Pub/Sub (Google), and Event Hub (Azure)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Advertising\n",
    "Stream-Stream joins were introduced in Spark 2.3 and have enabled Spark to be used for classes of problems involving two streams. A common example is Online advertising where you have ad impressions and ad clicks.\n",
    "\n",
    "Both clicks and impressions can have delays in sending messages to the broker system such as if a person is sitting on a page and then clicks an ad, or if a user has intermittent connectivity issues. This means we need to store messages for some reasonable period of time from each stream to wait for the corresponding streams message. This is called watermarking and is outlined below.\n",
    "\n",
    "What we would like to do is given a site and an ad exchange that we send ads through, predict the likelihood of our ad being clicked, aka potentially generating revenue. In the example below we'll seed a click with a given probability and if Naive Bayes does a good job we should end up with the same probability at the end of our training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Watermarks**: Watermarking in Structured Streaming is a way to limit state in all stateful streaming operations by specifying how much late data to consider. Specifically, a watermark is a moving threshold in event-time that trails behind the maximum event-time seen by the query in the processed data. The trailing gap (aka watermark delay) defines how long should the engine wait for late data to arrive and is specified in the query using withWatermark. Read about it in more detail in our previous blog post on streaming aggregations. For our stream-stream inner joins, you can optionally specify the watermark delay but you must specify to limit all state on both streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Click Through Rate Prediction\n",
    "* For each impression, we will have a site name, an exchange name and whether a user clicked or not\n",
    "    * For instance, \"Yahoo.com, AdX, 1\"\n",
    "* Bayes' law says that $P(\\text{click} | \\text{site}, \\text{exchange}) = \\frac{P(\\text{site}, \\text{exchange} | \\text{click}) P(\\text{click})}{P(\\text{site}, \\text{exchange})}$\n",
    "* Naive Bayes says that we can assume conditional independence, meaning that $P(\\text{site}|\\text{click}) * P(\\text{exchange}|\\text{click}) = P(\\text{site}, \\text{exchange}|\\text{click})$\n",
    "    * Recall that we don't need to keep track of the denominator\n",
    "* In order to build a NB model, we need to keep track of the following:\n",
    "    * $P(\\text{site}|\\text{click})$\n",
    "    * $P(\\text{exchange}|\\text{click})$\n",
    "    * $P(\\text{click})$\n",
    "* At inference time, we will be predicting \n",
    "    * $\\text{argmax}_{\\text{click} \\in {0, 1}} P(\\text{site} | \\text{click}) * P(\\text{exchange} | \\text{click}) *  P(\\text{click})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Data Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/kafka/libs/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/kafka/libs/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Topic impressions is marked for deletion.\n",
      "Note: This will have no impact if delete.topic.enable is not set to true.\n",
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/kafka/libs/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/kafka/libs/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "Topic clicks is marked for deletion.\n",
      "Note: This will have no impact if delete.topic.enable is not set to true.\n"
     ]
    }
   ],
   "source": [
    "!kafka-topics --zookeeper localhost:2181 --delete --topic impressions\n",
    "!kafka-topics --zookeeper localhost:2181 --delete --topic clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressions = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"localhost:9092\").\\\n",
    "    option(\"subscribe\", \"impressions\").load()   \n",
    "clicks = spark.readStream.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"localhost:9092\").\\\n",
    "    option(\"subscribe\", \"clicks\").load()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTR to sample by exchange and site. \n",
    "If NB preforms well our predictions will be close to these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"site_exchange_ctr\": {\n",
      "\t\t\"yahoo.com+AdX\": 0.4,\n",
      "\t\t\"yahoo.com+SpotX\": 0.2,\n",
      "\t\t\"cnn.com+AdX\": 0.6,\n",
      "\t\t\"cnn.com+SpotX\": 0.3\n",
      "\t}\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat click_through_rate_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watermarking and left outer join to keep non-clicked Ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "impressionsWithWatermark = impressions \\\n",
    "    .selectExpr(\"split(value,',')[0] as impressionAdId\", \\\n",
    "                \"split(value,',')[1] as site\", \\\n",
    "                \"split(value,',')[2] as exchange\",\n",
    "                \"timestamp as impressionTime\") \\\n",
    "    .withWatermark(\"impressionTime\", \"5 second\") \n",
    "\n",
    "clicksWithWatermark = clicks \\\n",
    "    .selectExpr(\"split(value,',')[0] AS clickAdId\", \\\n",
    "                \"timestamp as clickTime\") \\\n",
    "    .withWatermark(\"clickTime\", \"5 second\")\n",
    "\n",
    "statsLog = impressionsWithWatermark\\\n",
    "    .join(clicksWithWatermark,\n",
    "            expr(\"\"\"\n",
    "                clickAdId = impressionAdId AND\n",
    "                clickTime >= impressionTime AND\n",
    "                clickTime <= impressionTime + interval 5 second\n",
    "                \"\"\"),\n",
    "            \"leftOuter\"\n",
    "         )\n",
    "\n",
    "statsLog.createOrReplaceTempView(\"statsLog\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"python kafka_impression_stream.py &\")\n",
    "os.system(\"python kafka_click_stream.py &\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorsData = spark.sql(\"\"\"\n",
    "          select \n",
    "              site, \n",
    "              exchange, \n",
    "              if(clickAdId is not null, 1, 0) as is_click,\n",
    "              count(1) as count\n",
    "          from statslog\n",
    "          group by \n",
    "              site, \n",
    "              exchange,\n",
    "              if(clickAdId is not null, 1, 0)\n",
    "          \"\"\") \n",
    "\n",
    "## write to console\n",
    "query = priorsData\\\n",
    "    .writeStream \\\n",
    "    .format(\"console\")\\\n",
    "    .outputMode(\"complete\")\\\n",
    "    .option(\"truncate\",\"false\")\\\n",
    "    .trigger(processingTime='15 seconds')\\\n",
    "    .start()\n",
    "\n",
    "## write to mem\n",
    "queryMem = priorsData \\\n",
    "    .writeStream \\\n",
    "    .queryName(\"priorsData\") \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .trigger(processingTime='15 seconds') \\\n",
    "    .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(160 + 15) ## stops when close to done "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()\n",
    "queryMem.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output from Command Line\n",
    "\n",
    "```\n",
    "-------------------------------------------\n",
    "quickstart.cloudera_1  | Batch: 0\n",
    "quickstart.cloudera_1  | -------------------------------------------\n",
    "quickstart.cloudera_1  | +----+--------+--------+-----+\n",
    "quickstart.cloudera_1  | |site|exchange|is_click|count|\n",
    "quickstart.cloudera_1  | +----+--------+--------+-----+\n",
    "quickstart.cloudera_1  | +----+--------+--------+-----+\n",
    "quickstart.cloudera_1  |\n",
    "19/12/02 19:11:24 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 15000 milliseconds, but spent 21668 milliseconds\n",
    "-------------------------------------------\n",
    "quickstart.cloudera_1  | Batch: 1\n",
    "quickstart.cloudera_1  | -------------------------------------------\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  | |site     |exchange|is_click|count|\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  | |yahoo.com|SpotX   |1       |3    |\n",
    "quickstart.cloudera_1  | |cnn.com  |SpotX   |1       |10   |\n",
    "quickstart.cloudera_1  | |yahoo.com|AdX     |1       |16   |\n",
    "quickstart.cloudera_1  | |cnn.com  |AdX     |1       |24   |\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  |\n",
    "quickstart.cloudera_1  | 19/12/02 19:11:33 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 15000 milliseconds, but spent 18021 milliseconds\n",
    "19/12/02 19:11:42 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 15000 milliseconds, but spent 17970 milliseconds\n",
    "-------------------------------------------\n",
    "quickstart.cloudera_1  | Batch: 2\n",
    "quickstart.cloudera_1  | -------------------------------------------\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  | |site     |exchange|is_click|count|\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  | |yahoo.com|SpotX   |1       |4    |\n",
    "quickstart.cloudera_1  | |cnn.com  |SpotX   |1       |13   |\n",
    "quickstart.cloudera_1  | |yahoo.com|AdX     |1       |17   |\n",
    "quickstart.cloudera_1  | |cnn.com  |AdX     |1       |28   |\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  |\n",
    "quickstart.cloudera_1  | 19/12/02 19:11:51 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 15000 milliseconds, but spent 18183 milliseconds\n",
    "19/12/02 19:11:59 WARN ProcessingTimeExecutor: Current batch is falling behind. The trigger interval is 15000 milliseconds, but spent 16589 milliseconds\n",
    "[Stage 88:>(79 + 6) / 200][Stage 90:>   (0 + 0) / 1][Stage 91:>   (0 + 0) / 1][I 19:12:01.592 LabApp] Saving file at /LiveSessionMaterials/wk13Demo_Streaming/Spark_Streaming_Naive_Bayes.ipynb\n",
    "quickstart.cloudera_1  | [W 19:12:01.594 LabApp] Notebook LiveSessionMaterials/wk13Demo_Streaming/Spark_Streaming_Naive_Bayes.ipynb is not trusted\n",
    "-------------------------------------------\n",
    "quickstart.cloudera_1  | Batch: 3\n",
    "quickstart.cloudera_1  | -------------------------------------------\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  | |site     |exchange|is_click|count|\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "quickstart.cloudera_1  | |yahoo.com|SpotX   |1       |4    |\n",
    "quickstart.cloudera_1  | |cnn.com  |SpotX   |1       |13   |\n",
    "quickstart.cloudera_1  | |yahoo.com|AdX     |1       |17   |\n",
    "quickstart.cloudera_1  | |cnn.com  |SpotX   |0       |47   |\n",
    "quickstart.cloudera_1  | |yahoo.com|AdX     |0       |49   |\n",
    "quickstart.cloudera_1  | |yahoo.com|SpotX   |0       |53   |\n",
    "quickstart.cloudera_1  | |cnn.com  |AdX     |1       |28   |\n",
    "quickstart.cloudera_1  | |cnn.com  |AdX     |0       |40   |\n",
    "quickstart.cloudera_1  | +---------+--------+--------+-----+\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Data after streaming for a bit\n",
    "We would predict on an interval and bring in data from the stream to calculate each update. Here we'll walk through it in 1 step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.sql(\"select * from priorsData\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+--------+-----+\n",
      "|     site|exchange|is_click|count|\n",
      "+---------+--------+--------+-----+\n",
      "|yahoo.com|   SpotX|       1|    4|\n",
      "|  cnn.com|   SpotX|       1|   13|\n",
      "|yahoo.com|     AdX|       1|   17|\n",
      "|  cnn.com|   SpotX|       0|   47|\n",
      "|yahoo.com|     AdX|       0|   41|\n",
      "|yahoo.com|   SpotX|       0|   53|\n",
      "|  cnn.com|     AdX|       1|   28|\n",
      "|  cnn.com|     AdX|       0|   32|\n",
      "+---------+--------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_click</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count\n",
       "is_click       \n",
       "0           173\n",
       "1            62"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## P(click)\n",
    "p_click = df.groupby(['is_click']).sum()\n",
    "p_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>site</th>\n",
       "      <th>is_click</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">cnn.com</th>\n",
       "      <th>0</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">yahoo.com</th>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count\n",
       "site      is_click       \n",
       "cnn.com   0            79\n",
       "          1            41\n",
       "yahoo.com 0            94\n",
       "          1            21"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## P(site | click)\n",
    "p_site_click = df.groupby(['site', 'is_click']).sum()\n",
    "p_site_click"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <th>is_click</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">AdX</th>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">SpotX</th>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   count\n",
       "exchange is_click       \n",
       "AdX      0            73\n",
       "         1            45\n",
       "SpotX    0           100\n",
       "         1            17"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## P(exchange | click)\n",
    "p_exchange_click = df.groupby(['exchange', 'is_click']).sum()\n",
    "p_exchange_click"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's build our NB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NB:\n",
    "    def __init__(self, p_click, p_site_click, p_exchange_click):\n",
    "        self.p_click = p_click.astype(np.float)\n",
    "        self.p_site_click = p_site_click.astype(np.float)\n",
    "        self.p_exchange_click = p_exchange_click.astype(np.float)\n",
    "    \n",
    "    def classify(self, site, exchange):\n",
    "        p_numerator_click = (self.p_site_click.loc[site].loc[1] / self.p_click.loc[1])\\\n",
    "            * (self.p_exchange_click.loc[exchange].loc[1] / self.p_click.loc[1])\\\n",
    "            * (self.p_click.loc[1] / np.sum(self.p_click))\n",
    "        p_numerator_nonclick = (self.p_site_click.loc[site].loc[0] / self.p_click.loc[0])\\\n",
    "            * (self.p_exchange_click.loc[exchange].loc[0] / self.p_click.loc[0])\\\n",
    "            * (self.p_click.loc[0] / np.sum(self.p_click))\n",
    "        print(\"estimate of clicks to non-clicks: (%.3f):(%.3f)\" % (p_numerator_click, p_numerator_nonclick))\n",
    "        return float(p_numerator_click / (p_numerator_click + p_numerator_nonclick))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "\t\"site_exchange_ctr\": {\n",
      "\t\t\"yahoo.com+AdX\": 0.4,\n",
      "\t\t\"yahoo.com+SpotX\": 0.2,\n",
      "\t\t\"cnn.com+AdX\": 0.6,\n",
      "\t\t\"cnn.com+SpotX\": 0.3\n",
      "\t}\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat click_through_rate_config.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate of clicks to non-clicks: (0.065):(0.169)\n",
      "yahoo.com+AdX 0.277597129704939\n",
      "estimate of clicks to non-clicks: (0.025):(0.231)\n",
      "yahoo.com+SpotX 0.0958187045136147\n",
      "estimate of clicks to non-clicks: (0.127):(0.142)\n",
      "cnn.com+AdX 0.4716515525187701\n",
      "estimate of clicks to non-clicks: (0.048):(0.194)\n",
      "cnn.com+SpotX 0.1975503824660335\n"
     ]
    }
   ],
   "source": [
    "nb = NB(p_click, p_site_click, p_exchange_click)\n",
    "\n",
    "print(\"yahoo.com+AdX\",nb.classify(site=\"yahoo.com\", exchange=\"AdX\"))\n",
    "print(\"yahoo.com+SpotX\",nb.classify(site=\"yahoo.com\", exchange=\"SpotX\"))\n",
    "print(\"cnn.com+AdX\",nb.classify(site=\"cnn.com\", exchange=\"AdX\"))\n",
    "print(\"cnn.com+SpotX\",nb.classify(site=\"cnn.com\", exchange=\"SpotX\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: NB's conditional independence assumption made the estimation inaccurate; however they're roughly within 10% of the known click through rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means Streaming\n",
    "\n",
    "Since K-means is unsupervised and each point can be added into the model additivly it is a great example of an online model.\n",
    "\n",
    "In this simple example we're going to take some sample data in 2 clusters and bring in new data and let the cluster centers evolve based on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmeans_data\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmeans_data\n",
    "-3.0 -5.0\n",
    "-5.1 -4.1\n",
    "-3.9 -5.2\n",
    "-5.2 -4.5\n",
    "-3.3 -5.1\n",
    "4.0 2.0\n",
    "3.1 5.1\n",
    "5.2 5.2\n",
    "4.1 3.5\n",
    "4.5 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.loadtxt(\"kmeans_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2d1403df60>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_data[:,0], train_data[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kmeans_data_sample\n"
     ]
    }
   ],
   "source": [
    "%%writefile kmeans_data_sample\n",
    "(1.0), [1.7, 0.4]\n",
    "(2.0), [2.2, 1.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting new points we will stream in\n",
    "!cat kmeans_data > full_data\n",
    "!printf \"\\n1.7 0.4\" >> full_data\n",
    "!printf \"\\n2.2 1.8\" >> full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc = StreamingContext(sc, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(lp):\n",
    "    label = float(lp[lp.find('(') + 1: lp.find(')')])\n",
    "    vec = Vectors.dense(lp[lp.find('[') + 1: lp.find(']')].split(','))\n",
    "\n",
    "    return LabeledPoint(label, vec)\n",
    "\n",
    "trainingData = sc.textFile(\"kmeans_data\")\\\n",
    "    .map(lambda line: Vectors.dense([float(x) for x in line.strip().split(' ')]))\n",
    "\n",
    "testingData = sc.textFile(\"kmeans_data_sample\").map(parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingQueue = [trainingData]\n",
    "testingQueue = [testingData]\n",
    "\n",
    "trainingStream = ssc.queueStream(trainingQueue)\n",
    "testingStream = ssc.queueStream(testingQueue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StreamingKMeans(k=2, decayFactor=1.0).setRandomCenters(dim=2, weight=1.0, seed=0)\n",
    "model.trainOn(trainingStream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predictOnValues(testingStream.map(lambda lp: (lp.label, lp.features)))\n",
    "result.pprint() ## will print out values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.76405235 0.40015721]\n",
      " [0.97873798 2.2408932 ]]\n"
     ]
    }
   ],
   "source": [
    "original_model_centers = model._model.centers\n",
    "print(original_model_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "Time: 2018-08-01 18:43:25\n",
      "-------------------------------------------\n",
      "(1.0, 0)\n",
      "(2.0, 1)\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-08-01 18:43:26\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-08-01 18:43:27\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-08-01 18:43:28\n",
      "-------------------------------------------\n",
      "\n",
      "-------------------------------------------\n",
      "Time: 2018-08-01 18:43:29\n",
      "-------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssc.start()\n",
    "time.sleep(5)\n",
    "ssc.stop(stopSparkContext=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original cluster centers\n",
      "[[1.76405235 0.40015721]\n",
      " [0.97873798 2.2408932 ]]\n",
      "Updated cluster centers\n",
      "[[-2.10513538 -3.07140611]\n",
      " [ 3.5757476   4.10817864]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Original cluster centers\")\n",
    "print(original_model_centers)\n",
    "print(\"Updated cluster centers\")\n",
    "print(model._model.centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2cffdd7470>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(train_data[:,0], train_data[:,1])\n",
    "plt.scatter(original_model_centers.transpose()[0], original_model_centers.transpose()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2cffda2c88>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(full_data[:,0], full_data[:,1])\n",
    "plt.scatter(model._model.centers.transpose()[0], model._model.centers.transpose()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "What else could be done to make the Naive Bayes more effective in a real world system?\n",
    "- How could we checkpoint?\n",
    "- How can we rollback?\n",
    "- Other ideas?\n",
    "\n",
    "What are some examples of systems you would like to apply this to?\n",
    "- Email Spam (Data trumps complex models, see [The Unreasonable\n",
    "Effectiveness of Data](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf))\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
