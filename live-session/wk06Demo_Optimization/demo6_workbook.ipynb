{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#wk6-Demo---Supervised-Learning-&amp;-Gradient-Descent\" data-toc-modified-id=\"wk6-Demo---Supervised-Learning-&amp;-Gradient-Descent-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>wk6 Demo - Supervised Learning &amp; Gradient Descent</a></div><div class=\"lev1 toc-item\"><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Introduction</a></div><div class=\"lev2 toc-item\"><a href=\"#Notation-Review\" data-toc-modified-id=\"Notation-Review-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Notation Review</a></div><div class=\"lev4 toc-item\"><a href=\"#A-warning-about-OLS-before-we-start:\" data-toc-modified-id=\"A-warning-about-OLS-before-we-start:-2101\"><span class=\"toc-item-num\">2.1.0.1&nbsp;&nbsp;</span>A warning about OLS before we start:</a></div><div class=\"lev2 toc-item\"><a href=\"#Notebook-Set-Up\" data-toc-modified-id=\"Notebook-Set-Up-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Notebook Set Up</a></div><div class=\"lev1 toc-item\"><a href=\"#A-Small-Example\" data-toc-modified-id=\"A-Small-Example-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>A Small Example</a></div><div class=\"lev2 toc-item\"><a href=\"#Demo:-Random-Parameter-Search.\" data-toc-modified-id=\"Demo:-Random-Parameter-Search.-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Demo: Random Parameter Search.</a></div><div class=\"lev2 toc-item\"><a href=\"#Demo:-Systematic-Brute-Force.\" data-toc-modified-id=\"Demo:-Systematic-Brute-Force.-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Demo: Systematic Brute Force.</a></div><div class=\"lev1 toc-item\"><a href=\"#Parameter-Space,-Gradients,-and-Convexity\" data-toc-modified-id=\"Parameter-Space,-Gradients,-and-Convexity-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Parameter Space, Gradients, and Convexity</a></div><div class=\"lev3 toc-item\"><a href=\"#Optimization-Theory-...-a-short-digression\" data-toc-modified-id=\"Optimization-Theory-...-a-short-digression-401\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Optimization Theory ... a short digression</a></div><div class=\"lev2 toc-item\"><a href=\"#Demo:-Gradient-Descent\" data-toc-modified-id=\"Demo:-Gradient-Descent-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Demo: Gradient Descent</a></div><div class=\"lev2 toc-item\"><a href=\"#Demo-:-Stochastic-Gradient-Descent\" data-toc-modified-id=\"Demo-:-Stochastic-Gradient-Descent-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Demo : Stochastic Gradient Descent</a></div><div class=\"lev3 toc-item\"><a href=\"#That's-it-for-today!\" data-toc-modified-id=\"That's-it-for-today!-421\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>That's it for today!</a></div><div class=\"lev4 toc-item\"><a href=\"#Next-week-we-will-discuss...\" data-toc-modified-id=\"Next-week-we-will-discuss...-4211\"><span class=\"toc-item-num\">4.2.1.1&nbsp;&nbsp;</span>Next week we will discuss...</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wk6 Demo - Supervised Learning & Gradient Descent\n",
    "__`MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Spring 2019`__\n",
    "\n",
    "In Supervised Machine Learning we use labeled training data to learn a decision function (a.k.a 'model') and make evaluations about how well that decision function might perform when applied to new data. Of course the biggest factor that will determine the performance of your model is the quality of the data you train on. However another key challenge is the question of what models to consider & how to compare their performance so that you can choose the best one. Gradient Descent solves this challenge for a certain class of functions. By the end of this live session you should be able to:\n",
    "* __... define__ the loss function for OLS Regression and its gradient.\n",
    "* __... explain__ the relationship between model space and parameter space.\n",
    "* __... recognize__ convex optimization problems and why they are desirable.\n",
    "* __... describe__ the process of Gradient Descent & how it can be parallelized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In today's demo, we'll use Linear Regression on a simple example in order to explore key topics related to distributed learning of parametric models. Broadly speaking, the supervised learning of a parametric model can be split into to two components:\n",
    "\n",
    "1. **Optimization Task (a.k.a. Learning)**: Given a strategy for making a prediction, return the specific parameters which guarantee the optimal prediction.   \n",
    "2. **Prediction Task**: Given an input vector, return an output value.\n",
    "\n",
    "\n",
    "> __DISCUSSION QUESTION:__ _In the case of Linear Regression, which of the two tasks above are we most likely to want to parallelize? Why?_\n",
    "\n",
    "\n",
    "OK, Let's start with a quick review of some notation you will have seen in w207. \n",
    "\n",
    "## Notation Review\n",
    "\n",
    "Linear Regression tackles the __prediction task__ by assuming that we can compute our output variable, $y$, using a linear combination of our input variables. That is we assume there exist a set of **weights**, $\\mathbf{w}$, and a **bias** term, $\\mathbf{b}$, such that for any input $\\mathbf{x}_j \\in \\mathbb{R}^m$:\n",
    "\n",
    "\\begin{equation}\\tag{1.1}\n",
    "y_j = \\displaystyle\\sum_{i=1}^{m}{w_i\\cdot x_{ji} + b}\n",
    "\\end{equation}\n",
    "\n",
    "In vector notation, this can be written:\n",
    "\n",
    "\\begin{equation}\n",
    "y_j = \\displaystyle{\\mathbf{w}^T\\mathbf{x}_{j} + b}\n",
    "\\end{equation}\n",
    "\n",
    "Of course, this perfect linear relationship never holds over a whole dataset **$X$**, so Linear Regression attempts to fit (i.e. **learn**) the best line (in 1 dimension) or hyperplane (in 2 or more dimensions) to the data.  In the case of **ordinary least squares (OLS)** linear regression, best fit is defined as minimizing the Euclidean distances of each point in the dataset to the line or hyperplane.  These distances are often referred to as **residuals**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"residual.png\", width=\"400\", height=\"200\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The calculation of the average residual (a.k.a.**mean squared error, MSE**) over our test or training set allows us to measure how good a fit we've achieved. We call this function the **loss** or **objective** function because our goal in the **optimization task** is to find the parameters which minimize it. (Ok, yes, _technically_ MSE is _not actually equal_ to the average residual but it is conceptually equivalent & guaranteed to have the same minimum.)\n",
    "\n",
    "\\begin{equation}\\tag{1.2}\n",
    "f(\\mathbf{w}, b) = \\frac{1}{n}\\sum_{j=1}^{n}\\left[ (\\mathbf{w}^T\\mathbf{x}_j + b) - y_i\\right]^2,\\\\\n",
    "n = \\left|X_{\\text{train}}\\right|\n",
    "\\end{equation}\n",
    "\n",
    "For convenience, we sometimes choose to think of the bias $b$ as weight $w_{m+1}$. To operationalize this, we'll _augment_ our input vectors by setting $x_{m+1}=1$. This gives us a simpler way to write the loss function:\n",
    "$$\n",
    "\\mathbf{x}' :=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x}\\\\\n",
    "1\n",
    "\\end{bmatrix},\\quad\n",
    "\\boldsymbol{\\theta} :=\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{w}\\\\\n",
    "b\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\\begin{equation}\\tag{1.3}\n",
    "f(\\boldsymbol{\\theta}) = \\frac{1}{n}\\sum_{i=1}^{n}\\left[ \\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_i - y_i\\right]^2\n",
    "\\end{equation}\n",
    "\n",
    "Machine Learning packages like `sklearn` and `tensorflow` take this one step further by representing the entire training set in a single matrix were each row is an input vector and each column represents a feature:\n",
    "$$\n",
    "\\text{X}' =\n",
    "\\begin{bmatrix}\n",
    "\\mathbf{x'}_1^{\\text{T}}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathbf{x'}_n^{\\text{T}}\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{y} = \n",
    "\\begin{bmatrix}\n",
    "y_1\\\\\n",
    "\\vdots\\\\\n",
    "y_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\\begin{equation}\\tag{1.4}\n",
    "f(\\boldsymbol{\\theta}) = \\frac{1}{n}\\|\\text{X}'\\cdot \\boldsymbol{\\theta} - \\mathbf{y}\\|_2^2\n",
    "\\end{equation}\n",
    "\n",
    "As you see here, it is customary to write loss as a function of the parameters $\\theta$ (or equivalently $\\mathbf{w}$ and $b$). However it is important to note that the MSE loss depends on both the parameters/weights  _and_ the data $X$, we'll talk more about that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __DISCUSSION QUESTIONS:__ \n",
    "* _In equation 1.1 what do $x_{ji}$, $w_i$, and $\\mathbf{w}$ each represent?_  \n",
    "* _In the asynch's version of the loss function $\\alpha$ and $\\beta$ appear as parameters... what do they represent? How are they captured in equations 1.2 and 1.3 respectively?_ \n",
    "* _If we were computing loss over a really large data set what might be the arguments in favor / against using the augmented version of the loss function calculation?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A warning about OLS before we start:\n",
    "\n",
    "Supervised learning models, especially interprable ones, and especially linear/logistic regression, tend to get used for two different kinds of tasks: prediction and inference -- it is important to remember the difference between these two use cases. While it is practically possible to fit a linear model to any dataset and then use that model to make predictions... it is _not_ always fair to use the coefficients of your model to infer relationships (causal or otherwise) between your features and outcome variable. As you will rememeber from w203 and w207 if you are going to perform inference using OLS, your data should satisfy the following conditions:\n",
    "1. Residuals are homoscedastic - they have constant variance    \n",
    "1. Residuals are normaly distributed\n",
    "1. No multicolinearity - features are not correlated\n",
    "\n",
    "__For more info see the reading ISL 3.1.3__\n",
    "[ISL Slides](https://docs.google.com/presentation/d/1FuUe3jrFoCwA8XTkoSZBwz8xZ0oGJmpUGOmjWqJJAIc/edit#slide=id.p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "# magic commands\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import helper modules\n",
    "import helperFunc\n",
    "import linRegFunc\n",
    "\n",
    "# OPTIONAL - uncomment to print helper file docstrings\n",
    "print(helperFunc.__doc__)\n",
    "#print(linRegFunc.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Small Example\n",
    "\n",
    "We'll start with a small example of 5 2-D points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fivePoints.csv\n",
    "1,2\n",
    "3,4\n",
    "5,5\n",
    "4,3\n",
    "2,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# load data from file\n",
    "points = np.genfromtxt(\"fivePoints.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what they look like next to a the simplest possible linear model:  $ y = x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easy plotting with a helper function\n",
    "helperFunc.plot2DModels(points, [[1,0]],['model'], title = 'Small Example')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable, but its hard to gauge exactly how good a fit we have just by looking.\n",
    "\n",
    "> __A TASK FOR YOU:__ Fill in the calculations below to compute the \"Training Loss\" for our data. These are easy and intuitive calculations that you will know from long-ago math classes... but instead of relying on your visual intuition, challenge yourself to think through these numbers in the context of our matrix equation for loss. Here it is again for your reference:\n",
    "\\begin{equation}\\tag{1.3}\n",
    "f(\\boldsymbol{\\theta}) = \\frac{1}{n}\\sum_{i=1}^{n}\\left[ \\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_i - y_i\\right]^2\n",
    "\\end{equation}\n",
    "\n",
    "The parameter vector $\\theta$ for our initial line $y=x$ is: \n",
    "$ \\begin{bmatrix} ? \\ \\quad ? \\ \\end{bmatrix}$\n",
    "         \n",
    "The (augmented) data points $x_j$ are:\n",
    "$ \\begin{bmatrix} ? \\\\ ? \\\\ \\end{bmatrix}$\n",
    "$ \\begin{bmatrix} ? \\\\ ? \\\\ \\end{bmatrix}$\n",
    "$ \\begin{bmatrix} ? \\\\ ? \\\\ \\end{bmatrix}$\n",
    "$ \\begin{bmatrix} ? \\\\ ? \\\\ \\end{bmatrix}$\n",
    "$ \\begin{bmatrix} ? \\\\ ? \\\\ \\end{bmatrix}$\n",
    "\n",
    "Our loss calculations will be:\n",
    "\n",
    "|$i$  | $y_i$ |   $\\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_i$ | $\\left[ \\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_i - y_i\\right]^2$ |\n",
    "|:---:|:-----:|:----------------:|:------------------------:|\n",
    "|     | true y   |   predicted y   |  squared residual       |\n",
    "| 1   |       |                  |             |\n",
    "| 2   |       |                  |    |\n",
    "| 3   |       |                  |    |\n",
    "| 4   |       |                  |    | \n",
    "| 5   |       |                  |    | \n",
    "\n",
    " The training loss $f(\\boldsymbol{\\theta})$ for this data and these weights is: _______\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"small_example_loss.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to confirm your Hand Calculations\n",
    "X = helperFunc.augment(points)[:,:-1]\n",
    "y = points[:,-1]\n",
    "print(\"Loss:\", linRegFunc.OLSLoss(X, y,[1,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > __DISCUSSION QUESTIONS:__ \n",
    " * _What parts of this computation could be parallelized? What, if any, aggregation has to happen at the end?_ \n",
    " * _What key-value format, partitioning, sorting would help? Could you use a combiner?_ \n",
    " * _In addition to the data stream, what other information would your map or reduce tasks need access to?_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Random Parameter Search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we know the model looks ok and we know its loss is $0.8$ but is that any good? A naive approach to \"learning\" a Linear Model might be to randomly generate a few more models and then pick the model with the lowest loss. Let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helperFunc, linRegFunc\n",
    "\n",
    "#################### Demo Parameters #################### \n",
    "# TRY CHANGING THESE & SEE HOW IT AFFECTS OUR SEARCH\n",
    "NUM_MODELS = 10\n",
    "PARAM_RANGE = [-5,5]\n",
    "\n",
    "#################### Random Search Demo ####################\n",
    "# Load & pre-process data\n",
    "points = np.genfromtxt(\"fivePoints.csv\", delimiter=',')\n",
    "X = helperFunc.augment(points)[:,:2]\n",
    "y = points[:,1]\n",
    "\n",
    "# \"Training\"\n",
    "models = [[0,1]]\n",
    "names = [\"INIT - Loss: 0.8\"]\n",
    "best = {'loss':0.8, 'W': [1,0]}\n",
    "for idx in range(NUM_MODELS):\n",
    "    # initialize a random weight vector w/ values in specified range\n",
    "    W = np.random.uniform(PARAM_RANGE[0],PARAM_RANGE[1], size=(2))\n",
    "    # compute loss & store for plotting\n",
    "    loss = linRegFunc.OLSLoss(X, y, W)\n",
    "    models.append(W)\n",
    "    names.append(\"model%s - Loss: %.2f\" % (idx, loss))\n",
    "    # track best model\n",
    "    if loss < best['loss']:\n",
    "        best['loss'] = loss\n",
    "        best['W'] = W\n",
    "        \n",
    "# Display Results\n",
    "print(f\"Best Random Model: {best['W']}, Loss: {best['loss']}\")\n",
    "helperFunc.plot2DModels(points, models, names, \"A Random Approach.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that was pretty poor. One idea would be to run a lot more iterations.\n",
    "\n",
    "> __DISCUSSION QUESTION:__ \n",
    "* _To what extent could parallelization help us redeem this approach? What exactly would you parallelize?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Systematic Brute Force."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For obvious reasons a more systematic approach is desirable. Instead of randomly guessing, let's use what we know to search an appropriate section of the the model space.\n",
    "\n",
    "We can tell from the data that the linear model should probably have a fairly shallow positive slope and a positive intercept between 0 and 2. So lets initialize every possible combination of weights in that range up to a granularity of, say $0.2$, and compute the loss for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helperFunc, linRegFunc\n",
    "\n",
    "#################### Demo Parameters #################### \n",
    "# TRY CHANGING THESE & SEE HOW IT AFFECTS OUR SEARCH\n",
    "W0_MIN = 0\n",
    "W0_MAX = 2\n",
    "W0_STEP = 0.2\n",
    "\n",
    "W1_MIN = 0\n",
    "W1_MAX = 2\n",
    "W1_STEP = 0.2\n",
    "\n",
    "#################### Grid Search Demo #################### \n",
    "### Load & Pre-process Data\n",
    "points = np.genfromtxt(\"fivePoints.csv\", delimiter=',')\n",
    "X = helperFunc.augment(points)[:,:2]\n",
    "y = points[:,1]\n",
    "\n",
    "### \"Training\" \n",
    "# create a model for each point in our grid\n",
    "grid = np.mgrid[W0_MIN:W0_MAX:W0_STEP,W1_MIN:W1_MAX:W1_STEP]\n",
    "size = int(np.product(grid.shape)/2)\n",
    "models = grid.reshape(2,size).T\n",
    "# compute loss for each model\n",
    "loss = []\n",
    "for W in models:\n",
    "    loss.append(linRegFunc.OLSLoss(X,y,W))\n",
    "    \n",
    "### Display Results\n",
    "print(f\"Searched {size} models...\")\n",
    "print(f\"Best model: {models[np.argmin(loss)]}, Loss: {min(loss)}\")\n",
    "helperFunc.plotErrorSurface(points,models,loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __DISCUSSION QUESTIONS:__ \n",
    "* _When we think about scaling up, is this still a better approach than guessing? How could it be parallelized?_ \n",
    "* _What would change about this approach if we had higher dimension data?_\n",
    "* _In practice, when we're training Linear Models why don't we just look at the error surface and identify the lowest point?_\n",
    "* _What about if we're training other kinds of models?_  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Space, Gradients, and Convexity\n",
    "\n",
    "As suggested by the systematic search demo, when we train parametric models we tend to switch back and forth between two different ways of visualizing our goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"./GD_gif/Gradient_Descent.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When we look at a model next to our data represented in the Problem Domain Space, it is natural to think about loss as a measure of _**how far off the data are from our model**_. In other words, this visual suggests loss is a function of the training data $X$.\n",
    "* By contrast, looking at an error surface plotted in Model Parameter Space, we intuitively see loss as an indicator of _**how far off the current model is from the optimal model**_. In other words, this view helps us think of loss as a function of the parameters $\\theta$.\n",
    "\n",
    "Of course in one sense, this distinction is just a matter of sematics. As we saw in equations 1.2, 1.3 and 1.4, MSE loss depends on _both_ the data and the parameters. However, in the context of 'inventing' ways to train a model, this distinction is a useful one. If we think of the data as fixed and focus on how loss varies _with respect to the parameters_, then we can take advantage of a little theory to speed up our search for the optimal parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization Theory ... a short digression\n",
    "\n",
    "Calculus gives us the simple solution to optimizing a real function. The **First Order Conditions** (a.k.a. 'first derivative rule') says that the maximum or minimum of an unconstrained function must occur at a point where the first derivative = 0. In higher dimensions we extend this rule to talk about a **gradient** vector of partial derivatives which all must equal 0. \n",
    "\n",
    "When the first order partial derivatives are equal to zero, then we know we are at a local maximum or minimum of the real function.  But which one is it?  In order to tell, we must take the second derivatives of the real function.  If the second derivatives are positive at that point, then we know we are at a minimum.  If the second derivatives are negative, then we know we are at a maximum.  These are the **second order conditions.**\n",
    "\n",
    "**Convex Optimization** is the lucky case where we know that the second derivatives never change sign. There are lots of complicated loss functions for which we can't easily visualize the error surface but for which we _can_ prove mathematically that this 2nd order condition is met. If this is the case, then we can think of the suface as _always curving up_ or _always curving down_ which guarantees that any minimum we reach will be an absolute minimum. More powerfully still, this result can be shown to _also_ apply to a class of \"pseudo-convex\" functions - functions whose second derivative might not be well defined, but satisfy certain conditions that allow us to guarantee convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __DSICUSSION QUESTIONS:__ \n",
    "* _In the case of Linear Regression performed on data $X \\in \\mathbb{R}^m$, how many dimensions does the gradient vector have? What do each of the values in this vector represent visually?_\n",
    "* _If we are systematically searching the parameter space for a lowest point, why might it be useful to know that our loss function is convex?_ \n",
    "* _In general (i.e. beyond Linear Regression) if finding the ideal parameters $\\theta$, is as simple as solving the equation $f'(\\theta)=0$, why don't we always train our models by solving that equation?_ \n",
    "* _Condider the loss curves illustrated below -- do these illustrations represent problem space or parameter space? which ones are convex?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"loss_01_fabianp.png\" height=\"250\" width=\"250\"><img src=\"loss_02_algorithmia.png\" height=\"250\" width=\"250\"><img src=\"loss_03_mathworks.png\" height=\"250\" width=\"250\">\n",
    "\n",
    "Sources: [first image](http://fa.bianp.net/blog/2014/surrogate-loss-functions-in-machine-learning/) | [second image](https://blog.algorithmia.com/introduction-to-loss-functions/) | [third image](https://fr.mathworks.com/help/gads/example-finding-the-minimum-of-a-function-using-the-gps-algorithm.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take advantage of these lessons from Optimization Theory, we'll start by taking the derivative of the loss function with respect to the parameters $\\boldsymbol{\\theta}$. Recall the matrix formulation of our loss function:\n",
    "\n",
    "\\begin{equation}\\tag{1.3}\n",
    "f(\\boldsymbol{\\theta}) = \\frac{1}{n}\\sum_{i=1}^{n}\\left[ \\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_i - y_i\\right]^2\n",
    "\\end{equation}\n",
    "\n",
    "We can apply the sum and chain derivation rules to compute the gradient:\n",
    "\n",
    "\\begin{equation}\\tag{3.1}\n",
    "\\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}) = \\frac{2}{n}\\,\\sum_{i=1}^{n}\\left[ \\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_i - y_i\\right] \\cdot \\mathbf{x}'_i\n",
    "\\end{equation}\n",
    "\n",
    "We _could_ now set this equation equal to $0$ and then solve for $\\boldsymbol{\\theta}$... but it turns out that this __closed form solution__ can be computationally challenging in higher dimensions. It also turns out that a simple approximation technique will work almost as well. \n",
    "\n",
    "The strategy of **Gradient Descent** is to start somewhere random in the Model Parameter Space and then move down the error surface to find a minimum point with the optimal parameters for our training data. Its ingeniousness is that we can do this without actually knowing the full shape of the error surface. Think of it like walking down a hill while blindfolded. You test each direction to see which way is down, then take a little step in that direction and repeat the process until you can't feel any more 'down' to go. The 'size' of our steps is controled by a hyperparameter, $\\alpha$, the **learning rate**. The whole process can be summarized in 3 steps:\n",
    "1. Initialize the parameters $\\theta$.\n",
    "2. Compute the gradient $\\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta})$.\n",
    "3. Update the parameters: $\\theta_{\\text{new}} = \\theta_{\\text{old}} - \\alpha \\cdot \\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta}) $  \n",
    "\n",
    "We repeat these steps until we reach a stopping criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __A TASK FOR YOU:__ Compute one Gradent Descent update step for the small example from Part 2. \n",
    "Recall that our initial parameters were:\n",
    "$$ \\boldsymbol{\\theta} = \\begin{bmatrix} 1 \\ \\quad 0 \\ \\end{bmatrix}$$  \n",
    "> For your convenience the augmented input data vectors are already entered in the table below:\n",
    "\n",
    "\n",
    "Hand Calculations:\n",
    "\n",
    "|  $x_j '$  | $y_j$ |   $\\boldsymbol{\\theta}\\cdot\\mathbf{x}'_j$ | $\\left[ \\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_j - y_j\\right]\\cdot\\mathbf{x}'_j$ |\n",
    "|:----:|:-----:|:----------------:|:------------------------:|\n",
    "|  input   | true y   |   predicted y   |  gradient  component for $x_j$       |\n",
    "| $ \\begin{bmatrix} 1 \\\\ 1 \\\\ \\end{bmatrix}$   |  2   |                  |             \n",
    "| $ \\begin{bmatrix} 2 \\\\ 1 \\\\ \\end{bmatrix}$   |  3   |                  |    \n",
    "| $ \\begin{bmatrix} 3 \\\\ 1 \\\\ \\end{bmatrix}$   |  4   |                  |    \n",
    "| $ \\begin{bmatrix} 4 \\\\ 1 \\\\ \\end{bmatrix}$   |  3   |                  |    \n",
    "| $ \\begin{bmatrix} 5 \\\\ 1 \\\\ \\end{bmatrix}$   |  5   |                  |    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient $\\nabla_{\\boldsymbol{\\theta}} f(\\boldsymbol{\\theta})$ for this data and these weights is: [-0.8, -0.8]\n",
    "\n",
    "If $\\alpha = 0.1$ the update for this step will be: [-0.08 -0.08]\n",
    "\n",
    "The new parameters will be $\\theta_{\\text{new}}=$ [1.08, 0.08]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"small_example_gradient.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > __DISCUSSION QUESTIONS:__  \n",
    " * _How would you go about parallelizing this calculation? What would the mapper do, what would the reducers do? What key-value structure, sorting, partitioning, etc would you use?_ \n",
    " * _How do the computational demands of performing GD compare to the task of computing the loss?_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Run this demo to confirm your hand calculations & examine a few more GD steps.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helperFunc, linRegFunc\n",
    "\n",
    "#################### Demo Parameters #################### \n",
    "# TRY CHANGING THESE & SEE HOW IT AFFECTS OUR SEARCH\n",
    "N_STEPS = 5\n",
    "LEARNING_RATE = 0.1\n",
    "ORIGINAL_MODEL = [1,0]\n",
    "SHOW_CONTOURS = True\n",
    "\n",
    "################### Gradient Update Demo #################### \n",
    "### Load & Pre-process Data\n",
    "points = np.genfromtxt(\"fivePoints.csv\", delimiter=',')\n",
    "X = helperFunc.augment(points)[:,:2]\n",
    "y = points[:,1]\n",
    "\n",
    "### Perform GD Update & save intermediate model performance\n",
    "models, loss = linRegFunc.GDUpdate(X, y, N_STEPS,\n",
    "                                   ORIGINAL_MODEL, \n",
    "                                   LEARNING_RATE, \n",
    "                                   verbose = True)\n",
    "\n",
    "### Display Results\n",
    "print(f\"\\nSearched {len(models)} models...\")\n",
    "print(f\"Best model: {models[np.argmin(loss)]}, Loss: {loss[np.argmin(loss)]}\")\n",
    "linRegFunc.plotGDProgress(points, models, loss,\n",
    "                          show_contours = SHOW_CONTOURS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > __DISCUSSION QUESTIONS:__  \n",
    " * _Look closely at the loss for each model, what problem do you notice?_ \n",
    " * _Use the Model Parameter Space view to explain why this problem might be occurring._ __HINT:__ Try `SHOW_CONTOURS = True`. _Based upon your insights, propose a solution to this problem._\n",
    " * _When performing GD 'in the wild' will we be able to visualize the error surface (eg. using contour lines, heatmaps or 3D plots)?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo : Stochastic Gradient Descent\n",
    "\n",
    "\n",
    "In full Gradient Descent (what we did above) we do a descent step only after the calculation of the gradient over the whole set of data. That means we only update the weight vector once each **epoch** (pass over the data) thus making one small but “good” step towards the minimum. However since gradient descent is an interative algorithm that requires many updates to find the minimum, with large datasets, waiting to process every record before performing an update can result in a slow and computationaly costly training process. \n",
    "\n",
    "The alternatives are:\n",
    "1. **Stochastic GD** -- compute the gradient _with respect to a single point at a time_ and update the entire weight vector after each record. By the time we have seen the whole data set, we will have made N (num of observations), perhaps “not so good”, steps with a general trend towards the minimum. SGD will “zig-zag” towards the minimum and eventually oscillate around the minimum but never converge. The advantage of SGD is that we can make progress at every example - if the data is very large, we may only need 1 pass over the whole dataset.\n",
    "2. **Mini-batch GD** -- compute the gradient _with respect to a small **batch** (size of $B$) of points at a time_ and update the entire weight vector after each batch. If we are smart about shuffling the data, this can reduce the “zig-zaging” because the points in a batch will temper each other's influence. This is especially advantageous for noisy data where a single point might result in a gradient update that is dramatically in the wrong direction for the rest of the data. For this reason, MBGD can potentially finish even faster than SGD. However MBGD is seldom used because finding the right hyper-parameter b is a pain (usually $B$ is not too big $-$ from 32 to 256). \n",
    "\n",
    "\n",
    "Other than the denominator in front, the loss function for SGD/MBGD should look very familiar (note that SGD is basically just the special case where $B = 1$):\n",
    "\n",
    "\\begin{equation}\\tag{3.2}\n",
    "\\nabla f(\\boldsymbol{\\theta}) \\approx \\nabla_{\\text{batch}\\,\\,} f(\\boldsymbol{\\theta}) = \\frac{2}{B}\\sum_{i=1}^{B}\\left(\\boldsymbol{\\theta}^T \\cdot\\mathbf{x}'_{a_i} - y_{a_i}\\right)\\cdot \\mathbf{x}'_{a_i}\n",
    "\\end{equation}\n",
    "\n",
    "where $a_i$ is an array of indices of objects which are in this batch. After obtaining this gradient we do a descent step in this approximate direction and proceed to the next stage of batch descent.\n",
    "\n",
    "> __A TASK FOR YOU:__ Perform 5 update steps of Stochastic Gradient Descent with batchsize = $1$ on our small data set. \n",
    "Recall that our initial parameters were:\n",
    "$$ \\boldsymbol{\\theta} = \\begin{bmatrix} 1 \\ \\quad 0 \\ \\end{bmatrix}$$  \n",
    "> ... and we used a learning rate of $\\boldsymbol{\\eta} = 0.1$\n",
    "\n",
    "($\\eta$ is pronounced 'eh-ta', sometimes we also use $\\alpha$, \"apha\" to denote learning rate, the two are equivalent)\n",
    "\n",
    "Hand Calculations:\n",
    "\n",
    "|  $x_j '$  | $y_j$ |   $\\boldsymbol{\\theta}\\cdot\\mathbf{x}'_j$ | $\\frac{2}{B}\\left[ \\boldsymbol{\\theta}^T\\cdot\\mathbf{x}'_j - y_j\\right]\\cdot\\mathbf{x}'_j$ | $\\eta \\nabla_{\\boldsymbol{\\theta}} f$ | $\\boldsymbol(\\theta) - \\eta \\nabla_{\\boldsymbol{\\theta}} f $ |\n",
    "|:----:|:-----:|:----------------:|:------------------------:|:--------------:|:-----------:|\n",
    "|  input   | true y   |   predicted y   | gradient for this 'batch' | update | new parameters|\n",
    "| $ \\begin{bmatrix} 1 \\\\ 1 \\\\ \\end{bmatrix}$   |  2   |                  |             \n",
    "| $ \\begin{bmatrix} 3 \\\\ 1 \\\\ \\end{bmatrix}$   |  4   |                  |     \n",
    "| $ \\begin{bmatrix} 5 \\\\ 1 \\\\ \\end{bmatrix}$   |  5   |                  |      \n",
    "| $ \\begin{bmatrix} 4 \\\\ 1 \\\\ \\end{bmatrix}$   |  3   |                  |      \n",
    "| $ \\begin{bmatrix} 2 \\\\ 1 \\\\ \\end{bmatrix}$   |  3   |                  |      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " > __DISCUSSION QUESTIONS:__  \n",
    " * _How does this result compare to our result from the hand calculations in the last section? What implications does this have for our quest to find the optimal paramters?_ \n",
    " * _How will parallelizing Stoichastic Gradient Descent be similar/different to parallelizing regular GD?_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=\"demo6-SGD.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helperFunc, linRegFunc\n",
    "\n",
    "#################### Demo Parameters #################### \n",
    "# TRY CHANGING THESE & SEE HOW IT AFFECTS OUR SEARCH\n",
    "N_STEPS = 5\n",
    "BATCHSIZE = 1\n",
    "LEARNING_RATE = 0.1\n",
    "ORIGINAL_MODEL = [1,0]\n",
    "SHOW_CONTOURS = True\n",
    "\n",
    "################### Stoichastic GD Demo #################### \n",
    "### Load & Pre-process Data\n",
    "points = np.genfromtxt(\"fivePoints.csv\", delimiter=',')\n",
    "X = helperFunc.augment(points)[:,:2]\n",
    "y = points[:,1]\n",
    "\n",
    "### Perform SGD Updates & save intermediate model performance\n",
    "models, loss = linRegFunc.SGDUpdate(X, y, N_STEPS,\n",
    "                                    BATCHSIZE,\n",
    "                                    ORIGINAL_MODEL, \n",
    "                                    LEARNING_RATE, \n",
    "                                    verbose = False)\n",
    "\n",
    "### Display Results\n",
    "print(f\"\\nSearched {len(models)} models...\" %())\n",
    "print(f\"Best model: {models[np.argmin(loss)]}, Loss: {loss[np.argmin(loss)]}\")\n",
    "linRegFunc.plotGDProgress(points, models, loss,\n",
    "                          show_contours = SHOW_CONTOURS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __DISCUSSION QUESTIONS:__ \n",
    "* _At first glance does this seem to work as well as regular gradient descent? Why might our initial impression be deceiving?_ \n",
    "* _Does adjusting the batchsize and/or learning rate fix the problem that we're seeing?_\n",
    "* _What do you notice about the direction of the first 3 updates? From the perspective of the first three points, what should our line look like?_\n",
    "* _How does the scale of our data can impact the direction of our updates & time to convergence?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For more info, here are a few of rabbit holes:__\n",
    "> https://arxiv.org/pdf/1707.00424.pdf   \n",
    "> https://papers.nips.cc/paper/4390-hogwild-a-lock-free-approach-to-parallelizing-stochastic-gradient-descent.pdf\n",
    "> http://papers.nips.cc/paper/4006-parallelized-stochastic-gradient-descent.pdf\n",
    "> https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/distr_mini_batch.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it for today! \n",
    "\n",
    "#### Next week we will discuss...\n",
    "* __L1 and L2 Regularization__ \n",
    "* __Common GD variants__\n",
    "* __What to do if you can't compute a gradient for your loss function.__\n",
    "* __Logistic Regression & classification__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "462px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "567px",
    "left": "0px",
    "right": "707.4456787109375px",
    "top": "105px",
    "width": "243px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
