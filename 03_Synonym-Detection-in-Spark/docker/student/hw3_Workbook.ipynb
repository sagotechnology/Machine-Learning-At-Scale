{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c052a4ea-9f23-4194-afc4-ef6472f60a3b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# HW 3 - Synonym Detection In Spark\n",
    "__`MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Fall 2018`__\n",
    "\n",
    "In the last homework assignment you performed Naive Bayes to classify documents as 'ham' or 'spam.' In doing so, we relied on the implicit assumption that the list of words in a document can tell us something about the nature of that document's content. We'll rely on a similar intuition this week: the idea that, if we analyze a large enough corpus of text, the list of words that appear in small window before or after a vocabulary term can tell us something about that term's meaning. This is similar to the intuition behind the word2vec algorithm.\n",
    "\n",
    "This will be your first assignment working in Spark. You'll perform Synonym Detection by repurposing an algorithm commonly used in Natural Language Processing to perform document similarity analysis. In doing so you'll also become familiar with important datatypes for efficiently processing sparse vectors and a number of set similarity metrics (e.g. Cosine, Jaccard, Dice). By the end of this homework you should be able to:  \n",
    "* ... __define__ the terms `one-hot encoding`, `co-occurrance matrix`, `stripe`, `inverted index`, `postings`, and `basis vocabulary` in the context of both synonym detection and document similarity analysis.\n",
    "* ... __explain__ the reasoning behind using a word stripe to compare word meanings.\n",
    "* ... __identify__ what makes set-similarity calculations computationally challenging.\n",
    "* ... __implement__ stateless algorithms in Spark to build stripes, inverted index and compute similarity metrics.\n",
    "* ... __identify__ when it makes sense to take a stripe approach and when to use pairs\n",
    "* ... __apply__ appropriate metrics to assess the performance of your synonym detection algorithm. \n",
    "\n",
    "__RECOMMENDED READING FOR HW3__:\t\n",
    "Your reading assignment for weeks 4 and 5 were fairly heavy and you may have glossed over the papers on dimension independent similarity metrics by [Zadeh et al](http://stanford.edu/~rezab/papers/disco.pdf) and pairwise document similarity by [Elsayed et al](https://terpconnect.umd.edu/~oard/pdf/acl08elsayed2.pdf). If you haven't already, this would be a good time to review those readings, especially when it comes to the similarity formulas -- they are directly relevant to this assignment.\n",
    "\n",
    "DITP Chapter 4 - Inverted Indexing for Text Retrieval. While this text is specific to Hadoop, the Map/Reduce concepts still apply.\n",
    "\n",
    "__Please refer to the `README` for homework submission instructions and additional resources.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "516b0fa3-8a8e-4279-a9a9-d0e2610edca0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Notebook Set-Up\n",
    "Before starting your homework run the following cells to confirm your setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f5abc60-dcd4-468a-b0f2-250552a36386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f5abc60-dcd4-468a-b0f2-250552a36386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f5abc60-dcd4-468a-b0f2-250552a36386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# start Spark Session (RUN THIS CELL AS IS)\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"hw3_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f5abc60-dcd4-468a-b0f2-250552a36386",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.app.name', 'hw3_notebook'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.app.id', 'local-1633128898809'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/home/samueljohngomez/docker/student/spark-warehouse'),\n",
       " ('spark.driver.port', '40415'),\n",
       " ('spark.driver.host', 'docker.w261'),\n",
       " ('spark.driver.extraJavaOptions',\n",
       "  '-Dio.netty.tryReflectionSetAccessible=true'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.executor.extraJavaOptions',\n",
       "  '-Dio.netty.tryReflectionSetAccessible=true'),\n",
       " ('spark.app.startTime', '1633128897828'),\n",
       " ('spark.ui.showConsoleProgress', 'true')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark configuration Information (RUN THIS CELL AS IS)\n",
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7909b057-ba61-490a-95e7-e60c7cb06c04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://docker.w261:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>hw3_notebook</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fd20f046370>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get Spark Session info (RUN THIS CELL AS IS)\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5cf6e6b5-5993-4e10-9da2-47429244cfda",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Question 1: Spark Basics.\n",
    "In your readings and live session demos for weeks 4 and 5 you got a crash course in working with Spark. We also talked about how Spark RDDs fit into the broader picture of distributed algorithm design. The questions below cover key points from these discussions. Answer each one very briefly - 2 to 3 sentences.\n",
    "\n",
    "### Q1 Tasks:\n",
    "\n",
    "* __a) short response:__ What is Spark? How  does it relate to Hadoop MapReduce?\n",
    "\n",
    "* __b) short response:__ In what ways does Spark follow the principles of statelessness (a.k.a. functional programming)? List at least one way in which it allows the programmer to depart from this principle. \n",
    "\n",
    "* __c) short response:__ In the context of Spark what is a 'DAG' and how does it relate to the difference between an 'action' and a 'transformation'? Why is it useful to pay attention to the DAG that underlies your Spark implementation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d8876d5d-05fe-47a5-b61b-a251ee4ebc6a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Q1 Student Answers:\n",
    "> __a)__ Spark is a data processing engine for big data sets.  Similar to Hadoop, Spark distributes large tasks across different nodes.  Other similarities among these two frameworks include the use of functional programming, higher-order functions, and parallel computation fault tolerance.  In contrast to Hadoop, Spark is not constrained to Hadoop's two-stage paradigm.  Moreover, Spark processes data in random access memory (RAM) using a concept known as a resilient distributed dataset, while Hadoop MapReduce persists data back to the disk after a map or reduce action.  Spark's performance is thus much faster than Hadoop's.  Due to Spark's use of RAM, Hadoop runs at a lower cost.  Though both platforms process data in a distributed environment, Hadoop is ideal for batch processing and linear data processing.  Although, Spark has the capability of real-time processing and processing live unstructured data streams.  One advantage Spark has over Hadoop is the availability of custom libraries that perform regression, classification, persistence, pipeline construction, evaluation, and other machine learning computation. As a final note, Hadoop has the upper hand regarding security with its use of multiple authentication and access control methods.  However, Spark can integrate with Hadoop to improve security. \n",
    "\n",
    "> __b)__ Spark follows the principles of statelessness through its use of projection and selection operations.  Operations such as map(), flatMap(), filter(), etc., process each input record individually, self-reliant from previous information.  The independence from prior input data makes these operations stateless. \n",
    "\n",
    "> A DataFrame.groupBy().count() operation is one way Spark departs from statelessness.  This operation allows the programmer to generate a running count of the number of records received since the beginning of a query.  For example, every executed micro-batch adds the count of current records to the previous count of prior micro-batch records.  Spark executors maintain the state in memory, allowing the programmer to specify a location where checkpoint counts can be stored to enable fault tolerance. \n",
    "\n",
    "> __c)__ Spark achieves fast computation speed through several means.  The three most notable are CPU performance and memory, directed acyclic graph (DAG), and the use of whole-stage code generation in its execution engine, Tungsten.  The DAG scheduler and query optimizer construct an efficient computation graph usually decomposed into tasks for execution in parallel across workers on the cluster.  In essence, a DAG is a visual representation of Spark's execution plan, where each node within a DAG can be single or multiple stages with the tasks depicted to complete the job.  Transformations such as select(), filter(), etc., are represented visually in a DAG.  Since Spark transformations are lazily evaluated, an action like collect(), count(), etc., must be invoked to start the execution.  The visual representation of the job offers valuable insight into the execution roadmap for the programmer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c2542400-9725-4996-94c2-313025d682ba",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Question 2: Similarity Metrics\n",
    "As mentioned in the introduction to this assignment, an intuitive way to compare the meaning of two documents is to compare the list of words they contain. Given a vocabulary \\\\(V\\\\) (feature set) we would represent each document as a vector of `1`-s and `0`-s based on whether or not it contains each word in \\\\(V\\\\). These \"one-hot encoded\" vector representations allow us to use math to identify similar documents. However like many NLP tasks the high-dimensionality of the feature space is a challenge... especially when we start to scale up the size and number of documents we want to compare.\n",
    "\n",
    "In this question we'll look at a toy example of document similarity analysis. Consider these 3 'documents': \n",
    "```\n",
    "docA\tthe flight of a bumblebee\n",
    "docB\tthe length of a flight\n",
    "docC\tbuzzing bumblebee flight\n",
    "```\n",
    "These documents have a total of \\\\(7\\\\) unique words: \n",
    ">`a, bumblebee, buzzing, flight, length, of, the`.     \n",
    "\n",
    "Given this vocabulary, the documents' vector representations are (note that one-hot encoded entries follow the order of the vocab list above):\n",
    "\n",
    "```\n",
    "docA\t[1,1,0,1,0,1,1]\n",
    "docB\t[1,0,0,1,1,1,1]\n",
    "docC\t[0,1,1,1,0,0,0]\n",
    "```  \n",
    "\n",
    "### Q2 Tasks:\n",
    "\n",
    "* __a) short response:__ The cosine similarity between two vectors is $$\\frac{A\\cdot B}{\\|A\\|\\|B\\|}$$. Explain what the the numerator and denominator of this calculation would represent in terms of word counts in documents A and B. \n",
    "\n",
    "* __b) short response:__ Explain how the Jaccard, Overlap and Dice metrics are similar/different to the calculation for cosine similarity. When would these metrics lead to different similarity rankings for a set of documents? HINT: consider documents of very different lengths. It may be helpful to generate some small examples.\n",
    "\n",
    "* __c) short response:__ Calculate the cosine similarity for each pair of documents in our toy corpus. Please use markdown and \\\\(\\LaTeX\\\\) to show your calcuations.  \n",
    "\n",
    "* __d) short response:__ According to your calculations in `part c` which pair of documents are most similar in meaning? __BONUS__: Does this match your expecatation from reading the documents? If not, speculate about why we might have gotten this result.\n",
    "\n",
    "* __e) short response:__ In NLP common words like '`the`', '`of`', and '`a`' increase our feature space without adding a lot of signal about _semantic meaning_. Repeat your analysis from `part c` but this time ignore these three words in your calculations [__`TIP:`__ _to 'remove' stopwords just ignore the vector entries in columns corresponding to the words you wish to disregard_]. How do your results change?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4b5124c4-8817-422f-ba04-ad6d4de5ff9d",
     "showTitle": false,
     "title": ""
    },
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Q2 Student Answers:\n",
    "> __a)__ In data science and other subjects, cosine similarity is used as a quantitative measure for the similarity between two things.  Values range from -1 to 1, where -1 is perfectly dissimilar, and 1 is perfectly similar.  In this example, vectors represent the words in a document.  The numerator in the cosine similarity function is the dot product of the number of times each term appears in documents $A$ and $B$ (represented in vector format), also known as the inner product.  The numerator increases by the product of word i in documents $A$ and $B$.  This part of the equation can be understood as a numerical intersection, where more strongly weighted words increase the value.  The denominator is the product of these two vectors' Euclidean lengths, in other words, the magnitude of each document's co-occurrence vector with all other terms (vector norm). Dividing a vector by its norm rescales its components so the length is between 0 and 1\n",
    "\n",
    "> __b)__ Note that all these metrics are similarity statistics.  \n",
    "\n",
    "> The Jaccard index is similar to cosine similarity because only words common in both documents increase the value of the numerator.  The difference between the two is the normalizing component/denominator.  Cosine similarity only normalizes by the product of the sums of each word common to both documents, while Jaccard sums the cardinality of both documents (sums the total number of uniques words in each document).  In short, the cosine similarity's denominator is influenced by common words, while the Jaccard index's denominator is concerned about unique words in each document.\n",
    "\n",
    "> Similar to cosine similarity, the overlap coefficient's numerator increases in value only by words common in both documents.  The difference being the denominator is equal to the smaller number of unique words among documents A or B. \n",
    "\n",
    "> Similar to cosine similarity, the Dice coefficient's numerator increases in value only by words common in both documents.  As a side note, the Dice numerator differs from the Jaccard index and overlap coefficient in that it is multiplied by 2.   The difference between cosine similarity is that the denominator equals the sum of document A and B's cardinality--the same as the Jaccard Index. \n",
    "\n",
    "> When considering the similarity rankings for each statistic, the overlap coefficient yields quite a different ranking than the other statistics if the document's unique word count varies widely from the minimum document size.  In general, cosine similarity is more robust to document size disparity compared to the other statistics; it is affected more by common word frequency.\n",
    "\n",
    "> __c)__ \n",
    "> similarity = $cos(\\theta) = \\frac{|A|\\cdot|B|}{||A|| ||B||} = \\frac{\\sum_{i=1}^{n}A_i B_i}{\\sqrt{\\sum_{i=1}^{n}A_i^2}\\sqrt{\\sum_{i=1}^{n}B_i^2}}$\n",
    "\n",
    "> $\\sum_{i=1}^{n}A_i B_i = 4$, &nbsp; &nbsp; &nbsp; $\\sqrt{\\sum_{i=1}^{n}A_i^2} = \\sqrt{5}$, &nbsp; &nbsp; &nbsp; $\\sqrt{\\sum_{i=1}^{n}B_i^2}, = \\sqrt{5}$ &nbsp; &nbsp; &nbsp; --> &nbsp; &nbsp; &nbsp; $similarity_{AB} = 4/5 = 0.8$  \n",
    "\n",
    "> $\\sum_{i=1}^{n}B_i C_i = 1$, &nbsp; &nbsp; &nbsp; $\\sqrt{\\sum_{i=1}^{n}B_i^2} = \\sqrt{5}$, &nbsp; &nbsp; &nbsp; $\\sqrt{\\sum_{i=1}^{n}C_i^2}, = \\sqrt{3}$ &nbsp; &nbsp; &nbsp; --> &nbsp; &nbsp; &nbsp; $similarity_{BC} = 0.258$  \n",
    "\n",
    "\n",
    "> $\\sum_{i=1}^{n}A_i C_i = 2$, &nbsp; &nbsp; &nbsp; $\\sqrt{\\sum_{i=1}^{n}A_i^2} = \\sqrt{5}$, &nbsp; &nbsp; &nbsp; $\\sqrt{\\sum_{i=1}^{n}C_i^2}, = \\sqrt{3}$ &nbsp; &nbsp; &nbsp; --> &nbsp; &nbsp; &nbsp; $similarity_{AC} = 0.516$\n",
    "\n",
    "\n",
    "> __d & d-bonus)__  According to calculations, A and B are the most similar pair of documents.  This outcome does match my expectation but is contrary to my initial intuition.  Naturally, I thought A and C are more related because of common words bumblebee and flight, which are more relevant to document similarity than words a, of, and the.  However, because A and B have more common words overall, they are more similar in this example.  As the saying goes, the more data, the better--more data needed for this exercise!\n",
    "\n",
    "> __e)__ After removing stop words, documents A and C have the highest similarity ranking.\n",
    "```\n",
    "docA\t[1,0,1,0]\n",
    "docB\t[0,0,1,1]\n",
    "docC\t[1,1,1,0]\n",
    "``` \n",
    "> $similarity_{AB} = 0.5$  \n",
    "> $similarity_{BC} = 0.41$  \n",
    "> $similarity_{AC} = 0.82$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9b5fd240-e9d2-44a2-8fa8-9c6adfa5df05",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Question 3: Synonym Detection Strategy\n",
    "\n",
    "In the Synonym Detection task we want to compare the meaning of words, not documents. For clarity, lets call the words whose meaning we want to compare `terms`. If only we had a 'meaning document' for each `term` then we could easily use the document similarity strategy from Question 2 to figure out which `terms` have similar meaning (i.e. are 'synonyms'). Of course in order for that to work we'd have to reasonably believe that the words in these 'meaning documents' really do reflect the meaning of the `term`. For a good analysis we'd also need these 'meaning documents' to be fairly long -- the one or two sentence dictionary definition of a term isn't going to provide enough signal to distinguish between thousands and thousands of `term` meanings.\n",
    "\n",
    "This is where the idea of co-occurrance comes in. Just like DocSim makes the assumption that words in a document tell us about the document's meaning, we're going to assume that the set of words that 'co-occur' within a small window around our term can tell us some thing about the meaning of that `term`. Remember that we're going to make this 'co-words' list (a.k.a. 'stripe') by looking at a large body of text. This stripe is our 'meaning document' in that it reflects all the kinds of situations in which our `term` gets used in real language. So another way to phrase our assumption is: we think `terms` that get used to complete lots of the same phrases probably have related meanings. This may seem like an odd assumption but computational linguists have found that it works surprisingly well in practice. Let's look at a toy example to build your intuition for why and how.\n",
    "\n",
    "Consider the opening line of Charles Dickens' _A Tale of Two Cities_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b7504e66-ef09-472a-909b-bea5b1f5e393",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (RUN THIS CELL AS IS)\n",
    "corpus = \"\"\"It was the best of times, it was the worst of times, \n",
    "it was the age of wisdom it was the age of foolishness\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7676fba9-0e45-4f63-876d-89132d7b25c1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "There are a total of 10 unique words in this short 'corpus':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "520d6d4c-336a-4df2-b518-a1e48c00bc98",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'was', 'it', 'best', 'wisdom', 'of', 'the', 'worst', 'foolishness', 'times']\n"
     ]
    }
   ],
   "source": [
    "# (RUN THIS CELL AS IS)\n",
    "words = list(set(re.findall(r'\\w+', corpus.lower())))\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b095aa02-95a8-4ac1-9a1c-b7b6c985916a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "But of these 10 words, 4 are so common that they probably don't tell us very much about meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fec9f761-d5db-4c48-90cc-85303e7e3335",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# (RUN THIS CELL AS IS)\n",
    "stopwords = [\"it\", \"the\", \"was\", \"of\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d5a85035-6a79-476a-807b-cbcbdb71579e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "So we'll ignore these 'stop words' and we're left with a 6 word vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "117ecf80-a449-4cc5-9fa6-c5f5128a4daa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'best', 'foolishness', 'times', 'wisdom', 'worst']\n"
     ]
    }
   ],
   "source": [
    "# (RUN THIS CELL AS IS)\n",
    "vocab = sorted([w for w in words if w not in stopwords])\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b833d4bf-fe53-4ca1-bf82-733995aed493",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Your goal in the tasks below is to asses, which of these six words are most related to each other in meaning -- based solely on this short two line body of text.\n",
    "\n",
    "### Q3 Tasks:\n",
    "\n",
    "* __a) short response:__ Given this six word vocabulary, how many 'pairs' of words do we want to compare? More generally for a n-word vocabulary how many pairwise comparisons are there to make? \n",
    "\n",
    "* __b) code:__ In the space provided below, create a 'stripe' for each `term` in the vocabulary. This stripe should be the list of all other vocabulary words that occur within a __5 word window__ (two words on either side) of the `term`'s position in the original text (In this exercise, use ['it', 'was', 'the','of'] as stopwords, just ignore them from your 5 word vectors).\n",
    "\n",
    "* __c) short response:__ Run the provided code to turn your stripes into a 1-hot encoded co-occurrence matrix. For our 6 word vocabulary how many entries are in this matrix? How many entries are zeros? \n",
    "\n",
    "* __d) code:__ Complete the provided code to loop over all pairs and compute their cosine similarity. Please do not modify the existing code, just add your own in the spot marked.\n",
    "\n",
    "* __e) short response:__ Which pairs of words have the highest 'similarity' scores? __BONUS__: Are these words 'synonyms' in the traditional sense? In what sense are their meanings 'similar'? Explain how our results are contingent on the input text. What would change if we had a much larger corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "06d178ec-c8bf-42aa-8d67-a09ba61187f4",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Q3 Student Answers:\n",
    "> __a)__ The general formula for calculating pairwise comparison for a n-word vocabulary is: &nbsp; $\\frac{n * (n-1)}{2}$  \n",
    "> In this example, the number of pairwise comparisons is:  \n",
    "> $\\frac{(6)(5)}{2} = \\frac{30}{2} =15$\n",
    "\n",
    "> __c)__ For the six-word vocabulary, there are 36 entries in the matrix; there are 28 zero entries.  \n",
    "\n",
    "> __e)__ The pairs with the highest similarity scores are:  \n",
    "best-worst = 1  \n",
    "foolishness-wisdom = 1  \n",
    "\n",
    "> __e-bonus)__ The words in the pairs above are not synonyms in the traditional sense.  They are similar in this context because they appear around a common word--precisely two words before or after a common term.  If the corpus were larger, these words would most likely have a lower cosine similarity value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "429c15b1-d1bd-4b04-a6e7-175e336a1907",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CORPUS:\n",
      "It was the best of times, it was the worst of times, \n",
      "it was the age of wisdom it was the age of foolishness\n",
      "VOCAB:\n",
      "['age', 'best', 'foolishness', 'times', 'wisdom', 'worst']\n"
     ]
    }
   ],
   "source": [
    "# for convenience, here are the corpus & vocab list again (RUN THIS CELL AS IS)\n",
    "print(\"CORPUS:\")\n",
    "print(corpus)\n",
    "print('VOCAB:')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "482cae9e-bee6-48ab-97e4-175f993e0834",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "<img src='https://github.com/kyleiwaniec/w261_assets/blob/master/images/best-of-times.png?raw=true' style='width:80%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "72c12700-cffd-4ef4-b408-f5809acc6671",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part b - USE THE TEXT ABOVE TO COMPLETE EACH STRIPE\n",
    "# Stopwords: \n",
    "#     ['it', 'was', 'the', 'of'] \n",
    "# Hint:\n",
    "#     In provided sentence, age appears in two 5 word vectors: ['was', 'the', 'age', 'of', 'wisdom'] and ['was', 'the', 'age', 'of', 'foolishness']\n",
    "#     After removing stopwords, the remaining words are 'wisdom' and 'foolishness'\n",
    "#\n",
    "#     You finish the rest of the non-stopwords below. \n",
    "\n",
    "stripes = {'age':['wisdom','foolishness'], # example\n",
    "           'best':['times'], # YOU FILL IN THE REST\n",
    "           'foolishness':['age'],\n",
    "           'times': ['best', 'worst'],\n",
    "           'wisdom':['age'],\n",
    "           'worst':['times']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "38f4b1a4-3e91-4976-89d3-07b4942215bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part c - initializing an empty co-occurrence matrix (RUN THIS CELL AS IS)\n",
    "co_matrix = pd.DataFrame({term: [0]*len(vocab) for term in vocab}, index = vocab, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bac747a0-a1e3-4795-aa2c-c010b10ab979",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>times</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foolishness</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>times</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wisdom</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worst</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             age  best  foolishness  times  wisdom  worst\n",
       "age            0     0            1      0       1      0\n",
       "best           0     0            0      1       0      0\n",
       "foolishness    1     0            0      0       0      0\n",
       "times          0     1            0      0       0      1\n",
       "wisdom         1     0            0      0       0      0\n",
       "worst          0     0            0      1       0      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part c - this cell 1-hot encodes the co-occurrence matrix (RUN THIS CELL AS IS) \n",
    "for term, nbrs in stripes.items():\n",
    "    pass\n",
    "    for nbr in nbrs:\n",
    "        co_matrix.loc[term, nbr] = 1\n",
    "co_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9b6cf0e3-9003-4d88-aa65-68d0a7b693e5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age-best: 0.0\n",
      "age-foolishness: 0.0\n",
      "age-times: 0.0\n",
      "age-wisdom: 0.0\n",
      "age-worst: 0.0\n",
      "best-foolishness: 0.0\n",
      "best-times: 0.0\n",
      "best-wisdom: 0.0\n",
      "best-worst: 1.0\n",
      "foolishness-times: 0.0\n",
      "foolishness-wisdom: 1.0\n",
      "foolishness-worst: 0.0\n",
      "times-wisdom: 0.0\n",
      "times-worst: 0.0\n",
      "wisdom-worst: 0.0\n"
     ]
    }
   ],
   "source": [
    "# part e - FILL IN THE MISSING LINES to compute the cosine similarity between each pair of terms\n",
    "for term1, term2 in itertools.combinations(vocab, 2):\n",
    "    # one hot-encoded vectors\n",
    "    v1 = co_matrix[term1]\n",
    "    v2 = co_matrix[term2]\n",
    "    \n",
    "    # cosine similarity\n",
    "    ############# YOUR CODE HERE #################\n",
    "    dot, normV1, normV2 = np.dot(v1, v2), np.linalg.norm(v1), np.linalg.norm(v2)\n",
    "    csim = dot / (normV1 * normV2)\n",
    "    ############# (END) YOUR CODE #################    \n",
    "    \n",
    "    print(f\"{term1}-{term2}: {csim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3e757c6f-10ef-487c-bd29-4f0bd0c93aa7",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "source": [
    "# Question 4: Pairs and Stripes at Scale\n",
    "\n",
    "As you read in the paper by Zadeh et al, the advantage of metrics like Cosine, Dice, Overlap and Jaccard is that they are dimension independent -- that is to say, if we implement them in a smart way the computational complexity of performing these computations is independent of the number of documents we want to compare (or in our case, the number of terms that are potential synonyms). One component of a 'smart implementation' involves thinking carefully both about how you define the \"basis vocabulary\" that forms your feature set (removing stopwords, etc). Another key idea is to use a data structure that facilitates distributed calculations. The DISCO implemetation further uses a sampling strategy, but that is beyond the scope of this assignment. \n",
    "\n",
    "In this question we'll take a closer look at the computational complexity of the synonym detection approach we took in question 3 and then revist the document similarity example as a way to explore a more efficient approach to parallelizing this analysis.\n",
    "\n",
    "### Q4 Tasks:\n",
    "\n",
    "* __a) short response:__ In question 3 you calculated the cosine similarity of pairs of words using the vector representation of their co-occurrences in a corpus. In the asynch videos about \"Pairs and Stripes\" you were introduced to an alternative strategy. Explain two ways that using these data structures are more efficient than 1-hot encoded vectors when it comes to distributed similarity calculations [__`HINT:`__ _Consider memory constraints, amount of information being shuffled, amount of information being transfered over the network, and level of parallelization._]\n",
    "\n",
    "* __b) read provided code:__ The code below provides a streamined implementation of Document similarity analysis in Spark. Read through this code carefully. Once you are confident you understand how it works, answer the remaining questions. [__`TIP:`__ _to see the output of each transformation try commenting out the subsequent lines and adding an early `collect()` action_.]\n",
    "\n",
    "* __c) short response:__ The second mapper function, `splitWords`, emits 'postings'. The list of all 'postings' for a word is also refered to as an 'inverted index'. In your own words, define each of these terms ('postings' and 'inverted index') based on your reading of the provided code. (*DITP by Lin and Dyer also contains a chapter on the Inverted Index although in the context of Hadoop rather than Spark. You may find the illustration in Chaprter 4 helpful in answering this question*).\n",
    "\n",
    "* __d) short response:__ The third mapper, `makeCompositeKeys`, loops over the inverted index to emit 'pairs' of what? Explain what information is included in the composite key created at this stage and why it makes sense to synchronize around that information in the context of performing document similarity calculations. In addition to the information included in these new keys, what other piece of information will we need to compute Jaccard or Cosine similarity?\n",
    "\n",
    "* __e) short response:__ Out of all the Spark transformations we make in this analysis, which are 'wide' transformations and which are 'narrow' transformations. Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "244c0e4a-7043-4bc1-a64f-231db9211ea1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Q4 Student Answers:\n",
    "\n",
    "> __a)__ The pairs and stripes data structures allow similarity calculations to be handled in parallel across a cluster, unlike the vector form computed in Question 3.  Parallel computation is particularly important for speed and memory--two advantages of the pairs and stripes data structures.  One-hot encoding may be too overwhelming for one machine's memory.  At some point, memory is limited when using a pandas dataframe for one-hot encoding vector computation.  With pairs and stripes, more resources can be added to the cluster to handle large datasets.  Another benefit is the available computation power in parallel, which can speed up the processing time. \n",
    "\n",
    "> __b)__ _read provided code before answering d-f_ \n",
    "\n",
    "> __c)__ A posting consists of a document ID and a payload.  In this example, a posting is comprised of a term's document ID and the number of words in the document in which it resides.  Each unique term has its postings arranged into a posting list (a list of tuples) by invoking the reduceByKey() transformation and lambda function.  The result is an inverted index, which provides quick access to document IDs containing a specific term.\n",
    "\n",
    "> __d)__ The third map loops over the data to emit pairs of documents containing the same term.  The composite key is a pair of postings belonging to the same term.  In this example, the posting includes the docID and the total number of words in each document.  It makes sense to synchronize around this information to as a precursor to calculating the Jaccard coefficient or another similarity statistic.   Aside from the pairs of posting data, the total number of similar words among the document pair is needed to compute a similarity statistic--which the key-value pair includes.\n",
    "\n",
    "> __e)__ The transformations applied in this analysis are map(), flatMap(), and reduceByKey().  Categorizing these transformation as either wide or narrow yields the following:   \n",
    "> wide - reduceByKey()  \n",
    "> narrow - map(), flatMap()  \n",
    "> If each partition of the parent RDD is used by at most one partition of the child RDD, the transformation is narrow.  In contrast, a wide transformation uses multiple parent RDD partitions to generate a child RDD partition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "02bbeeeb-2c83-40ad-b648-79b76f2603cb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "A small test file: __`sample_docs.txt`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c4aa7016-5fff-4b11-b615-4cff0007f244",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting sample_docs.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile sample_docs.txt\n",
    "docA\tbright blue butterfly forget\n",
    "docB\tbest forget bright sky\n",
    "docC\tblue sky bright sun\n",
    "docD\tunder butterfly sky hangs\n",
    "docE\tforget blue butterfly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c738aa14-92f0-4727-bd60-0c0f5326ad37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docA\tbright blue butterfly forget\n",
      "docB\tbest forget bright sky\n",
      "docC\tblue sky bright sun\n",
      "docD\tunder butterfly sky hangs\n",
      "docE\tforget blue butterfly\n"
     ]
    }
   ],
   "source": [
    "# load data - RUN THIS CELL AS IS\n",
    "!cat sample_docs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "36e04f30-d4ee-484f-a6f4-5568a1698a49",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Document Similarity Analysis in Spark:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "da504044-0c75-4763-adad-2d8e2817265b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load data - RUN THIS CELL AS IS\n",
    "data = sc.textFile(\"sample_docs.txt\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "13bca2b5-8996-4018-b59b-3db3599f14fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# helper function - RUN THIS CELL AS IS\n",
    "def splitWords(pair):\n",
    "    \"\"\"Mapper 2: tokenize each document and emit postings.\"\"\"\n",
    "    doc, text = pair\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        yield (w, [(doc,len(words))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "68200122-deb9-434b-84b1-a1a130566b68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# helper function - RUN THIS CELL AS IS\n",
    "def makeCompositeKey(inverted_index):\n",
    "    \"\"\"Mapper 3: loop over postings and yield pairs.\"\"\"\n",
    "    word, postings = inverted_index\n",
    "    # taking advantage of symmetry, output only (a,b), but not (b,a)\n",
    "    for subset in itertools.combinations(sorted(postings), 2):\n",
    "        yield (str(subset), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "34b72a6c-cab1-46ea-b50b-00ce7fa49cc4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# helper function - RUN THIS CELL AS IS\n",
    "def jaccard(line):\n",
    "    \"\"\"Mapper 4: compute similarity scores\"\"\"\n",
    "    (doc1, n1), (doc2, n2) = ast.literal_eval(line[0])\n",
    "    total = int(line[1])\n",
    "    jaccard = total / float(int(n1) + int(n2) - total)\n",
    "    yield doc1+\" - \"+doc2, jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a706f1c-bbb2-4f45-af1c-9ebee2fbea0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bright', [('docA', 4)]),\n",
       " ('blue', [('docA', 4)]),\n",
       " ('butterfly', [('docA', 4)]),\n",
       " ('forget', [('docA', 4)]),\n",
       " ('best', [('docB', 4)]),\n",
       " ('forget', [('docB', 4)]),\n",
       " ('bright', [('docB', 4)]),\n",
       " ('sky', [('docB', 4)]),\n",
       " ('blue', [('docC', 4)]),\n",
       " ('sky', [('docC', 4)]),\n",
       " ('bright', [('docC', 4)]),\n",
       " ('sun', [('docC', 4)]),\n",
       " ('under', [('docD', 4)]),\n",
       " ('butterfly', [('docD', 4)]),\n",
       " ('sky', [('docD', 4)]),\n",
       " ('hangs', [('docD', 4)]),\n",
       " ('forget', [('docE', 3)]),\n",
       " ('blue', [('docE', 3)]),\n",
       " ('butterfly', [('docE', 3)])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Job - RUN THIS CELL AS IS\n",
    "result = data.map(lambda line: line.split('\\t')) \\\n",
    "             .flatMap(splitWords).collect() \\\n",
    "#              .reduceByKey(lambda x,y : x+y) \\\n",
    "#              .flatMap(makeCompositeKey) \\\n",
    "#              .reduceByKey(lambda x,y : x+y) \\\n",
    "#              .flatMap(jaccard) \\\n",
    "#              .takeOrdered(10, key=lambda x: -x[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a706f1c-bbb2-4f45-af1c-9ebee2fbea0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bright', [('docA', 4), ('docB', 4), ('docC', 4)]),\n",
       " ('butterfly', [('docA', 4), ('docD', 4), ('docE', 3)]),\n",
       " ('best', [('docB', 4)]),\n",
       " ('sky', [('docB', 4), ('docC', 4), ('docD', 4)]),\n",
       " ('sun', [('docC', 4)]),\n",
       " ('blue', [('docA', 4), ('docC', 4), ('docE', 3)]),\n",
       " ('forget', [('docA', 4), ('docB', 4), ('docE', 3)]),\n",
       " ('under', [('docD', 4)]),\n",
       " ('hangs', [('docD', 4)])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Job - RUN THIS CELL AS IS\n",
    "result = data.map(lambda line: line.split('\\t')) \\\n",
    "             .flatMap(splitWords) \\\n",
    "             .reduceByKey(lambda x,y : x+y).collect() \\\n",
    "#              .flatMap(makeCompositeKey) \\\n",
    "#              .reduceByKey(lambda x,y : x+y) \\\n",
    "#              .flatMap(jaccard) \\\n",
    "#              .takeOrdered(10, key=lambda x: -x[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a706f1c-bbb2-4f45-af1c-9ebee2fbea0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"(('docA', 4), ('docB', 4))\", 1),\n",
       " (\"(('docA', 4), ('docC', 4))\", 1),\n",
       " (\"(('docB', 4), ('docC', 4))\", 1),\n",
       " (\"(('docA', 4), ('docD', 4))\", 1),\n",
       " (\"(('docA', 4), ('docE', 3))\", 1),\n",
       " (\"(('docD', 4), ('docE', 3))\", 1),\n",
       " (\"(('docB', 4), ('docC', 4))\", 1),\n",
       " (\"(('docB', 4), ('docD', 4))\", 1),\n",
       " (\"(('docC', 4), ('docD', 4))\", 1),\n",
       " (\"(('docA', 4), ('docC', 4))\", 1),\n",
       " (\"(('docA', 4), ('docE', 3))\", 1),\n",
       " (\"(('docC', 4), ('docE', 3))\", 1),\n",
       " (\"(('docA', 4), ('docB', 4))\", 1),\n",
       " (\"(('docA', 4), ('docE', 3))\", 1),\n",
       " (\"(('docB', 4), ('docE', 3))\", 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Job - RUN THIS CELL AS IS\n",
    "result = data.map(lambda line: line.split('\\t')) \\\n",
    "             .flatMap(splitWords) \\\n",
    "             .reduceByKey(lambda x,y : x+y) \\\n",
    "             .flatMap(makeCompositeKey).collect() \\\n",
    "#              .reduceByKey(lambda x,y : x+y) \\\n",
    "#              .flatMap(jaccard) \\\n",
    "#              .takeOrdered(10, key=lambda x: -x[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a706f1c-bbb2-4f45-af1c-9ebee2fbea0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"(('docA', 4), ('docB', 4))\", 2),\n",
       " (\"(('docA', 4), ('docC', 4))\", 2),\n",
       " (\"(('docB', 4), ('docC', 4))\", 2),\n",
       " (\"(('docD', 4), ('docE', 3))\", 1),\n",
       " (\"(('docC', 4), ('docD', 4))\", 1),\n",
       " (\"(('docA', 4), ('docD', 4))\", 1),\n",
       " (\"(('docA', 4), ('docE', 3))\", 3),\n",
       " (\"(('docB', 4), ('docD', 4))\", 1),\n",
       " (\"(('docC', 4), ('docE', 3))\", 1),\n",
       " (\"(('docB', 4), ('docE', 3))\", 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Job - RUN THIS CELL AS IS\n",
    "result = data.map(lambda line: line.split('\\t')) \\\n",
    "             .flatMap(splitWords) \\\n",
    "             .reduceByKey(lambda x,y : x+y) \\\n",
    "             .flatMap(makeCompositeKey) \\\n",
    "             .reduceByKey(lambda x,y : x+y).collect() \\\n",
    "#              .flatMap(jaccard) \\\n",
    "#              .takeOrdered(10, key=lambda x: -x[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a706f1c-bbb2-4f45-af1c-9ebee2fbea0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('docA - docB', 0.3333333333333333),\n",
       " ('docA - docC', 0.3333333333333333),\n",
       " ('docB - docC', 0.3333333333333333),\n",
       " ('docD - docE', 0.16666666666666666),\n",
       " ('docC - docD', 0.14285714285714285),\n",
       " ('docA - docD', 0.14285714285714285),\n",
       " ('docA - docE', 0.75),\n",
       " ('docB - docD', 0.14285714285714285),\n",
       " ('docC - docE', 0.16666666666666666),\n",
       " ('docB - docE', 0.16666666666666666)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Job - RUN THIS CELL AS IS\n",
    "result = data.map(lambda line: line.split('\\t')) \\\n",
    "             .flatMap(splitWords) \\\n",
    "             .reduceByKey(lambda x,y : x+y) \\\n",
    "             .flatMap(makeCompositeKey) \\\n",
    "             .reduceByKey(lambda x,y : x+y) \\\n",
    "             .flatMap(jaccard).collect() \\\n",
    "#              .takeOrdered(10, key=lambda x: -x[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1a706f1c-bbb2-4f45-af1c-9ebee2fbea0c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('docA - docE', 0.75),\n",
       " ('docA - docB', 0.3333333333333333),\n",
       " ('docA - docC', 0.3333333333333333),\n",
       " ('docB - docC', 0.3333333333333333),\n",
       " ('docD - docE', 0.16666666666666666),\n",
       " ('docC - docE', 0.16666666666666666),\n",
       " ('docB - docE', 0.16666666666666666),\n",
       " ('docC - docD', 0.14285714285714285),\n",
       " ('docA - docD', 0.14285714285714285),\n",
       " ('docB - docD', 0.14285714285714285)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spark Job - RUN THIS CELL AS IS\n",
    "result = data.map(lambda line: line.split('\\t')) \\\n",
    "             .flatMap(splitWords) \\\n",
    "             .reduceByKey(lambda x,y : x+y) \\\n",
    "             .flatMap(makeCompositeKey) \\\n",
    "             .reduceByKey(lambda x,y : x+y) \\\n",
    "             .flatMap(jaccard) \\\n",
    "             .takeOrdered(10, key=lambda x: -x[1])\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6a9f78ca-93fe-46ba-8d26-fa7a8adc6710",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# About the Data\n",
    "Now that you are comfortable with similarity metrics we turn to the main task in this assignment: \"Synonym\" Detection. As you saw in Question 3 the ability of our algorithm to detect words with similar meanings is highly dependent on our input text. Specifically, we need a large enough corpus of natural language that we can expose our algorithm to a realistic range of contexts in which any given word might get used. Ideally, these 'contexts' would also provide enough signal to distinguish between words with similar semantic roles but different meaning. Finding such a corpus will be easier to accomplish for some words than others.\n",
    "\n",
    "For the main task in this portion of the homework you will use data from Google's n-gram corpus. This data is particularly convenient for our task because Google has already done the first step for us: they windowed over a large subset of the web and extracted all 5-grams. If you are interested in learning more about this dataset the original source is: http://books.google.com/ngrams/, and a large subset is available [here from AWS](https://aws.amazon.com/datasets/google-books-ngrams/). \n",
    "\n",
    "For this assignment we have provided a subset of the 5-grams data consisting of 191 files of approximately 10MB each. These files are available in the 'data' folder in 'Assignments/HW3/' github.  Please only use the provided data so that we can ensure consistent results from student to student.\n",
    "\n",
    "Each row in our dataset represents one of these 5 grams in the format:\n",
    "> `(ngram) \\t (count) \\t (pages_count) \\t (books_count)`\n",
    "\n",
    "__DISCLAIMER__: In real life, we would calculate the stripes cooccurrence data from the raw text by windowing over the raw text and not from the 5-gram preprocessed data.  Calculating pairs on this 5-gram is a little corrupt as we will be double counting cooccurences. Having said that this exercise can still pull out some similar terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "67ee798a-99fd-4ada-b8b1-4bfa6d032335",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# set global paths to full data folder and to the first file (which we'll use for testing)\n",
    "NGRAMS = '../../data'\n",
    "F1_PATH = '../../data/googlebooks-eng-all-5gram-20090715-0-filtered.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d36301d1-c5fd-46c7-91a5-4745bb175741",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "As you develop your code you should use the following file to systems test each of your solutions before running it on the Google data. (Note: these are the 5-grams extracted from our two line Dickens corpus in Question 3... you should find that your Spark job results match the calculations we did \"by hand\").\n",
    "\n",
    "Test file: __`systems_test.txt`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed5ebc27-0381-4fe6-901b-fe4fc4f5a10d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting systems_test.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile systems_test.txt\n",
    "it was the best of\t1\t1\t1\n",
    "age of wisdom it was\t1\t1\t1\n",
    "best of times it was\t1\t1\t1\n",
    "it was the age of\t2\t1\t1\n",
    "it was the worst of\t1\t1\t1\n",
    "of times it was the\t2\t1\t1\n",
    "of wisdom it was the\t1\t1\t1\n",
    "the age of wisdom it\t1\t1\t1\n",
    "the best of times it\t1\t1\t1\n",
    "the worst of times it\t1\t1\t1\n",
    "times it was the age\t1\t1\t1\n",
    "times it was the worst\t1\t1\t1\n",
    "was the age of wisdom\t1\t1\t1\n",
    "was the best of times\t1\t1\t1\n",
    "was the age of foolishness\t1\t1\t1\n",
    "was the worst of times\t1\t1\t1\n",
    "wisdom it was the age\t1\t1\t1\n",
    "worst of times it was\t1\t1\t1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ac26da79-b410-4a8c-9d5d-6c074d48769d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Finally, we'll create a Spark RDD for each of these files so that they're easy to access throughout the rest of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4e162747-4cf6-4f36-89ca-a1214512f5c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Spark RDDs for each dataset\n",
    "testRDD = sc.textFile(\"systems_test.txt\") \n",
    "f1RDD = sc.textFile(F1_PATH)\n",
    "dataRDD = sc.textFile(NGRAMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "70ae8e81-27de-4975-8b4c-22bbb82c6be5",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Let's take a peek at what each of these RDDs looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6382f9a6-0b3d-4cb5-be31-f4ac27814306",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it was the best of\\t1\\t1\\t1',\n",
       " 'age of wisdom it was\\t1\\t1\\t1',\n",
       " 'best of times it was\\t1\\t1\\t1',\n",
       " 'it was the age of\\t2\\t1\\t1',\n",
       " 'it was the worst of\\t1\\t1\\t1',\n",
       " 'of times it was the\\t2\\t1\\t1',\n",
       " 'of wisdom it was the\\t1\\t1\\t1',\n",
       " 'the age of wisdom it\\t1\\t1\\t1',\n",
       " 'the best of times it\\t1\\t1\\t1',\n",
       " 'the worst of times it\\t1\\t1\\t1']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7a94a009-6a28-4c71-9cfd-57fc3f0469e4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A BILL FOR ESTABLISHING RELIGIOUS\\t59\\t59\\t54',\n",
       " 'A Biography of General George\\t92\\t90\\t74',\n",
       " 'A Case Study in Government\\t102\\t102\\t78',\n",
       " 'A Case Study of Female\\t447\\t447\\t327',\n",
       " 'A Case Study of Limited\\t55\\t55\\t43',\n",
       " \"A Child's Christmas in Wales\\t1099\\t1061\\t866\",\n",
       " 'A Circumstantial Narrative of the\\t62\\t62\\t50',\n",
       " 'A City by the Sea\\t62\\t60\\t49',\n",
       " 'A Collection of Fairy Tales\\t123\\t117\\t80',\n",
       " 'A Collection of Forms of\\t116\\t103\\t82']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1RDD.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3821fa08-6fbd-46dd-9233-92ae8dad4e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Background Paper Prepared for\\t130\\t130\\t126',\n",
       " 'A Bicycle Built for Two\\t626\\t618\\t544',\n",
       " 'A Cabinet was formed with\\t41\\t41\\t41',\n",
       " 'A Case Study of State\\t219\\t218\\t159',\n",
       " 'A Catechism and Confession of\\t169\\t165\\t140',\n",
       " 'A Catholic could not be\\t64\\t56\\t56',\n",
       " 'A Certain Tendency in the\\t67\\t64\\t53',\n",
       " 'A Chronicle of One Hundred\\t127\\t127\\t87',\n",
       " 'A Chronicle of the Arctic\\t88\\t88\\t81',\n",
       " 'A Chronicle of the Pontiac\\t96\\t96\\t92']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2bec439f-08e0-45b9-a249-6e57064f627d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Question 5: N-gram EDA part 1 (words)\n",
    "\n",
    "Before starting our synonym-detection, let's get a sense for this data. As you saw in questions 3 and 4 the size of the vocabulary will impact the amount of computation we have to do. Write a Spark job that will accomplish the three tasks below as efficiently as possible. (No credit will be awarded for jobs that sort or subset after calling `collect()`-- use the framework to get the minimum information requested). As you develop your code, systems test each job on the provided file with Dickens ngrams, then on a single file from the Ngram dataset before running the full analysis.\n",
    "\n",
    "\n",
    "### Q5 Tasks:\n",
    "* __a) code:__ Write a Spark application to retrieve:\n",
    "  * The number of unique words that appear in the data. (i.e. size of the vocabulary) \n",
    "  * A list of the top 10 words & their counts.\n",
    "  * A list of the bottom 10 words & their counts.  \n",
    "  \n",
    "  __`NOTE  1:`__ _don't forget to lower case the ngrams before extracting words._  \n",
    "  __`NOTE  2:`__ _don't forget to take in to account the number of occurances (count) of each ngram._  \n",
    "  __`NOTE  3:`__ _to make this code more reusable, the `EDA1` function code base uses a parameter 'n' to specify the number of top/bottom words to print (in this case we've requested 10)._\n",
    "\n",
    "\n",
    "* __b) short response:__ Given the vocab size you found in part a, how many potential synonym pairs could we form from this corpus? If each term's stripe were 1000 words long, how many tuples would we need to shuffle in order to form the inverted indices? Show and briefly explain your calculations for each part of this question. [__`HINT:`__ see your work from q4 for a review of these concepts.]\n",
    "\n",
    "* __c) short response:__ Looking at the most frequent words and their counts, how usefull will these top words be in synonym detection? Explain.\n",
    "\n",
    "* __d) short response:__ Looking at the least frequent words and their counts, how reliable should we expect the detected 'synonyms' for these words to be? Explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "551ea292-76ba-40de-920f-e3e528c52b31",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Q5 Student Answers:\n",
    "\n",
    "> __b)__ Given the size of the vocabulary is 269,339 the potential number of synonym pairs is 36,271,613,791 (36.3 billion).\n",
    "\n",
    "> Synonym Pairs:    \n",
    "> $C(n,r) = \\frac{n!}{r!(n-r)!} = \\frac{269,339!}{2!(269,339-2)!} = 36,271,613,791$\n",
    "\n",
    "> 1,000 Word Stripes:\n",
    "If each stipe were 1,000 words long, the total number of tuples shuffled across the network would be 36.3 trillion.  The example below illustrates my logic for this computation. The first code chunk is the result of a flatMap().  The second code chunk takes the first as input into a reduceByKey() invoking a shuffle of tuples resulting in a stripe.  \n",
    "\n",
    "```\n",
    "[('bright', [('docA', 4)]),\n",
    " ('blue', [('docA', 4)]),\n",
    " ('butterfly', [('docA', 4)]),\n",
    " ('forget', [('docA', 4)]),\n",
    " ('best', [('docB', 4)]),\n",
    " ('forget', [('docB', 4)]),\n",
    " ('bright', [('docB', 4)]),\n",
    " ('sky', [('docB', 4)]),\n",
    " ('blue', [('docC', 4)]),\n",
    " ('sky', [('docC', 4)]),\n",
    " ('bright', [('docC', 4)]),\n",
    " ('sun', [('docC', 4)]),\n",
    " ('under', [('docD', 4)]),\n",
    " ('butterfly', [('docD', 4)]),\n",
    " ('sky', [('docD', 4)]),\n",
    " ('hangs', [('docD', 4)]),\n",
    " ('forget', [('docE', 3)]),\n",
    " ('blue', [('docE', 3)]),\n",
    " ('butterfly', [('docE', 3)])]\n",
    " \n",
    " ```\n",
    ">              ||  \n",
    "             ||  \n",
    "             \\/  \n",
    "             \n",
    "```\n",
    "[('bright', [('docA', 4), ('docB', 4), ('docC', 4)]),\n",
    " ('butterfly', [('docA', 4), ('docD', 4), ('docE', 3)]),\n",
    " ('best', [('docB', 4)]),\n",
    " ('sky', [('docB', 4), ('docC', 4), ('docD', 4)]),\n",
    " ('sun', [('docC', 4)]),\n",
    " ('blue', [('docA', 4), ('docC', 4), ('docE', 3)]),\n",
    " ('forget', [('docA', 4), ('docB', 4), ('docE', 3)]),\n",
    " ('under', [('docD', 4)]),\n",
    " ('hangs', [('docD', 4)])]\n",
    "```\n",
    "\n",
    "> __c)__ The most frequent words in the corpus resulted in what is commonly referred to as stop words in synonym detection.  They are common in the English language and are of marginal importance in distinguishing words with similar semantics.  These words may add noise to the signal of true synonyms.\n",
    "\n",
    "> __d)__ The detected synonyms for the least frequent words will most likely be unreliable for two reasons.  One, several of them appear to be surnames that do not have synonyms.  Two, the small number of counts may indicate insufficient data to establish a reliable quality in synonym detection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "091af7db-444d-4aa7-bbc3-691f728d2840",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part a - write your spark job here \n",
    "def EDA1(rdd, n):\n",
    "    total, top_n, bottom_n = None, None, None\n",
    "    ############# YOUR CODE HERE ###############\n",
    "    \"\"\"\n",
    "    1. split on tab\n",
    "    2. lower and split ngram on white space, preserve remaining list\n",
    "    3. extract gram from ngram, pair with count\n",
    "    4. sum counts on key\n",
    "    \"\"\"\n",
    "    \n",
    "    # spark job\n",
    "    result = rdd.map(lambda line: line.split('\\t')) \\\n",
    "                 .map(lambda line: (line[0].lower().split(' '), line[1:])) \\\n",
    "                 .flatMap(lambda x: ((x[0][i], int(x[1][0])) for i in range(len(x[0])))) \\\n",
    "                 .reduceByKey(lambda a,b: a+b)\n",
    "    \n",
    "    total = result.count()\n",
    "    \n",
    "    top_n = result.takeOrdered(n, key = lambda x: -x[1])\n",
    "    \n",
    "    bottom_n = result.takeOrdered(n, key = lambda x: x[1])\n",
    "    \n",
    "    ############# (END) YOUR CODE ##############\n",
    "    return total, top_n, bottom_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4babf25b-06f1-4d63-86d8-a2e853f13e2c",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0.30712175369262695 seconds\n"
     ]
    }
   ],
   "source": [
    "# part a - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\n",
    "import time\n",
    "start = time.time()\n",
    "vocab_size, most_frequent, least_frequent = EDA1(testRDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "615f0416-8170-4d20-9eb1-42c5abfbeb64",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 10\n",
      "|------ Top Words ------|--- Bottom Words ----|\n",
      "         was         17 |    foolishness   1\n",
      "          of         17 |           best   4\n",
      "         the         17 |          worst   5\n",
      "          it         16 |         wisdom   5\n",
      "       times         10 |            age   8\n",
      "         age          8 |          times  10\n",
      "       worst          5 |             it  16\n",
      "      wisdom          5 |            was  17\n",
      "        best          4 |             of  17\n",
      " foolishness          1 |            the  17\n"
     ]
    }
   ],
   "source": [
    "# part a - display results (feel free to modify the formatting code if needed)\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"|------ Top Words ------|--- Bottom Words ----|\")\n",
    "for (w1, c1), (w2, c2) in zip(most_frequent, least_frequent):\n",
    "    print(f\"{w1:>12} {c1:>10} |{w2:>15} {c2:>3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf050ce9-3cc6-484c-8036-7d380d4ca0dc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Expected output for testRDD:\n",
    "<pre>\n",
    "    Vocabulary Size: 10\n",
    " ---- Top Words ----|--- Bottom Words ----\n",
    "     was         17 |    foolishness   1\n",
    "      of         17 |           best   4\n",
    "     the         17 |          worst   5\n",
    "      it         16 |         wisdom   5\n",
    "   times         10 |            age   8\n",
    "     age          8 |          times  10\n",
    "   worst          5 |             it  16\n",
    "  wisdom          5 |            was  17\n",
    "    best          4 |             of  17\n",
    "foolishness       1 |            the  17  \n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "61d1bbae-7d1d-483e-b23a-a32fef6e2264",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.390817642211914 seconds\n"
     ]
    }
   ],
   "source": [
    "# part a - run a single file, ie., a small sample (RUN THIS CELL AS IS)\n",
    "start = time.time()\n",
    "vocab_size, most_frequent, least_frequent = EDA1(f1RDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "79a6aa9a-4c42-483e-b859-9711a8bbff9f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 36353\n",
      "|---- Top Words ----|--- Bottom Words ----|\n",
      "     the   27691943 |    stakeholder  40\n",
      "      of   18590950 |          kenny  40\n",
      "      to   11601757 |         barnes  40\n",
      "      in    7470912 |         arnall  40\n",
      "       a    6926743 |     buonaparte  40\n",
      "     and    6150529 |       puzzling  40\n",
      "    that    4077421 |             hd  40\n",
      "      is    4074864 |        corisca  40\n",
      "      be    3720812 |       cristina  40\n",
      "     was    2492074 |         durban  40\n"
     ]
    }
   ],
   "source": [
    "# part a - display results (feel free to modify the formatting code if needed)\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"|---- Top Words ----|--- Bottom Words ----|\")\n",
    "for (w1, c1), (w2, c2) in zip(most_frequent, least_frequent):\n",
    "    print(f\"{w1:>8} {c1:>10} |{w2:>15} {c2:>3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7e6bd030-552b-4cbb-aafb-955cc5f2575c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Expected output for f1RDD\n",
    "<pre>\n",
    "Vocabulary Size: 36353\n",
    " ---- Top Words ----|--- Bottom Words ----\n",
    "     the   27691943 |    stakeholder  40\n",
    "      of   18590950 |          kenny  40\n",
    "      to   11601757 |         barnes  40\n",
    "      in    7470912 |         arnall  40\n",
    "       a    6926743 |     buonaparte  40\n",
    "     and    6150529 |       puzzling  40\n",
    "    that    4077421 |             hd  40\n",
    "      is    4074864 |        corisca  40\n",
    "      be    3720812 |       cristina  40\n",
    "     was    2492074 |         durban  40\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f82284a5-a9a1-49b4-b8fa-057d6ed6f368",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 530:===================================================> (183 + 4) / 190]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 257.61443614959717 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# part a - run full analysis (RUN THIS CELL AS IS)\n",
    "start = time.time()\n",
    "vocab_size, most_frequent, least_frequent = EDA1(dataRDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 369.26355481147766 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "47c705e3-8578-48ce-82ca-9cf3274ab801",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 269339\n",
      "|---- Top Words ----|--- Bottom Words ----|\n",
      "     the 5490815394 |      scholared  40\n",
      "      of 3698583299 |          porti  40\n",
      "      to 2227866570 |     foretastes  40\n",
      "      in 1421312776 |       parcival  40\n",
      "       a 1361123022 |           cras  40\n",
      "     and 1149577477 |   schwetzingen  40\n",
      "    that  802921147 |       jaworski  40\n",
      "      is  758328796 |         mildes  40\n",
      "      be  688707130 |    unmurmuring  40\n",
      "      as  492170314 |    viscerating  40\n"
     ]
    }
   ],
   "source": [
    "# part a - display results (feel free to modify the formatting code if needed)\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"|---- Top Words ----|--- Bottom Words ----|\")\n",
    "for (w1, c1), (w2, c2) in zip(most_frequent, least_frequent):\n",
    "    print(f\"{w1:>8} {c1:>10} |{w2:>15} {c2:>3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b9cd59be-634c-4cad-a6a8-209e0c777905",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Expected output for dataRDD:\n",
    "(bottom words might vary a little due to ties)\n",
    "<pre>\n",
    "Vocabulary Size: 269339\n",
    " ---- Top Words ----|--- Bottom Words ----\n",
    "     the 5490815394 |   schwetzingen  40\n",
    "      of 3698583299 |           cras  40\n",
    "      to 2227866570 |       parcival  40\n",
    "      in 1421312776 |          porti  40\n",
    "       a 1361123022 |    scribbler's  40\n",
    "     and 1149577477 |      washermen  40\n",
    "    that  802921147 |    viscerating  40\n",
    "      is  758328796 |         mildes  40\n",
    "      be  688707130 |      scholared  40\n",
    "      as  492170314 |       jaworski  40\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "81a856ad-4475-4912-9de7-fa14d6a73044",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Question 6: N-gram EDA part 2 (co-occurrences)\n",
    "\n",
    "The computational complexity of synonym analysis depends not only on the number of words, but also on the number of co-ocurrences each word has. In this question you'll take a closer look at that aspect of our data. As before, please test each job on small \"systems test\" (Dickens ngrams) file and on a single file from the Ngram dataset before running the full analysis.\n",
    "\n",
    "### Q6 Tasks:\n",
    "* __a) code:__ Write a spark job that computes:\n",
    "  * the number of unique neighbors (i.e. 5-gram co-occuring words) for each word in the vocabulary. \n",
    "  \n",
    " <pre>\n",
    "  HINT: consider all words within a five-gram to be co-occuring. In other words, a word in a single 5-gram will always have 4 neighbors\n",
    "  EXAMPLE:\n",
    "    the dog ate cat litter \n",
    "    the cat has clean litter \n",
    "    \n",
    "    Vocabulary:\n",
    "    the, dog, ate, litter, cat, has, clean\n",
    "    \n",
    "    Neighbors:\n",
    "    (the, dog) (the, ate) (the, cat) (the, littler), (dog, ate) (dog, cat) (dog, litter), (ate, cat) (ate, litter), (cat, litter)\n",
    "    (the, cat) (the, has) (the, clean) (the, litter), (cat, has) (cat, clean) (cat, litter), (has, clean) (has, litter) (clean, litter)\n",
    "    \n",
    "    Unique neighbors:\n",
    "    the 6\n",
    "    dog 4\n",
    "    ate 4\n",
    "    litter 6\n",
    "    cat 6\n",
    "    has 4\n",
    "    clean 4\n",
    " </pre>\n",
    "    \n",
    "    \n",
    "  * the top 10 words with the most \"neighbors\"\n",
    "  * the bottom 10 words with least \"neighbors\"\n",
    "  * a random sample of 1% of the words' neighbor counts     \n",
    "  __`NOTE:`__ for the last item, please return only the counts and not the words -- we'll go on to use these in a plotting function that expects a list of integers.\n",
    "\n",
    "\n",
    "* __b) short response:__ Use the provided code to plot a histogram of the sampled list from `a`. Comment on the distribution you observe. How will this distribution affect our synonym detection analysis?\n",
    "\n",
    "* __c) code + short response:__ Write a Spark Job to compare word frequencies to number of neighbors.\n",
    "    * Of the 1000 words with most neighbors, what percent are also in the list of 1000 most frequent words?\n",
    "    * Of the 1000 words with least neighbors, what percent are also in the list of 1000 least frequent words?   \n",
    "[__`NOTE:`__ _technically these lists are short enough to compare in memory on your local machine but please design your Spark job as if we were potentially comparing much larger lists._]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5c9910e4-476d-4501-998d-08d7e85444af",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Q6 Student Answers:\n",
    "\n",
    "> __b)__ The distribution of the random 1% sample from total words with less than 6,000 co-words displays a positive skew.  After digging deeper into the data, it became apparent the sample contains over 55% of words with less than ten co-words.  The positive skew coupled with half the data having few co-words may prove that features with a certain threshold of co-words are more useful than others not in the specified threshold.  Filtering for specific words could reduce computation time while having a marginal effect on the synonym detection results if not a positive impact. \n",
    "\n",
    "> __c)__  \n",
    "> f1RRD  \n",
    "87.7% of the top 1,000 words with the most neighbors are also the top 1,000 most frequent words.  \n",
    "5.1% of the bottom 1,000 words with the least neighbors are also the bottom 1,000 least frequent words.   \n",
    "\n",
    ">dataRDD  \n",
    "88.0% of the top 1,000 words with the most neighbors are also the top 1,000 most frequent words.  \n",
    "1.9% of the bottom 1,000 words with the least neighbors are also the bottom 1,000 least frequent words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7965afbc-ba04-4482-91c6-369579a412ed",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# part a - spark job\n",
    "def EDA2(rdd,n):\n",
    "    \n",
    "    top_n, bottom_n, sampled_counts = None, None, None\n",
    "    \n",
    "    ############# YOUR CODE HERE ###############\n",
    "    \"\"\"\n",
    "    1. split on tab\n",
    "    2. lower and split ngram on white space\n",
    "    3. pair combinations for words in ngrams\n",
    "    4. filter pairings - drop like grams - drop like pairings\n",
    "    5. add count to pair\n",
    "    6. extract first gram from pair, preserve count\n",
    "    7. sum counts on key\n",
    "    \"\"\"\n",
    "    # spark job\n",
    "    result = rdd.map(lambda line: line.split('\\t')) \\\n",
    "                .map(lambda line: line[0].lower().split(' ')) \\\n",
    "                .flatMap(lambda ngram:(itertools.permutations(ngram,2))) \\\n",
    "                .filter(lambda gram: gram[0] != gram[1]).distinct() \\\n",
    "                .map(lambda pair: (pair, 1)) \\\n",
    "                .map(lambda pair: (pair[0][0], pair[1])) \\\n",
    "                .reduceByKey(lambda a, b: a + b)\n",
    "    \n",
    "    # top 10 words with most neighbors\n",
    "    top_n = result.takeOrdered(n, key=lambda x: -x[1])\n",
    "    \n",
    "    # bottom 10 words with least neighbors\n",
    "    bottom_n = result.takeOrdered(n, key=lambda x: x[1])\n",
    "    \n",
    "    # random 1% sample of the words' neighbor count \n",
    "    sampled_counts = result.sample(False, 0.01, seed=1).map(lambda x: x[1]).collect()\n",
    "    \n",
    "    ############# (END) YOUR CODE ##############\n",
    "    return top_n, bottom_n, sampled_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "28365223-462e-4232-abd6-cfa2bc38af66",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0.4472999572753906 seconds\n"
     ]
    }
   ],
   "source": [
    "# part a - systems test (RUN THIS CELL AS IS)\n",
    "start = time.time()\n",
    "most_nbrs, least_nbrs, sample_counts = EDA2(testRDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 2.1621551513671875 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d387813d-7682-467e-b501-d3332ca207fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Most Co-Words ---|--- Least Co-Words ----\n",
      "         was        9 |     foolishness    4\n",
      "          of        9 |            best    5\n",
      "         the        9 |           worst    5\n",
      "          it        8 |          wisdom    5\n",
      "         age        7 |             age    7\n",
      "       times        7 |           times    7\n",
      "        best        5 |              it    8\n",
      "       worst        5 |             was    9\n",
      "      wisdom        5 |              of    9\n",
      " foolishness        4 |             the    9\n"
     ]
    }
   ],
   "source": [
    "# part a - display results (feel free to modify the formatting code if needed)\n",
    "print(\" --- Most Co-Words ---|--- Least Co-Words ----\")\n",
    "for (w1, c1), (w2, c2) in zip(most_nbrs, least_nbrs):\n",
    "    print(f\"{w1:>12} {c1:>8} |{w2:>16} {c2:>4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a002829e-8e36-40ec-bde8-1d7d8a39d104",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Expected output for testRDD:\n",
    "<pre>\n",
    " --- Most Co-Words ---|--- Least Co-Words ----\n",
    "         was        9 |     foolishness    4\n",
    "          of        9 |            best    5\n",
    "         the        9 |           worst    5\n",
    "          it        8 |          wisdom    5\n",
    "         age        7 |             age    7\n",
    "       times        7 |           times    7\n",
    "        best        5 |              it    8\n",
    "       worst        5 |             was    9\n",
    "      wisdom        5 |              of    9\n",
    " foolishness        4 |             the    9\n",
    " </pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f23d9344-a019-4985-bb5b-f98a7bf03bb6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.305120944976807 seconds\n"
     ]
    }
   ],
   "source": [
    "# part a - single file test (RUN THIS CELL AS IS)\n",
    "start = time.time()\n",
    "most_nbrs, least_nbrs, sample_counts = EDA2(f1RDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 10.43604040145874 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9722b282-a935-48c6-8a10-54a72290f639",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Most Co-Words ---|--- Least Co-Words ----\n",
      "         the    25548 |              vo    1\n",
      "          of    22496 |           pizza    2\n",
      "         and    16489 |        premiers    2\n",
      "          to    14249 |        enclaves    2\n",
      "          in    13891 |   selectiveness    2\n",
      "           a    13045 |           trill    2\n",
      "        that     8011 |      noncleaved    2\n",
      "          is     7947 |             gem    2\n",
      "        with     7552 |            hoot    2\n",
      "          by     7400 |     palpitation    2\n"
     ]
    }
   ],
   "source": [
    "# part a - display results (feel free to modify the formatting code if needed)\n",
    "print(\" --- Most Co-Words ---|--- Least Co-Words ----\")\n",
    "for (w1, c1), (w2, c2) in zip(most_nbrs, least_nbrs):\n",
    "    print(f\"{w1:>12} {c1:>8} |{w2:>16} {c2:>4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "91305880-710d-4bea-8611-be8482ff1fb6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Expected output for f1RDD:\n",
    "<pre>\n",
    " --- Most Co-Words ---|--- Least Co-Words ----\n",
    "         the    25548 |              vo    1\n",
    "          of    22496 |      noncleaved    2\n",
    "         and    16489 |        premiers    2\n",
    "          to    14249 |        enclaves    2\n",
    "          in    13891 |   selectiveness    2\n",
    "           a    13045 |           trill    2\n",
    "        that     8011 |           pizza    2\n",
    "          is     7947 |            hoot    2\n",
    "        with     7552 |     palpitation    2\n",
    "          by     7400 |            twel    2\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7c1d0769-3bbb-4c2f-886c-a6c286d1552c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1065:=================================================>  (180 + 4) / 190]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2285.4985280036926 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# part a - full data (RUN THIS CELL AS IS)\n",
    "start = time.time()\n",
    "most_nbrs, least_nbrs, sample_counts = EDA2(dataRDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 1204.2034149169922 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dd5932f9-e92a-4001-a11f-7fe9ef1441ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " --- Most Co-Words ---|--- Least Co-Words ----\n",
      "         the   164982 |          cococo    1\n",
      "          of   155708 |            inin    1\n",
      "         and   132814 |        charuhas    1\n",
      "          in   110615 |         ooooooo    1\n",
      "          to    94358 |           iiiii    1\n",
      "           a    89197 |          iiiiii    1\n",
      "          by    67266 |             cnj    1\n",
      "        with    65127 |            choh    1\n",
      "        that    61174 |             neg    1\n",
      "          as    60652 |      cococococo    1\n"
     ]
    }
   ],
   "source": [
    "# part a - display results (feel free to modify the formatting code if needed)\n",
    "print(\" --- Most Co-Words ---|--- Least Co-Words ----\")\n",
    "for (w1, c1), (w2, c2) in zip(most_nbrs, least_nbrs):\n",
    "    print(f\"{w1:>12} {c1:>8} |{w2:>16} {c2:>4}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5d6764e4-62a4-4fce-9761-9aa5ee03d30e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Expected output for dataRDD: \n",
    "(bottom words might vary a little due to ties)\n",
    "<pre>\n",
    " --- Most Co-Words ---|--- Least Co-Words ----\n",
    "         the   164982 |          cococo    1\n",
    "          of   155708 |            inin    1\n",
    "         and   132814 |        charuhas    1\n",
    "          in   110615 |         ooooooo    1\n",
    "          to    94358 |           iiiii    1\n",
    "           a    89197 |          iiiiii    1\n",
    "          by    67266 |             cnj    1\n",
    "        with    65127 |            choh    1\n",
    "        that    61174 |             neg    1\n",
    "          as    60652 |      cococococo    1\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "589e0ce5-0d5e-4d34-8948-1f907fb3d316",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__`NOTE:`__ _before running the plotting code below, make sure that the variable_ `sample_counts` _points to the list generated in_ `part a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "41df9fd4-f75a-45f3-86f9-46d207136f18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: we'll exclude the 6 words with more than 6000 nbrs in this 2629 count sample.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# part b - plot histogram (RUN THIS CELL AS IS - feel free to modify format)\n",
    "\n",
    "# removing extreme upper tail for a better visual\n",
    "counts = np.array(sample_counts)[np.array(sample_counts) < 6000]\n",
    "t = sum(np.array(sample_counts) > 6000)\n",
    "n = len(counts)\n",
    "print(\"NOTE: we'll exclude the %s words with more than 6000 nbrs in this %s count sample.\" % (t,n))\n",
    "\n",
    "# set up figure\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize = (15,5))\n",
    "\n",
    "# plot regular hist\n",
    "ax1.hist(counts, bins=50)\n",
    "ax1.set_title('Freqency of Number of Co-Words', color='0.1')\n",
    "ax1.set_facecolor('0.9')\n",
    "ax1.tick_params(axis='both', colors='0.1')\n",
    "ax1.grid(True)\n",
    "\n",
    "# plot log scale hist\n",
    "ax2.hist(counts, bins=50)\n",
    "ax2.set_title('(log)Freqency of Number of Co-Words', color='0.1')\n",
    "ax2.set_facecolor('0.9')\n",
    "ax2.tick_params(axis='both', colors='0.1')\n",
    "ax2.grid(True)\n",
    "plt.yscale('log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55.76264739444656, 19.322936477748193)"
      ]
     },
     "execution_count": 811,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(counts[counts<10])/len(counts))*100, (len(counts[counts>50])/len(counts))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "15310f55-9345-4dd1-907b-a719f475e693",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part c - spark job\n",
    "def compareRankings(rdd1, rdd2):\n",
    "    percent_overlap = None\n",
    "    ############# YOUR CODE HERE ###############\n",
    "    \n",
    "    # join like terms from neighbors and words\n",
    "    rddJoin = rdd1.join(rdd2)\n",
    "    \n",
    "    # intersection count\n",
    "    interCount = rddJoin.count()\n",
    "    \n",
    "    # total should be 1000\n",
    "    total = rdd1.count()\n",
    "    \n",
    "    # percent overlap\n",
    "    percent_overlap = (interCount/total)*100\n",
    "    \n",
    "    ############# (END) YOUR CODE ##############\n",
    "    return percent_overlap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "daa4ad30-6c4d-4622-8bd6-1a5c6f94287e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 1000 words with most neighbors, 87.7 percent are also in the list of 1000 most frequent words.\n",
      "Of the 1000 words with least neighbors, 5.1 percent are also in the list of 1000 least frequent words.\n"
     ]
    }
   ],
   "source": [
    "# part c - get lists for comparison (RUN THIS CELL AS IS...)\n",
    "# (... then change 'testRDD' to 'f1RDD'/'dataRDD' when ready)\n",
    "total, topWords, bottomWords = EDA1(f1RDD, 1000)\n",
    "topNbrs, bottomNbrs, sample_counts = EDA2(f1RDD, 1000)\n",
    "twRDD = sc.parallelize(topWords)\n",
    "bwRDD = sc.parallelize(bottomWords)\n",
    "tnRDD = sc.parallelize(topNbrs)\n",
    "bnRDD = sc.parallelize(bottomNbrs)\n",
    "top_overlap = compareRankings(tnRDD, twRDD)\n",
    "bottom_overlap = compareRankings(bnRDD,bwRDD)\n",
    "print(f\"Of the 1000 words with most neighbors, {top_overlap} percent are also in the list of 1000 most frequent words.\")\n",
    "print(f\"Of the 1000 words with least neighbors, {bottom_overlap} percent are also in the list of 1000 least frequent words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "daa4ad30-6c4d-4622-8bd6-1a5c6f94287e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of the 1000 words with most neighbors, 88.0 percent are also in the list of 1000 most frequent words.\n",
      "Of the 1000 words with least neighbors, 1.9 percent are also in the list of 1000 least frequent words.\n"
     ]
    }
   ],
   "source": [
    "# part c - get lists for comparison (RUN THIS CELL AS IS...)\n",
    "# (... then change 'testRDD' to 'f1RDD'/'dataRDD' when ready)\n",
    "total, topWords, bottomWords = EDA1(dataRDD, 1000)\n",
    "topNbrs, bottomNbrs, sample_counts = EDA2(dataRDD, 1000)\n",
    "twRDD = sc.parallelize(topWords)\n",
    "bwRDD = sc.parallelize(bottomWords)\n",
    "tnRDD = sc.parallelize(topNbrs)\n",
    "bnRDD = sc.parallelize(bottomNbrs)\n",
    "top_overlap = compareRankings(tnRDD, twRDD)\n",
    "bottom_overlap = compareRankings(bnRDD,bwRDD)\n",
    "print(f\"Of the 1000 words with most neighbors, {top_overlap} percent are also in the list of 1000 most frequent words.\")\n",
    "print(f\"Of the 1000 words with least neighbors, {bottom_overlap} percent are also in the list of 1000 least frequent words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8bda2949-b3f0-4446-8010-4f3d53bfd605",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Question 7: Basis Vocabulary & Stripes\n",
    "\n",
    "Every word that appears in our data is a potential feature for our synonym detection analysis. However as we've discussed, some are likely to be more useful than others. In this question, you'll choose a judicious subset of these words to form our 'basis vocabulary'. Practically speaking, this means that when we build our stripes, we are only going to keep track of when a term co-occurs with one of these basis words. \n",
    "\n",
    "\n",
    "### Q7 Tasks:\n",
    "* __a) multiple choice:__ Suppose we were deciding between two different basis vocabularies: the 1000 most frequent words or the 1000 least frequent words. How would this choice impact the quality of the synonyms we are able to detect? How does this choice relate to the ideas of 'overfitting' or 'underfitting' a training set?\n",
    "<pre>  \n",
    "  MULTIPLE CHOICE:\n",
    "   A. 1000 most frequent words would overfit, while 1000 least frequent words would underfit\n",
    "   B. 1000 most frequent words would underfit, while 1000 least frequent words would overfit\n",
    "  \n",
    "  BONUS: Explain your answer \n",
    "</pre>\n",
    "* __b) short response:__ If we had a much larger dataset, computing the full ordered list of words would be extremely expensive. If we need to none-the-less get an estimate of word frequency in order to decide on a basis vocabulary, what alternative strategy could we take?\n",
    "\n",
    "* __c) multiple choice:__ Run the provided spark job that does the following:\n",
    "  * tokenizes, removes stopwords and computes a word count on the ngram data\n",
    "  * subsets the top 10,000 words (these are the terms we'll consider as potential synonyms)\n",
    "  * subsets words 9,000-9,999 (this will be our 1,000 word basis vocabulary)    \n",
    "  (to put it another way - of the top 10,000 words, the bottom 1,000 form the basis vocabulary)\n",
    "  * saves the full 10K word list and the 1K basis vocabulary to file for use in `d`.  \n",
    "<pre>\n",
    "  What is another way to describe the Basis Vocabulary in machine learning terms?\n",
    "  A. Stop-words\n",
    "  B. Features\n",
    "  C. Postings\n",
    "  D. 1000-grams\n",
    "</pre>\n",
    "\n",
    "* __d) code:__ Write a spark job that builds co-occurrence stripes for the top 10K words in the ngram data using the basis vocabulary you developed in `part c`. This job/function, unlike others so far, should return an RDD (which we will then use in q8)."
   ]
  },
  {
   "attachments": {
    "9777b34a-cad2-4fa4-bb34-90ff6d67bf7c.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp8AAAC/CAYAAAC427cXAAAK32lDQ1BJQ0MgUHJvZmlsZQAASImVlwdUk8kWgOf/0xsBEiIgJfQmSCeAlNADKL2KSkgCCSXEhKCAXRZXcFUQkaau4KqIgmsBZC2IBSuKDfuCLArKuliwobI/8Ai7+85777x7zmS+c3Pnljkz/7kDACWYK5Gkw8oAZIizpOH+XszYuHgmrh8QAQTUgCMAXJ5Mwg4NDQaITM1/l/d3EVtEblmO+/r3//+rqPIFMh4AUALCSXwZLwPhNmS84kmkWQCgDiF6gyVZknG+jTBdiiSI8MA4p0zyl3FOmmC08oRNZLg3woYA4MlcrjQFALI1omdm81IQP+RQhK3FfJEY4VUIu/OEXD7CSFwwKyMjc5yHEDZF7CUAUOgIs5L+4jPlb/6TFP653BQFT9Y1IXgfkUySzs35P7fmf0tGunwqhjEyyEJpQDgyM5D9u5eWGaRgcdK8kCkW8SfsJ1goD4iaYp7MO36K+VyfIMXa9HnBU5ws8uMo/GRxIqdYIPONmGJpZrgiVrLUmz3FXOl0XHlalEIvFHAU/nOFkTFTnC2KnjfFsrSIoGkbb4VeKg9X5C8Q+3tNx/VT1J4h+0u9Io5ibZYwMkBRO3c6f4GYPe1TFqvIjS/w8Z22iVLYS7K8FLEk6aEKe0G6v0Ivy45QrM1CDuf02lDFHqZyA0OnGAQDf8AEAcAHhCOzDwibYJAlWJo1Xox3piRHKkoRZjHZyI0TMDlintUspq21rQ0A4/d38ki8DZ+4lxDj1LQuczdylN8jd6Z4WpdUCkBzAQDqD6Z1hjsAoOYD0NTOk0uzJ3Xo8R8M8mWgAjrQADrAAJgCS2CLfCVcgSfwBYEgBESCOLAQ8IAQZAApWAKWgdWgABSBzWArqAQ7QS3YBw6Cw6AZnABnwAVwBdwAd8BD0AP6wUswDN6DUQiCcBAFokEakC5kBFlAthALcod8oWAoHIqDEqEUSAzJoWXQWqgIKoEqoV1QHfQzdBw6A12CuqD7UC80CL2BPsMomAzTYW3YGJ4Ns2A2HARHwgvgFHgxnAvnwxvhcrgGPgA3wWfgK/AduAd+CY+gAIqEYqD0UJYoFsobFYKKRyWjpKgVqEJUGaoG1YBqRXWgbqF6UEOoT2gsmoZmoi3RrugAdBSah16MXoHegK5E70M3oc+hb6F70cPobxgKRgtjgXHBcDCxmBTMEkwBpgyzB3MMcx5zB9OPeY/FYhlYE6wTNgAbh03F5mE3YLdjG7Ft2C5sH3YEh8Np4CxwbrgQHBeXhSvAVeAO4E7jbuL6cR/xJLwu3hbvh4/Hi/Fr8GX4/fhT+Jv45/hRgjLBiOBCCCHwCTmETYTdhFbCdUI/YZSoQjQhuhEjianE1cRyYgPxPPER8S2JRNInOZPCSCLSKlI56RDpIqmX9ImsSjYne5MTyHLyRvJechv5PvkthUIxpnhS4ilZlI2UOspZyhPKRyWakpUSR4mvtFKpSqlJ6abSKyqBakRlUxdSc6ll1CPU69QhZYKysbK3Mld5hXKV8nHlbuURFZqKjUqISobKBpX9KpdUBlRxqsaqvqp81XzVWtWzqn00FM2A5k3j0dbSdtPO0/rpWLoJnUNPpRfRD9I76cNqqmr2atFqS9Wq1E6q9TBQDGMGh5HO2MQ4zLjL+DxDewZ7hmDG+hkNM27O+KA+U91TXaBeqN6ofkf9swZTw1cjTaNYo1njsSZa01wzTHOJ5g7N85pDM+kzXWfyZhbOPDzzgRasZa4VrpWnVat1VWtEW0fbX1uiXaF9VntIh6HjqZOqU6pzSmdQl6brrivSLdU9rfuCqcZkM9OZ5cxzzGE9Lb0APbneLr1OvVF9E/0o/TX6jfqPDYgGLINkg1KDdoNhQ13DuYbLDOsNHxgRjFhGQqNtRh1GH4xNjGOM1xk3Gw+YqJtwTHJN6k0emVJMPUwXm9aY3jbDmrHM0sy2m90wh80dzIXmVebXLWALRwuRxXaLrlmYWc6zxLNqZnVbki3ZltmW9Za9VgyrYKs1Vs1Wr2Ybzo6fXTy7Y/Y3awfrdOvd1g9tVG0CbdbYtNq8sTW35dlW2d62o9j52a20a7F7bW9hL7DfYX/PgeYw12GdQ7vDV0cnR6ljg+Ogk6FTolO1UzeLzgplbWBddMY4ezmvdD7h/MnF0SXL5bDLH66Wrmmu+10H5pjMEczZPafPTd+N67bLrced6Z7o/qN7j4eeB9ejxuOpp4En33OP53O2GTuVfYD9ysvaS+p1zOuDt4v3cu82H5SPv0+hT6evqm+Ub6XvEz99vxS/er9hfwf/PP+2AExAUEBxQDdHm8Pj1HGGA50ClweeCyIHRQRVBj0NNg+WBrfOhecGzt0y99E8o3niec0hIIQTsiXkcahJ6OLQX8KwYaFhVWHPwm3Cl4V3RNAiFkXsj3gf6RW5KfJhlGmUPKo9mhqdEF0X/SHGJ6Ykpid2duzy2CtxmnGiuJZ4XHx0/J74kfm+87fO709wSChIuLvAZMHSBZcWai5MX3hyEXURd9GRRExiTOL+xC/cEG4NdySJk1SdNMzz5m3jveR78kv5gwI3QYngebJbcknyQIpbypaUQaGHsEw4JPIWVYpepwak7kz9kBaStjdtLD0mvTEDn5GYcVysKk4Tn8vUyVya2SWxkBRIeha7LN66eFgaJN0jg2QLZC1ZdKRRuio3lX8n7812z67K/rgkesmRpSpLxUuv5pjnrM95nuuX+1MeOo+X175Mb9nqZb3L2ct3rYBWJK1oX2mwMn9l/yr/VftWE1enrb62xnpNyZp3a2PWtuZr56/K7/vO/7v6AqUCaUH3Otd1O79Hfy/6vnO93fqK9d8K+YWXi6yLyoq+bOBtuPyDzQ/lP4xtTN7Yuclx047N2M3izXeLPYr3laiU5Jb0bZm7pamUWVpY+m7roq2XyuzLdm4jbpNv6ykPLm+pMKzYXPGlUlh5p8qrqrFaq3p99Yft/O03d3juaNipvbNo5+cfRT/e2+W/q6nGuKasFlubXftsd/Tujp9YP9Xt0dxTtOfrXvHenn3h+87VOdXV7dfav6kerpfXDx5IOHDjoM/BlgbLhl2NjMaiQ+CQ/NCLnxN/vns46HD7EdaRhqNGR6uP0Y4VNkFNOU3DzcLmnpa4lq7jgcfbW11bj/1i9cveE3onqk6qndx0ingq/9TY6dzTI22StqEzKWf62he1Pzwbe/b2ubBzneeDzl+84HfhbAe74/RFt4snLrlcOn6Zdbn5iuOVpqsOV49dc7h2rNOxs+m60/WWG843WrvmdJ266XHzzC2fWxduc25fuTPvTtfdqLv3uhO6e+7x7w3cT7//+kH2g9GHqx5hHhU+Vn5c9kTrSc2vZr829jj2nOz16b36NOLpwz5e38vfZL996c9/RnlW9lz3ed2A7cCJQb/BGy/mv+h/KXk5OlTwu8rv1a9MXx39w/OPq8Oxw/2vpa/H3mx4q/F27zv7d+0joSNP3me8H/1Q+FHj475PrE8dn2M+Px9d8gX3pfyr2dfWb0HfHo1ljI1JuFLuRCuAQgacnAzAm71IfxwHAO0GAMT5k/31hECTb4IJAv+JJ3vwCUFeGrXdAETmARB8DYCKSqSlRfxTkXdBKBXRuwLYzk4x/iWyZDvbSV9kD6Q1eTw29tYUAFwxAF+Lx8ZGa8fGvtYiyT4EoC1nsq8fFx3kjbEjD5Ayjj4QDq8C/5DJnv8vNf5zBuMZ2IN/zn8CbuYdExS7aFsAAABWZVhJZk1NACoAAAAIAAGHaQAEAAAAAQAAABoAAAAAAAOShgAHAAAAEgAAAESgAgAEAAAAAQAAAp+gAwAEAAAAAQAAAL8AAAAAQVNDSUkAAABTY3JlZW5zaG90YqX+3wAAAdZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IlhNUCBDb3JlIDYuMC4wIj4KICAgPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4KICAgICAgPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIKICAgICAgICAgICAgeG1sbnM6ZXhpZj0iaHR0cDovL25zLmFkb2JlLmNvbS9leGlmLzEuMC8iPgogICAgICAgICA8ZXhpZjpQaXhlbFlEaW1lbnNpb24+MTkxPC9leGlmOlBpeGVsWURpbWVuc2lvbj4KICAgICAgICAgPGV4aWY6UGl4ZWxYRGltZW5zaW9uPjY3MTwvZXhpZjpQaXhlbFhEaW1lbnNpb24+CiAgICAgICAgIDxleGlmOlVzZXJDb21tZW50PlNjcmVlbnNob3Q8L2V4aWY6VXNlckNvbW1lbnQ+CiAgICAgIDwvcmRmOkRlc2NyaXB0aW9uPgogICA8L3JkZjpSREY+CjwveDp4bXBtZXRhPgoYclgQAABAAElEQVR4Aey9WZCdx5Xnd+6+1L5h3wiCG0hxkShSu9QttaRRz4w6NPMwY4/DM+GYJ/vJ4Rf7zU9+sB/siOlwhDtmPO12e3rUe2tvtSRKpLiKK0iQIBYCIHagCrVX3d2///luVt0qLAJILLeqMoFb357fl//Mk2fJkydTLZK1U9hNpVJ2tf1wn7bhejj3247DfXEbEYgIRAQiAhGBiEBEICKwNhCQTNiZftux7r2WHBmeTSE0uvCpzbVuVkadwuW19nVfSJ33hHNxGxGICEQEIgIRgYhARCAisHYQCALj6i/uPH+9/SAPBhlT26wy04VwcnXm4aGwDfeH+zqf7bwnXF99f+f5uB8RiAhEBCICEYGIQEQgItBdCHQKk52ync53youd+6tL0JmHrnXKiy58hpPhwetlFu7p3Dabzc7Da1pJV9wUDyICEYGIQEQgIhARiAhEBLoOgSAohg8LgqTOd17T/vVSuDfcF7bZcEEPh5Od28798AKd6zwf9jvz6Lw37MdtRCAiEBGICEQEIgIRgYhA9yMQBM7wpZ3H2g/HYRvu69zqWqeMGO69wvLZeZP2w3HY79zqBeE47F9vq2sxRQQiAhGBiEBEICIQEYgIdC8CQUjUNuzra8N+5/mwH7bXKpWuS2bUdkn41M06uXobhMvVWw21d94f9sMQfDhevfUXxD8RgYhARCAiEBGICEQEIgJdh4CEQ6XVwmQ6nb7ivO7R+XBv59Zvbv/RecmD2iplw4n2db/YKTBqPwiaV9vXc6vP61i/cM13Vv0J11edjocRgYhARCAiEBGICEQEIgJ3CIEgEK5+nc6Ha2Ff2yBs6n7tS57rPB/2r5afzun+JcunDjp/4QYJnp3Cp+4J57TtvC9cC+d0vHrfT/AnXAvHcRsRiAhEBCICEYGIQEQgInBnEZCw2Jl0HM517gehU/JbuK59nddPMuHq+zvzDfu6xycchROdW2XY+esUQBuNxpIAqnuUgkDa+Uy4Fs7pvnBOL+88r2sxRQQiAhGBiEBEICIQEYgI3H4EgqDYKZfpreF8577OSc4Lls5wrVOOC8+Fe1bnq2dCcstneDhsOwXNIFSGc9pK+AwCqJ5ZfU/IZ/U2vDRsdT2miEBEICIQEYgIRAQiAhGBO4+ABMbVKQiRV9sGK6e2uq5tJpPxLMK5zvxCHrrWma4Ydg+CZBAcg7AZzmtbr9dXCKCd17Qfng1bnVMKx50fEPcjAhGBiEBEICIQEYgIRATuLgJBUNRXBEEynAuCps53/iR4BrkvnJesF1J4PuSprc75sHu4UduQSdgPVs5g6QzHEkD10/3hF67p2fB82OqF4bz2Y4oIRAQiAhGBiEBEICIQEegOBFYLiuE4CKISNPULQqa22Wx2SbYL17QNSfcoSU5U0jXJgkvCZxAMwzYIlNpKqOwUNGu1munXKWyGe7TVM8qnGYTQ9jl/c8cf3RNTRCAiEBGICEQEIgIRgYjAnUdAAubq5MIlQqKupfn5FiFSgqOETW3DuSDvKQ/JdEHY1HHIO5wL8qWuXTHsrpPhBm07hdAgiAahUwJouL5a+PTzEj47LKPKW0n5rk5XO7f6nngcEYgIRAQiAhGBiEBEICLw0REIQmFnDp3nJCwG4dIFUY61lVwX5MJwvvO+kJ/u03XdG34hfx1r/wrhM2QeXhAEzWDR1HUlZeym1bbUrPv9mGvKOKWPleAZtu3n9KzuXZ2udm71PfE4IhARiAhEBCICEYGIQETgoyMQBMHOHDrPSb5bkuMkwyHTBZlPW/9h/cy095VPkA0ly/mz7We0r3O6HvZ1/1WH3XVTp9AZrJrKQCbXUqlk5XLZ75EYqfNu4WTLQXKsbftaOKcX6t6YIgIRgYhARCAiEBGICEQEugcBCYdKvmVfW/91nPNh+CCccl5Gx4WFBatUKkvumSEPCakhad9lxbaMuBRqSTdI6NRFbTsFUPl7aohdKZfLWbFYtMHBQT+OfyICEYGIQEQgIhARiAhEBDYuAtVq1YVPISCBNVhIlwRYzkmuDELoimF3PRQEz7DttIDqnCyf2sYUEYgIRAQiAhGBiEBEICKwsREIo+MyUkq4lMFSW1lFJS92CqBh9HuF5TOcDDAGK6gyDsKotqvvC/fHbUQgIhARiAhEBCICEYGIwMZBQDJhkBNV6iAv6nz4BTTCcTrsXG0bBE1dCxlrq+OYIgIRgYhARCAiEBGICEQENjYCkgmDwBlkxHAuIKPjIDtqu7S2e7gQMgiCp7bKrFP41LnblRYXF91EWygUbtcrYr4RgYhARCAiEBGICEQEIgK3AAHJj0FO1BB7kBd1XvJiGHYP/p565dJUpCB8hq0e6BQ8NYYfMtc9tyPpfe8cPGivv/6Gzc7O3Y5XxDwjAhsOAfnhjE+M+2zEDVf4WOCIwF1GQAaV6elp04SMmCIC6xEByW6SETt/QQDVtSBXhq0wWBI+dRAuhJu17fzdTuFThHnu/Hn7q7/+a/t3f/jv7K0Db1q9UV8y0+r7YooIRARuHoEjR4/af/qzP7PjJ04s0fjN5xKfiAhEBG4WAfG1AwcO2M9/8Qs7ffq0G3BuNo94f0Sg2xGQ7ChZsVPgDLJjuBbky7BdmnCkE0rhQuc2ZBK24d5bBYik5cuXL9vPfvYz+wd+hw8ftv0PP2x77rnHRoZHLJ/P25ULQN2qt8d8IgLrE4Fmi86g3rAf/uiH9of/7g9taGjYNm3aZL09PR4ybX2WOpYqInD3EXAeyfDjeQwqf/t3f2fvHTrkjFkhCvv7+5cWZLn7Xxq/ICLw8RFQew+Cp3LrlB9X74e3+YSjcOAE0z5Y/YCOb4fwqXxnZ2ft+PHj9vwLL9ixY8f8+DevvmpvvfUWwxUzXqjbM9AfSh63EYH1h0C91rAPPzxlL77woh3/4AN77rnn7OWXX3aa6qT19VfyWKKIwN1DIPDKarViR48dtVdeedl+85vf2AvwN/G5CtbQZtvYc/e+Mr45InDrEFCbD+1ecmI47tyGt+mc0lKcz84L4WLngyKWWy18ag0kvePsuXP28iuv2IG337YpfGP0aW+z/9KLL9vWLdtYTYkVlVhVCa/V8JlxGxGICFwTAWgVIlrA1+y5Z5+1t955x2lHwmdfb59t27bdBgb6PWbvNbOIFyICEYGPiEAKl7GGnTt33t548007ceIk++fstddft0cY0RsaGrJt27dbngVbYooIrBcEloROCtQpO3bKk6GsOnfFsLsurn5QgmfnuZDBx92SrU3PzjhR/ujHP7YjR474e5Tvh6dO2a+f/zXD7kPW29tj9zAEH0XPj4t4fH4jICC6mp+fsyNHj9j3f/hDO4G1JcXiEO+9/z5L45Zt165dtmXLZhsbHd0IcMQyRgTuKAKaqzAxcRlr56v2zDO/9LkMVSb9yff6xz/5iZVYmvprX/2qjYyM3NHvii+LCNwuBCQfBuNkiuDynTKj3qnrnVvtL1k+w8Orb9Kxr9vennzkx+2MPLeP8Ud5vX3gbfvBD37gM9wnJyddwFRUfL3zTbTGhfl5G4ZIN20aQwjt5XoUQT8G5PHRdY6ASLyGD/Xhw0ftu//5u/biyy8xy5ZVJ7IZa0BTRxFI//j/+WN78KEH7Ytf+DzWF/yp44jCOm8VsXh3EoEp+NgLLzxv3/ve35ncx2bm5iwNT7t48aLPachi8dy9Z4/19vXF+Qx3smLiu24rApLnJICm+El+07FSkBk7tzq/Yra7TiiteEjH+rUzU+ZXppbVqos2xaShmYWKNZJ3clvTFhfmbPLytFXwPwuntZVkPHF5wn7+85+jHT6DH9qU9fX0Wg+TIfohyj4ETQ3BHyT00ve/9z07dOh9Cnblm+OZiMB6RaDVbNjCzGW7NDHHMN5y42/WKjYN7VyeqSJQBqpKUJBqdopRg3/46U/t+z/4vp0+c8YKTNjLIGBm0UhnYYTvMAz/F9/9cyZDXHDBU+4vMUUEIgIfHwHNbn+fEYa/IWqLJtDKoJLP5yzHyIPSDPMbfv3rX8P3fmGXLl5KGPPHf23MISJwVxHoFCxdVuRrwrlrfdjSCkerb1gSQCV0tqW+cG71vbwFJnnR3jvwkr327nGbWlCIpIbV5s/Z0fdetVfeOGzT81Xd1v5pZhSWzTfetF/96lc2OTXls2/37bvXtm3dio9n2TZv2mz9+KfJb+1ZiPUVHLY1MaktTF/xCfFERGDdIdCs2YVT79pPfva8nbo0Y4t1iYlNu3jumD0L3Rw5N2uVOvTZUXDF9NTEhu8heJ49e9a0WENfX6+vszvQPwBN9bp2+ndYZd55+x2r1kSXiVtNRzZxNyKwsREQTTB8rpG32dlF96F2OvMIEhXcWuZtsVJfxqjN2y6NT+Au9rzPYbiApVNC5wCz2zXDfZiZ7iXo8eTJk+6LLbeYaoXYn3rXck5xLyKw9hCQYNbBR4Kx8lq8ReevavkMJb+asHlFZqIarCrpxqydP/myPfPcK3bq/IzVa4t2+cM37Dcv/theP3YJyw1mVh8xh9AQZuWTpvhnCkGRZUhiGCfsXTt3mkJRKAr+PQxL7N69yzIQr4TT1159DWZ6hpdFQg31E7frG4FUJg2djNsPf/jn9tJ7p+3cdA2lrWLvvv2S/dU//MqqGYhv1ZC5hvZee+01RgoOueK2Y9s2py2Fwdi3bx++03tR9PKMOly25379nF2enHKFTmSsX0wRgYiA+ChhympzKH8n7diRUzankTv4VrNRs7mJc3bigxN2nhEJpxv+iPdqVFCTjF577XU7g+In9zGN4Ok3ODBgW6HFPoRQ8TeFE3wb5W+WOQ9Od8ogpojAGkbgZlvwdYVP4RD8wa4QOgNIKb0yZblSn/UWemz68Ds4Vh+38+NnGd6DwA5dtr7BfisWkmEHz4cnNDT4JqGUFN9zYHDAHnzwAZ8IUSwW/Z17ED7vv+8+1xb1zOtvvEHYimPuzxak6vAJcRsRWJcIpDLWPzBso3mG6p45YAffPWdTF07ZkYNvWqV3m4305hlKl0YnhSwhfbmpKJySFDbRySP799vmzZuJ91m3hx580Pbj6zkEIxSj/MUzSeBr7ete56DrEshYqIjATSIgsrKGjR85ZK/84nk7dHbWarjBVOen7AMmEr320tt2cTGwW7bwwTkMKlL6Dh9+3xYWFmwIQ8ru3buxeg74aJ5G9Xbu3GFDw8N28dJF5jscsPMXLngowZv8unh7RKDrEAgyorY3kq4QPldnsDqj1ccSPJUKfdts/6NfsYeGG/bLH/yN/em//xP7yTPHzIaetK889YAN9OQSCwvfpTwOM7Nd4ZTyDEM89MCD9vnPf94kcEor1E8TjB5//DH79JNPutaomfBH0BY13HHlN9xIUeM9EYG1hkDGtux82P7Lf/xlm3zxJ/bLv/sz+7O/+L4dPNKwf/xP/pntHiJYfDKcIPkT/7Ip+zn+05qop+G+nTt22mc+8xkbGxtlCLFBiKVt9thjj9mTT37Kylhj3mQZ22efe9ZmZuTOcmMdxlpDMH5vROCjICCjSzpbtGK2bkffecF++LNf2bmL5+z88bfs+V+9Zkc+XLCevrIrbKIdKXByc3nuuV8RWumEz1t44IEH7JOf/CT8a9ANKtu3bbXPfuaz9vD+h13Ze+mlF51W5/DDVh6RBj9KTcVnugGB63GP0LZXt++l2e5XK8Dqm692z9K5Vtq27N1nT//uJ+2F//0/2J//bNbuf+pr9q/+1e/a7i0MpXOjvNN81RUYoeINPojQuQfN8OmnnrK99+71YULNCpTwWSjkbT9WG81074FRahhjcHDIfUU1x0IGV/qHmCIC6xIBpz0aeKYwaA99+nfs959+0f7i5e/aD54ftj/49n9n3/zEVivl0m7x1L2KAiEryiEmO2gt6V27dto3vv579vAjD9urr/7GMUojqN577734gPbbGeIOSkh95eVX7J/+k297ODPRlGTZSFbrsknFQt0UAhhBMiXbi/L2qVMH7e+e/U/2R+PvW3bifZtL7bIv/e6X7KHRfCIwQjeK6ykfT1k9tf/E44/bF77wBRsdGeXcERdOxb8efvgRRgGLzHy/YMfx/ZTb2Ve+8hWnP964NNJ4U58ab44I3G0ErqE8XU+GvK7w2VkeZXK9jJxj5QZs5+599s0v77W5nSO264mv22P7tlgZJhmS8lActAfuv9/+9b/+r21+TqGUhpm12/BQFPL/VJwoWUSHh0cZdhyyzVu24ENas/vvf5DzeRdglWPLuDdkHLcRgXWEgCwv8DRPfZu222f++R/YL96bstGFtH3j208RFaLo10RPTZ/x3vSFGB79xKM2Pztn9+7dY5/73OeYuLcJZQ46Ib8cIV4U4Lqn3GP/+Fu/D30N2+NYQnO5rA/Lp1NQlf8iVbWhj5uNjAA0U+jdDB19yY4ePGR/8sd/afnRzfZf/Df/yL702T1LyLhRhQm0itTyCehPw+xPP/20G08mJiYgKVRD8TSiTvT399kTn3zCFln9SKv57d65C9pM+zK4qWykuyVQ486aRCDIiWF7vULcsPB5vUw6r2kyw/DYmG1pbLOhTSMwtkzn5WQfrlooFjzW2cLCvDNPzdItFGaWht3z+YKVeljVCPFSBKt85RvqiefhuST9iQTrmMQ/6w6BpZadzloJJriltMcWinUb68lCJ+3itrgLYlAMz3Jvj/3+t75ln2EkQeFdxOykxGWI8amkkEuyumQZkv/KV77sTHA3AedLrB6WdBYK5xQy9kfin4jAhkYgheI2vP0Be/zeh+zEyGkrfOUb9tinv2ADcE5xH//xRz7X8q3+zj/7DiEHJ60ITZVR8uT7qYlHGQg2B03q/AiLO3z9a7/nNKcFH0SX7ncNHYsOwzyLDQ18LPy6R+CWC59QDlqehs6zrtFdTTiUFqhZ7D2EVBJh1pkMUalUnFlqyN2tNBBkgclHGorQvVqKTAKptETl6QQaZc9130BjARMEZJXMQlNZxsaXhNIOcEQKukfDfOViCWG07hMZCuyLxpQyoiGUvmwz5xEmhoaGmX3b55bRq9GpPxT/RAQ2NAK4vuR63G9zz9aylfZutuHRoRWIJPSYcv60ZfMWDxEoniYXMoU6k+ApvqaRBx1L2StjJXVLKJP/0kS1EP3GFBHYSAjccuFTQwxaTSUDQSmwdSej1L6I0LVACFEUp2OtyKKkSRIufLIv64ysNGlm/IpopTUW+GlYPpNpC5/kH1NEYP0joPaOH7RoIgvRdLR77UoRS/OTkKloEWJkdULCKLySjoPwKfrSsawsoi+ttFJAoRM9JkODkZ7Wf1uKJbxpBERf0FYuDw3yy8J/Qgp7bjBx+tJoHauMMZInXuYLPPCsrju9ofwVSxp9SIwpGtGTW4zo1w0qIeO4jQiscwRuufCZ6xm13Q99zn5ne7/14stZglg7kxgdlOcEl81kXbD0QNfcJCFTBJgQcs5KWG3EJGX1FOFKoNUzmjgRU0RgoyDQamWs1L/FPvuNL9mDM00bxt8zpSG6NgAJPWTcksJpLDUspUlg3VpdriwFZ5y6Nadhd6wuEJgV2jQl2pLPp5Q6McCYIgIRgdUIoNjl4VW9cmFBURORkUQt2hO/koIn+mL+u/Ms0Z7OS9lzgwr7uSz0B0+Tz7XcYdyogvAp+tPzzvt4PqaIwEZA4NYLn31b7J5H+F0FPRGXkggtk2a6EMKkNEoxQ2mKbqHxeyBmhFTXDiFMJ1SsqW6dCUPuV8k/nooIrDcE5AMGxVh5cId94Ts7kuIFwRNaCYxQAqiYWNg2mNRXY033jM4FukORkzAqtxcNzUuxS2PFyWBVDQxSL4h+ZwnM8W9EAGKARnK25aHH7cl8j2X33GdjxZVKmmhONJVOYyBhqxEGjeZJPZRAGmgrGc3TsHsZIRT3FwRPV/o0WshzS8JshD0isAEQuOXC541g5qQLQ/ShQllqRLgwwKD5iVdqmNGJWsP3TtjJ9RvJP94TEVgvCASFbUV5JHSGE+y7gNqmJ9GUaKkOzRiTkeRPFu7WNTFAt9IglIpJdip0iaCbWHJC9nEbEdjoCKSxWG598En/rcYi0KdoLIVBJZ1rC5LQn9xbMozUQVHO2zIImaK/xI0MwVO02OZ7S/kuEfbSmbgTEViXCNwV4TMgKTqDHzojdZpDEJWdZ/lkQrRwUyfe8FzcRgQiAssIiAGKbtwKKuFTlhQETxcsRWBOYSIrzvNzxc6VuysVusBMl3OPexGBDYyA08+Nld9pRzQGMYrOWqI1pz0xNn461vW2MUVzIkSrMUUENiICKx0yNyICscwRgXWAgLMwmJknNr57Pb4W7u0oexQ8O8CIuxGBj4CASC7QnpNfoMFV9Jbcx193q/kIL4qPRATWOALdJ3zKhBNTRCAi8PEQcO6WWDtDRhIulwXM9g3hYtxGBCICtwSBJcpa2mlnKwHUhdAOJrdKKL0lHxAziQisAQS6RvjsIMc1AFv8xIjAGkBgiajaO2KGMUUEIgK3HQFRnP+iZfO2Yx1fsDYR6A7hs60hBl65WmFcm9DGr44IdCECUQDtwkqJn7SeEYgT+dZz7cayfVQEukL4DEJnW1f8qGWJz0UEIgIRgYhARKC7EIgKX3fVR/yarkCgK4TPrkAifkREICIQEYgIRARuNQLL1pV23Ilb/YKYX0Rg7SEQhc+1V2fxiyMCN4VAGPaLnO+mYIs3RwQ+HgLu9Bl8Pz9eVvHpiMB6Q+Cuxvm8LphxFuB14YkXEwTcqCCn/iYritSq9PSNDmgY72Ld5BRBolMe7Lnj0gbajXMeNlBl36aiBuNdHEG+QYCD4OnE10omufujQjD8bjCveNuGR0DNab3RXlcKn0k4mPUG9Yann1sOgDNEOvdmo2bNy6etceKAtaqLbSKl/SBwpsoDltm8xzKb9q474r3lgMYMIwJtBNxazhKtrcVppykde4/c7pbTPUNm+XJH6K4I3W9DwAPOCz8MK9G28tvQ2uDXobdWo2qthVm2FTUaB8T/puFrpT6MKgVvS2sVqa4VPkWcCdzL27UKcvzu24SABE+WsKstzlv96GtW/4c/IrxJk45d3iSIpqmMpQc3Wfbxr1se4TPD2dCmbtMXdV22LqB33VfFD+pmBNRmWgiejcmzVj/ysjUvHee4xtmkU041zbKf+Jpldz7CcpLFKEjdZGVGwfMmAdtgt0vRkxGlOfEhfO0Va06ds1Z7JayU2Fp50LL3Pm2ZrfeZln5dq6m7hE9ADykICWEbzsdtRCAgICKtNxoInxWrT16w5pl3LdWHNpgrWKvO8HsNy011ylqXP2GpBusuQ7kprXm+kZLT1DJdbaSix7LePAJqKU3+NOtVq188ZtV3fm6NU28jjbaFTy62Kg3L94xaavSeFdaX2FffPN7xiYhAJwJOf/C0xtyk1U++bdXf/AAh9Lil8plkMaw6PKx3zArZotnIjsSlrDODNbTfVcKn+KQP96whAOOn3j0ERKgNCLVaq1kLppjK5SxdyjEciDWmzrkFbkDYbCB41upNy3dVa7/9uEVh4PZjvB7foNGEOjTVmJuy5sxFs8VJXFgwd9KgWrWmtWYqVpuesEy1YpkW5xlTiG3txlpCxOnGcNqod0n+aTQxqFQWrDE9zujDebOFcUu1sHByrVWpw/SaXLtkaWg0w7nlVevWFmpdxY6B1leFWFsQxq+9WwiotTRl+YQIjWFCxE5P6uAlmCqJmHVPnetNfEA19L6xUmoJi41V7ljaj4KAlDgJn1LqmowciOHJ6pLKJayilRIdIZjCAEVTOa6LAXqK48nXhTzCc1144kUQcH7l9Ff3UT35tKTzOUsVC5bivOizxeBdo163tGhU9Mlza1EA7ZoxyCAseAt0NGNbjAhcGwG1FxFiQ1YarJwNDbOLCYo4mfnOHz/UHxc+ZQl1K82184xXIgIbHQEpdC5YotBJqWtBX+7qKclJLittCaoGPdUQTpsIoX7PRgfueuWnW5Jw4C4/bfyud3u8tjERcJ4Gv6pDU6I90ZiES9FdKhPaT9qNCTUUP93ThN+t1dRdlk9Hf61CGb/7TiOg5iLak9+ntKgUE4xaizDLegWGCButwzBTWTRFzotJ6h/EvBa1xI+DrcodU0TgRhAQr2uipNWgKSl0Gegmi8sKKhw/6MmVvMTdpQEDlODZwhSzEenqRvDUPVdQn0COKSKwGgGnvYS26jWN6OFbLeUPK2erypid9qHHJnMX6qJDzsv4kst0jQ1xdYmue9xVwud1vzRejAisQEBCpH7IlwynN/q32Oz2T1pNswQRPFPMDtRMwOzAmKUHdvjwYPK4On4e2kBJgkFMEYHfhkDSSvjbHjVoZBjqy/VwmIP5acIRqUmYl1yKTdGF0ajYJLBc86/ghP4iTtdEKF7oREBthV8TxtbK4Oepn+YuLGpkj/8NFL183kSb7mmdEG1nDmtmv8uETyG5htFcM9W+9j+UQQj/lyasUjpfsOrYPpt8+J/a3OyMDwdmshkrFItW6huwnk27rKgYFTyRyGGr2lh7KGxjiaRrvw3EEtwmBFpQAqMF9Z5haw3tssYisQZri5APCh2jC6l+hM+BTcRbYvGGNu3cpi9Z89ku9TRLO2u+SLEAtwsBGVL8xx8itjT7Rqw+tA3lD/cXpzN4XiFljb4xazDjHevK7fqSO5Lv2v76OwJRfEm3IgArxB0mbTmEz1r/mLW2ZqyJ8KmJEukMQ+0lwlGUypbuH7Cs/GYYomjWYaKsgpRKpNCkaLqmgL1ombKYrjvLaGR83dqEu+q71PLV9sXnMlkmOfRvtvmdT1i1MGJVZt8qZTM5+GLOsgqzRIzPJNHAZLFhlu7KpLzIzBnnyisb5yjBZuOUN5b0oyKQcB64GvwonS9ZY2inLe75rFUH7iH6BK5lnM9Cl5neAcuP7CHGLiMTGFWSka2rd/JQ4Ar6Wza+JHT+Ub/1VjzXlcKnKmHdCQC3orZiHksIiODSCIrZbNYKBTFBhiMYbs8VCrjCIHxiuSkwPJEv5JE/yzDNtIeNaZx8g6DZJ9xfJmljDNEXeyxDwOzMjv2WLiCsrnGNcgkk7YiYrt4vrbgtHkQEhIDkxMDkcn1Dtrh1v1XK22xxsS18Es6syczb/OAIuhpDgnqAAPQKQt/EB7Q9tOCnU/kepFiEWBRBPxEhjghEBK6LgMgpA71k4UOZwa22kCrYwtC0VSqENeN8DporYlApDkF/OYVf4r8WgMCw0upcWpoRwRS058tL641kLHc0TSbUvNtMNkV+d9dXtKuET/HIhE+KY8YUEbg2ArKoSADNIXxaocQWiwz75d4yTFC+oAimEKuG33MQqQLMN8dPWf3NH1vj5FswzCrESf7ca4UhyyzMWa5/1LIQfKqAX9u1Xx2vRATWLQJp0Q000yKuYNF6mWbEMHuhx4rE9FSSsucKXQmaE/NTTML3nycQ/XtmWEeDbyPZWGbLHsuMbLfsnk9hyQlW0nUL3XULJgtU8u+6t8WLGxwBjbw5jeEyVhYWsnSW+j3urqIlyPIp+iv3lF0Qbc1esMp7v7YWMUEVbjBYQT3m9fAWy+561DJje30kcGpy0d46eN4+ODVJPinbf9+YPXT/JiuV7o4YeHfeusEbWCz+rUFAAib0CBPMQkxoi2xLTU2EQNHDb83/+TR4As0zEakxT9Dsy2etOTcBMTJEqNnxzBpU4OzmBCskTU8yVD9MXMOSZXyJzlvznTGXiMBaQUBKVwaiakFLLohiHSli6VTcT0WMlVU0o3i5UuzY1iszVof5Nd/6OU/Ot8MJYUSoILbu2Q/zewR3mIdQDAs8uzFUusSAslzjOl59bvlq3IsIJAhIcBRPE23lsXBqPoOMKmUUPcXelfVSfEl0J16XQRFssPRm/ZW/stalkzQymTTJyxsbQ/fb9lkT15js4E4/ff78rP3yueP2wpsfunvZP//Ww7bvnpENLHwmTggBfYBLKmBjdFOR7D4OAmo6iQCaWEHzMLeWdehTXBcdKhyFrwGP9aZF7DSPt0fgbMN3jaWQED4RTomZVl9ctFS16uFl0oqrJvNNTBGBjYQAbV6tXj7SLWa1J4yQUQMnNsiFa4EqGpyrLs6jzE0xI3fK0kX8qTXUJzG1Bq3NXrYGvyY0ZUXCxhD2bMOSVCdwG6k9xbLeMAKB30hHy0m5awufDYbTg2AqAkprQiCJlTbhWVVWHMPqucgvJ0sM/I/QaIby18QaWmEORJ0h+xz3jk/M2anTUzZ+eQHBNc1t8iNN+KOUykDXN/zBH/PGDk79MXP6iI9LOFC/dmW601Bc+QXxTHcjIEaWCKCJwrLMFpPvTtqWGKf8XVi1BStnCu3QLaJisqLyNjeUgNpi2MK3+Ma4qtjdxb/u1wkXlT9S0XVhihdXIaA2oyRmJIYnEtFQejjv9MJ5xffUKitahlOLN7hVE0uMhvvERJtZzvNPQeib3JPl/tgiHdr4JyJwTQSWhEzuyEB8csvMaD5DwuicthTcWv6bLUYjtNCDjJ1uUMnhIsMkJEtrCU4FqDcPVN+Q8gc9T88s8EvcZzIYVyBVnksMMxrlCLzwmh93iy/cdeHzmuWJXPOa0MQLywgksuOVjSUIXgnTFLMkaDa/jChSbFEb7WuH/7LsiKH68MZy9mtzT5pxWztWASiZl+NKlNZm8eJX3z4EvI1AVM7seE2I/rC67TTllkKz0uS+FAImR37ME+z4EXlIoWNpWwmoLnzqppgiAhGBayEQrJ+6ntCeqEn0KOUtGY3T8poa42swA96X2YQOl+jTGWJy5ItFiD5rVaIyZW12vuI/8TiFTFOevoxui31/y1Iu1/q8W3q+u4XPO4vFLQU2ZnZ3EVhuOong5TKmdqHhVhWmqFVbGJqA+jjFKkhcc22SbfLE3f3+j//2ZQQ+fl4xh42GQGCCooXVLSnQh5QaH01AicvqpBikJj2IAXIsJqelbrUCme69Wl4bDddY3ojAjSCwgv5gTikpe6QlGmJH0V3q0FjWmVv7opQ8jv0UfyScYv60WqZm8/OLNr/AMD3PZp1GZZCBXpvJrPkrCN3fePv+dK/wefvKHHPeiAjgpF3r32rzu5+2VnETQ4H4pEkSJWXKg5ZmUkSmZ4x4n8T6dBJfjyCtFiPWYxljmW4lAtduMWJwEiixy7Qtpa1ZFLm02CP8j0l8LSwqLP6XMMJb+VFrKK8gBCRiwxr68PipXYGA059bM5PPEW9KKCy0KB0xLF/jTiyhLQRMEVxLrmZa9parPuqHUlhhlbIKgqjyzDOej8mlPdKX0HLyhjv3tzuFzw6wO6GQmbi5OG3NqQs42V5izAdfhnZSwOPUwFZLD/FDgIgpIiAE5N+pYQuFqEizWkTlvi/b4qZHrFZh9ruGJPCFKfX2W+/Ydiv0DbcD97ZZLu2txT2aHd+c+BBL6azn6MgSCzQ9sNkyw9t9dvyV9iG/6+788WVHQxd1c59wrafaiNxcZvHudYlA0j1DV1hjUsWyzd37BZsiFmhtbprlbYk5SGMpEG83x8piueGtVs6VnA5Xt6EN09ZcAvjtPcRqPFbjtS4bUyzUTSKgVkFLYUPkalY72mTjD/8Tq18+bzVi8SY8DX9OYoHmRrdbevhey0GnGoJfZM7DIqEF5d9ZzDNjHgHUfbLll50hT5+AJG55Z1peVwqfKnowO6tm3HdIUDNTuXb8DasdftFa544h6RP42OsC4FiDOLPv05Z9+HctO7LLwxDo2ZgiAhqxyOKMXejps8LYTmv1jFgaP5gG2qCGM4oEoS/0cY2QFhJS3ZJDu2oyS1ChmeofvGb1Q88yexeFB2HVTTlp4q/teMTyj3/TMlvvR+HRLN8uShJA25+j4ZnrJdFVY/y4Nc++S5nnvW/zP8y4TPeMWnpkt2U37V1Bk9fLL15bvwiECREpLJyalJQjxq5t22/Vvu22MDtLMOwFbydNaCnVP8xoQi8Bs4sevkmouLVUfK4yZ43Dv7Tm/HS7vXFRbRZBNbvjE5bevI8ef50lyk0RVyQdNucniUF8wpqTZ3EJUjD/5CZhkWaVqfTme4kk0Od91YqH48HGQ0BNg45dPEp+m5neYavvfdoWZghEvzCPf3XFDSrFcq9Z/5AVWV5aq5U1mylG3xmGl4sMk43KLSYB0t9X33jPsgrlRKhC3Zcu91t220MYVrYs8Y/bBXJXCp+rC6uhC0noDULlNC5ApCfesgbCZ8qwfAKkm5tbRWsUB6y181FLD25j+BTL1OqM4vHGQiAQKkMQChkja0xvb68Hx5bg2UTTExEXOS/BM0/Q7BxCqjRDtbkGhNyYQqM8e9gaH75NOJlxb1eKDdpsagYiHcCexy01do+vJsFjXZmWB2qWPy+ZUJLMmmwgANROHrD66z8gLM70MoPEuptCkcvd+7SlR/d4oOIuLeJyweLebUUgGAV8RIHZuKKZIiMHWuc9XUTQ1MxaUklBsmGAuWKyyphClyn5KisQV2Nu0i4/+wM7eBqXl3zVHhs+TggZBNp8mSHEquUQPn0JXB67U5YY/8A78KeThuT4U6ePqb/3rDXpYzS60pKEyn9hkd76oGXha1lWi1JEgYD/HfjM+IpuRMDbRkIRslzmiyUrDo4y1ED7WKwgYDK5CKWwiFJYKvXA1xiBYFr7/DxWz2SiO3TWsBL9fP7kEWbLn7VaHtcYQi9pVcB032Zr5fssj9Jzu9vamhA+1QY0G1mO6w2GS6UdtppI+DnC5hCvUctKtUC2Rcw5xbRSWA9ZkW+76N6NjTN+0xIC6sSdTOntFTMtr9gStCOthKTJEPrJ8inizOqH9qc14UV0PneC9laTwqP2xopI6azamxoW2woCaG0Rzw/aIfcphJMPWHSrBLqEStjBpUCjCWjCNeI01s6ftMaxgzC+OZ9lKQbZqoMFKz+lsRTXEbhzdGq3u0MKXxe33Y2A2oGYXB7GVS4z6uSBr/NWYGa7+t0iQbK17K1oTvQmwSnQXKXasIXJGTt+4Kj96P0vI7xO230PHLVii7Ax3Fvf8kASPsZpChNCp7TW3bBc9+u8a1Df0i6QhkLVazRmJ6yO4Nn84I0kPirllYzRBNO0LFkPfIXRhx1u0Vpvgvh1AYsXr0DAOVqbHrQ8poLRF0V/WC3zBUaGGcVyukQplLFF9Jfmvhr+oJVF8S7lULdijVWOJjDkNT6wBjIUpOw8r9m7ydIPf83lJ2+pt5GfdanwmaCbQCW8sNBgZVJYgAZCgBxoRb8pQE0CYSUErVA6immVhVFmYapB276iBuOJDYGAOuowTCj/NBGiCFbr23poJRqYrJwZaXycV2gL/vMUbQ3BVGFkarQnxSnUeW9raIjW4JcmhIysp1xP0y4145Am6s+uBXBVHGHTgAFWGSptLM6hvC2g+cIOwclpToyPYfimlDrKmm0SUQ7hPKaNjUCgKa2EJOYnuimw5F9ddAUtoKH4SEO2TVeiOyiLJtW0ubmaHXjzvL3z1nl75sRn7MN6v40sZuzgxF67p3TSRktT1liY1WCWC6A8uO4SZOf9j6ybNfhUFYNKkzJbbZaRFeBDoGd2COtfYKpanMGXj0kkAJJWAP91iMe6q+DbWCDvt8lfyp+Wj9aonYRN52kuHyWjeVLixOtcWYHuKvTh89CeUibVtHJ61kqpGWQo2lUBIwMCaapCSLTqHAa8ZKEVxQK9ncaGrhQ+V9OXC6FYN6s4szeqgATIPiSzghJhpAqfg6BQJ8CqZjJrtuVtFNy9IuOf7kZAxOPMUoIls/8SokW2an/2UlvjPt9Xg3FlB0s7wmcV4bLFDMGcrOnInJ1Jw/byl9R9OZ7xlSeWMuy88w7vIwW35BbAazs/Jynh8hkP1SEndI3HQDea/egKHRZguCMCNnQk6wzXpNTlEDSi6HmH67ILX+cMSRIUtKLRAjG5Fm0jCVWWtDr5hKq9aWRBipssL8/+8oT91Y/fsfOX5mxypmoTFYb4YHA7yCuTQ8nL4FrFvuitAQPMscKS3pERTa7hJERUDv95OTij/4y516CtqguaxCDWSI1oD9cfa3C/fPQQ6OsIpyn6mXyrcAVNr2FY4qd/RAREDUEBlGKnteB17PTno3kJ3Sl7WdflYjY/W7PpKZQYUppV/fryM0wExL8YY0qKlZFS+ISiH3o+FbVH2mVOblftf/7gLf7TPcKnOp32b3UZRbyyVPmwDcRIH+WBjW0RSb4OYjBQa0KY7Xt8goVTvP6oqmLqZgS83mVpPPxra81d7uik+Wq0uux9n8cRepC+e2VdNhdnrf7+cwyJ0w6oe0/ck+LezPb9yTNYX1wAlWCla6vyuAIXtSFOqr3J+ilrunMJFJ4WFkI8umGOmgUPw2XmoCw9cuIOr78iv246obIn5llnYvpmzY5UZ5Nm67EaV9GL6kadl4RPBQqPFNVNFXpj39KmjBU3r6SkFZe8jleeSY46n1EsTxkAnLa8XYmpdbyJfdHQ4kLNDr03bv/fX75hhz6YsHOXZp2u1PYGmgv2jf7X7Mkdp21becYKLSzwtM8m/XkTQ0MTS59ksfWQhF0nfiqTFLsq/q0VKXYYTlhsBgOn+BkCPcoj4y8+10EKcBb6lCARFOj1gMlGKYOoQj/Vf9iubgtXw6LzOV3vfMbpTvQHf8yw1b0ZD3OWEIyERp2VaASLspnZBZua1mQ2sdSG9RYS4VM2T43+iYT1AvX3VRkiaG8tZsTfznR7c/+oXw4IVxUS0KJr5SFr8ssTaqlVBXLFt0JkTxVwVC/34b9Q1sOcU3XE1O0IJAoDRHL6bVv4/h+aTZ8RFSWfTRW26kwI+tac5Z78NlYBhhjabUPCUOXY61b5z/8L53WSm73aeXZgkxU+988s++g/sgyTIJy4/OINoOGMVC/mP7MJ64UBhNhhNETa1cKM+0GalphgtnuTiQANnLOT9nYDed+lW4SxJ22EUTvpUB2UmJrg87qY1SS+WjKyAG21Ctyh4VQXsNv5hAzitmsR8HplIln98PNWP/4qHEgTgah8tYU8M8p3P2FZTSTrUOpUu42Lx7n/N9a4dJyh3zm0sEThSNO/ZnZ+wjL3fMrSvURAgDZCu/cmxZ/QZyuf48cm7Xs/OmiHj43byQuzdpZfTQoOtL19pN92l+ftszPftS3FaRtBeUzPa5UV2iKWUE08coUutE2+W//Wagr011kKpyTK2STI90I1YyenR+2Z41+01xe22pOFM/aNobdse3HSjSxudFG9ta1TaxiKtVqFN/XdXrc80ZLLxDs/s/qZg/ALte+k+xUfy+z5lOUe+GLCttpN2+NxTpyy2pEXrDV+suOdCJk9w5bd/zXLju52uhOtBXoTHSY0uJJG6NY9aRBrarbCaAMWdP6JXeYZbs9yg+bKNA360001KJDVOcNKf2pywVjR8TG3bLcrhc+VEC6XtYWUX+8bs+roPqsgAMjyJYA4bZlSvzWGdiKEEmJA9uOYuh4BF3a8A8bCCKNsTpyD4V1AmFxulg1m6TVQNNIIQGmZBjR8TslkkazzTGPiDEHiuV+zaSFCJzj+NGYvM1SFiwZEhc6yTKg3gwrDDsSqsBrRE5qj91kzPwChJppimjV0m8wAzxKawl9wM/l2073QTyuTp9PpJQTVICtmzCY8TkSI5ttCwG6WBpLOrZu+O37LNRFwuuJqo4qv7rn3rX70ZfpJaEd1Cr2lskXqtmyp7Q+baYEF5zKSbbC1EU7MJ7+cfQ9L//zSc4qd3GICjG2+n5GFEfQv8uH+ziRetYBf2ftHx+2td87bq2+ftZOnp2xyLpkB399TsM1jeds8WLDt+UXblKmYlnSopYuMNCeTHuryIaW9pZ2QO3Nfq/tC5ToJ7BEDbC4zYKfqWTs8O2abUKxnCP1WzdXxx+sncL98sBNLFjtkthL36+QeL91hBFQ7gf5a+NHXjhOmT1EMED6r+MxXazmrp3psIDtm/Q/AzlDuxNPEu6SI1Ilh3jhJNJ/zR5RTUtXiYcxCT237BLHMCb2F8Crf+xttBVLqKljWq4zY6RnNam9B/01myIvM6hoN4xtSeWSqUh8z3xOf/6St3b72tszl73Al3czrHDAkCM3oaozts7nskC1umcaBdgazMrNw8XsoE0KnNDBMKB0ChaNd32jF3Mx3xHtvLQIiijC03cDUr+NMD4sFtM39Ok4Ty1VL+GWo5xSzzVto/4xIISQla0Y7/yvhm4LTNA6LugAh8aSGw/ml20F1V/HJ6xZEbUfG16wYYd+oVbY/bnPFbTY3M+X+nZoZXyTERal/0AYHtvlMefUfay/RqemjETwbCNi1rfusOTsOTdFJid6Y+NAg1FJj+B7rlYYX05pAQMxPw+KKDFI/e5wwYe9Rx7RlEQGMTJM3UwPbCc3CBBcXPBNBUmymMXURZnnQmucOo7ixNJ+qnXvqiu7QAwN8cAbygha50La3OLNVNqLXixfn7C//6oC9dPCsTU7zfmhX+eYgqH3bBuzLX+iDbzKhQZPYmvcwoW+a/hprDIwvlUPZ6eln4YY91uNqXqLo6T3KO7yP7NZPoj5aLJDSYrSmWWLEYcpsrjkMj9tqiwPCYi+CQo8LJ6kwurN+Sr9+S0Kjr83jFnb4ZRTAk1bJFGy6mrfx+T6bXui3vf1nrfQVReXR4s7JULm7N2H5bJx4m5CSx93oSKOHKKG38rhl7v+QsH57zHqG4E8Q5o0yNdpYXUtsugFHftr4ZzOrvdo/ZdVF3Nzw+2zyyzBDvsVCPRpBTiyrt7d6ukr49E5T5W2DKtz9ByMUc88zs6vUN0SlEFNOw0UKqkrnlqPTKhFuoFxGICC2XJZj72j1cExdi4B8c91nkjpcwPyfQgvMqKIl+ZHEctQUqprtKb8o9wHjGsxTjvoVmKssJ944IEYJTBI83V9TPmNabSWP9VOrEaHt3XgS08PXFCGzQAB6WYSasvxA9C4I077yhJEp0d4KCqKNpdZXe+EZteHVFqEbf+/tvRNkeIF+idas70zjVJeDZhZ3ftImBnbbzNSkz/BPgVexVLQiwkDP4DCRAqApzomkJExoG1N3IiBBsI4SVmP2ahPlLSU3CuoS7R1GRv0vED5M/sua3cp9ogzxMu7iGULWEVrMYyhrFiz1TsBbrKBMCKouQou6Xmd2u2Ze06Kg4YnxeTt+YtJ++vPD9pv3zvkQe6WC1Y48C0ye2TXaa9/8vV1YPVvIwPgP49dYq45YtfgdWyCigiYsFVB0FBqmDD2NbN1pBR6WESGMKqxtwVMUo99ycvqB/lygJE5jY99j1jp22tLnZ+x8ftDev+f3rPBwjw1vGrV+raTmlmHqQ32cKlgdY0zdhwB141F5JPBBYy2iGBydHrb/ePKbdp42PQ21NbGAln9YssfP/tz+0Vfvt/sfGLa+QeKUY5lsEHGkyYxzrC24jLFSI0Jhq6IoEriZEfZOCmWOkEpJHHPxvGu3AylsLlMh4Fbhsfpl4a8lhEvb8bhN7H3CJvDnl1ua8zrxNCzu/az2x2uTtnYbEe4u4VMFFWGtTnRycqyVhbO3p8dD5tRqPQggrFKDBUydVB7tUWE/Cvw8tpV6PmV17bpZ/ZZ4fIcRcCERZqhwRnUYocIVeaWxDVWnU4pdpok+0hIb8rfkpIdBQpvLh/rVM7QT3e+O/OSpGXsp2gcUfFMlc6EXIlV760GpUSBttSsFqJf/VQYLa0YCaL6ABbSI8EkoGQnNfHX4nJt64R262fupACzv1DdLcC5DU87cSris9CIUILQrLqMC7yuURwkrb45tmHXczWW8Q1B27Ws8diSWyTrMzyM1YDXJqW2qP5QCBoGoHYhBKqSKIhkU5LKCJbPGuRo0paFACXtqH4p+oHiwSpqx3kARLCKANhh+uDxRtb/6m7ftlQNn7OLkgs3gU1bhngyca/tw2T776e22a2evbRppWn+/wpzBU/mj0Q4pnc0RhC4Yoj5IizuIxoq0uZ7BAQRRKXT6ivWSEjwd/HaRZD3OohgX6ENKfUlAfpV5nlnu9dIgyyNutuLwIKN6/eAjNTvBwyd7rRdY1lE51LXqJx4h48j8/LyNTw/ZHx9+0l7MMm9APruEORJFTUyn7MLzR+2t98/bI/vG7Otf3WePPTIATS4m9CcihS6d/kSDTs+KOgJPg3aSUJLXBk8cNOkL9C0tlDziOfNdg7i+jOJzPTA6YD2bcb1BmdFPBjwpf0WW5SwjgIrnJQa820eBN8eVr13WW3NFAsQ1chJRepxGOtE8Q0i+JimCRcJLIWM6VsWlkjk6Kw2fdD2t4BqviafvIAIS1UQgdX5ifNLKWgssIoBSERqCZMc6Q+cphFRZWTSj1pV//DkVWsulTaIetFjZgQqHq/LLyVpJQfwZMiB/BvRvmJGpcxe7VXBsj2XIVkKYFJ3EsilLPMMUam+0tSSeWhs4fUO3pasQlU5JmEzx/VqNRoK2GL9GDxTeJdGGtf4vllGEghwCtsrpeHdjGbsN87v0PVK+IBMXLqsSJEVXqmwJnbroPzFIhE8UOl1vyqLNeQ/rA10prFi4128nQ9FqBYvnzPiczVUm7Znn3rYX3jhtZy/NuC+Z6CKDFX3bYMm+8bv32n37MhgKMig3WDWhHQmWvtoRWwm6bTGKz5ElHtLlGxQXVH27KzswP9Ge+vBuHk3wj7+JP+odRFtS7tRfKVSVBwovEhBcIyicryLAa2i0D6Wwt7fHFVwJB4HsurCHuQkE1v+tChcmfjYzV7HDMz32y9YWRugaVmxWbW/ujO1Pn7JXpj9pH2R77eS5KY8AcfDIRfuD39tjXxttWF58jjxgdSvosAE9I0k6bYsmbiSJcqdn6nZ5XBFhWHGzt2C7tg3ZlrEBGxpJDCu+QIT6efp48QHRYFjp73a2te4SPq+JJl2VKA/wxAwVVLWVA1YqwDsmd5ilonheQkFIXkE8dzsBDO/ayFsng6sRw41iTwYNIhhYsd9a01PIiqEOuUCnW2N2bc7r1d/k7UDCZANLXaq3zwVYzdRT+1AP3WAN92pxxPJiXpxsP3XNKvLrV/l+MQlZ3NXefC5uC580/qk9ucbIntqlt6+wveZb7t6FZQT8y9sfkuxTNIRLhEyGgpp0PAWsuT77vV028cgkYDFdBWWMaQ0goAbNT4Kdy3YVOVwQKou4rZqAJz9oua6of0xmUkMnnNJIRJLoX4ky0UQQbS4QcgVhdHqmZG8cbNmL739gJ2rTdmECSycTifRMH1bKscGyPfHYNrt3T8a2bNIoQRbSxRCAQCWreVlWdH5qa1LtEouL3pa0Th2LWkVrOQQyrTQW2tv6MyIkZVYv58otLgdFGH4BrDQTuSrlj/LLzUyCuzAMgnhSP/FvVyIgehJtUX8QBhPtMvbG2XusgfZXSs3b/uwhe6xw2HYXz9vQlh57uf+b9t6hi0SMbNgJ3C3+5idHrHDfBfsyfCa7gNGkwbC9GgRD4ywzBw1Du9Cih5L8bQCIlPmMFHQ+N12xqcvkxalymUl/W/oRPPusB+VGhoekfcl4J9kKgwp0q/aWMLbf9qKPfr2rhM/Q9a0ujoQAIedaMBd17IInJmx1orqWCAXsk1zo1E4XCwT6vPWUvO6WmBcluwHsk9qSgMcPgXF+6/0+A0+ao5LqO8us8kb/pqXOl1Oet/uDlQdsdtvDDNvj2yYTKY+JeaUGtzBRaJNbUzyjG/iz1GY67nXBUvlxbqm9tSlSImfCFNnyvckXdzzchbv6ZsDzLxOz177wdGWOEvg+59vigB/7E2CgTkn7KmeSg2cT/3QtAiIGFDRFa1DEAq9v6k48BWGm7rOo6f5VoaHx0o4bzKRtFZkBX5hEAK0gCKXt3FzRjs312VuLQ/Y+IwxnK0xUgMkSmxpBs8+2DsHQRgp2354e27GDESqMm7LU6Sf/e7mm5PWT9RMFZ4muAt3Q8BIq49u0T1vz9qbrHK+r9tYuPkWS/QAAQABJREFUjDZJWTWCkjB+n/FPBTW0XDTbDD7uvtyvCwI8IQIFE992bbvb6B+GcKh2Cz9aJBb0SSYXafGALIHdRwpTNkposUKpxdB3w/YQ+WHqcsHOj1dsHr9OKXRvn2rZ3uF+25YqG8H8NIWB9s9y0Ew6a+VKjFJIZGs3outArWai7xBfnJ+vsLKYFnaHZvFT6+2HJpmkq5HkPPzVreq0MR8JE715U1Nbu6FXXecrrn+pq4RP/1ShpiQEOpIIdQkL7tExeqPLnk05xLM+btOHa5Pn9DcFUacKJTrSEre2fRg68oy7Hx2Bdi15Z9hijfPW/BRaHxqaCENmFFIaP9w0zI8Wz9mkXvxC+w88Bq2LWJoNNK7+MRt/4l/azOUJW8RfU7fLit3bx/J7m7dCIBqGUyct4Uh5Y4Uc2W3nnvq37luj2XzyIxNz6xsctKHRMeqd9/NMYqW8Oi2pk/CQXe2wXUvfJwZIPMQ04Shw8PT2BnkuXfaP4I+XlLZ4ZemWb+32PfmwtjKURIWRWyAbHw4Vncl0piVtke09UVAxRoiLe2XFium2IAD2XgdYOlYk9Xvg7/2f94Errnp9+C06TdutbX7QanOEJNNEIk5J0UsXadNb9iMQMvOcqtQkPyn0WnavjtJW3foYK8gOWJVRiPGprD0zvtNemhix8abCxEhMbFlZ1s6+nH31c7vt/n1FLJ1NDVJAf8nQuSx2efZ9MhFWvSLWPbmxKM6njyZ0tB19V0hqT142lZ9vWvPty4kplG7lVmWTcCnLk34FCevgI59YFdzrBvrLNOXzDt25LxEPgV2iRawDfFZC0jVHND8Brj+rvomKUbsUkV0t+elkRIEogfZelQmp+RZxNVPWN5AmQkqfLRY2W27rmO3HNWWA6DyvvD5lJ84s2Gy1Yc+dHrSexl77nS05Gy7Bz4jw4u0Ag0qTXwaa9lXorvbujnPqOxq41dSRiSan5mxicp6rmmyUsuER+GpvMsoli7tcY0STuq7PV9kkuF6zjB3v+Ti73Sd8qjTXqNil6m5fD3RdP/+BLfzF/2yN4wfEGYUhPoKAx0zd3KNftNxT3yFA8qMeSiCS68dpLh3PtpmDhLfK27+w6vf/NwTQSYCXYEI14JuS3fO4Fb7531puzyeTDlNV25GFGKGYkzSwHobQq8OjzK5liI5JCGr8ssiVe8poagMe9kgdc+JWIetKwXo05N7caoV5hXTRCiD4StEx9zAxqMy1IsKnZmm75XzVu/UZaj/1qfO2+Mx/tNqLf86nixw4C+GmiBub3f8ly37625bdtt9jI8rHtEoHoZ/84+TzWS5BxEX5Y3WWTLl3R9JXCcvflpwuVG/cqG7IQ2Bd/IDYq6etNXlRmXgW3kkxWzJNCKbsjv3JOf8b/9xKBJrMOG9cOEaM24kV2aYUIH54h6WHtnhlrWh2qiNOiG7UNrP0f9P7vmRTww+z0hCzaGnXUsY0qWBweJiJBSP4WSaMR/loIGk+v8VODH7ZTk4+aW+eu2TvnbhslxkCbNGvSrAcLGVsmLi6n3tqlz2yv8xEIvktcg2LaZgxm0fQzBNCKXv5AqHSFmGeKIA8q0UbWkQrYcwR57NNNDQJsiv7hKWWygfp2lpPqhInHQc4lDYpWXIqqS8J5uUyQ+/gJBVeET7q545Z7SLhsDjTQEDwfgwMs9v2WZqQOFKMXUBXRjHdEgTa3RwGiRlrjJ+Cj8liuJwU7jG9ZR9aFrE2SVcgD50gefivirIwAU31wOfKvQO2sOfzdmknAiCjfH19TPjpydowNLRnZ5+98tple/Y3l2xysWXfO7fX3s3st08/1md7d0uxK1hff78Nj27CFQODiBtDEmFx+cuW9+QuU5+8YJVLp32G/MVjl+3ixJxPuy2zulEpW4Fe4a8aZm+7uLiPN+0o0N+d4GddI3x6oUPNL+N4/T3uV5zPCvE+G7MQaXMegZNKAVA8ft3noTlz0TV/VUhKkyauQ6gSpDysiBqcaz1qWvoyttLU6fglXN2Jirl+wW/91SX8KbcsmcJhqSXqdUCglRkSosP6CPbyF6sTr69GcPjG9ATWSPAX9npQQ+GXT1sNBmS7NJmIhu75JOTqwiVY0qfCmGA0aGRinJrwoslk+h4NveUQMsswS49gAEOV8KMcGMDDIR+tknqp9/IufTffI+bqs/Zw4HdrqQRW8nEO0K77IIxpFZUKE5yq4xetOX2Jofoy85XwMSXYc4WhitrR89bsP0NIrzHC0BTs0vk5Vm6ZsKMfQMzjszY23GNf/9r99tTT262EELoekrAVGTawllV++cdWP/yKNS+cpv3rCgnMLA/uT/6+lb7zP9GJUd/XoankoeSv6vRqqZ3z1S6tq3M3Un61Tf2qp9+zhf/3v7fmJQR/tV+1es6nUKhyT/+BFb/9PyLUOUUt9UfBUqi7JfApFu3A0AiDPnlfQlX0qr5L9NGLclYi/JIsblqxa36+Zic/nCFc0hl79qXjdg4fsSrKlr6lhJVzBEa5b3e/PfzgkO3ckeV5BKViJpmsJutJewhPQ+tSElt//0fWeOsZ4oZexoraLoK+nz409/V/Y8Uv/lcs0EA8Qafm5Wped23Bq+46Ne/X5WeXssH+oiuzLZTg+dNHbHrubctffMsK9RmP6qF+TEp9/nMoxJ/4muXuexpLGBEqqNMbwe1qX3Ejzy3Xztre+23lT2jPxQarvfbXtvjj/2DNmXEKzZMCShlgGCn/D9+1/C4MEleVBRIBDnEDiyPD5TxUxACyY8uAbd2ats07mEiGIFrCqKL5K3pnX1/TvjaQg5ZS9tNfX7Qp/KwPflhlO2dfzfXbU58a89npZaymPnGP/DRa4d0uzyc7Sd34J2IwWHjmT2z6xe/bIrGpJy5/wmYXvmRFjCY9l85a6hzK5Ci+MYTQW6r/dh++dJxkd1v/do3w2VlKAfDbQBDI+nm8R8WBpGOVFU2WsxQCSyuNozyjtx5zC9Nzk5mamZwcuVVpV+auvJpY7urnDxPk9S2j1jiTJNVvemSPZR/8nGX7NyfaZri4DrYiACVtm8Ql03rpzfNHAUQ6eDK0nMJtIc3yerm9nwJfgpIjhNTBvEa4Fv3k4gBFIXwmk3JajXkXCHHIZKUhcGe2n4YLAva+5X0SJt3XhBrXbFkxxPA9qib5PYnQ5BelZ7zm9BzHJQRMMb3g76kvlXUgsfwkflS6X7/AmJMwGAo/0bC5BQj87IwtTtJhNAZhtv02SfzBDy9vtaOXNtmxd4Zt/BenbT51xiqUV77k+jb++3tGeot2z71D9tjjhERRoPvk63hbl6WkevkoR6K9vfo3qmwKMq9wSy3izaVahP4oIbT0s7yoBHwsaBrCbWCZW1SsyBTCBPV2rbJ7Xcothvs9IoFTbfvdWHFEr4YvExXcrehdHagbPOvQQyeGQtdkxaFEqe14GEFDMYtptK48qX3K6lwh3p9VZplnAA0i3DmDUXQHYm3W5+cIaVRlgkoSgWCJpgKs0IvcWZBUnRY0cUUjA95woQ9dk6VN8TbnULImJyv23K9P2A9/9j4TH1hpjEYgmivkZenM2pOPjNijD5dtaIhRCo/HieBJnmVmYpeheUWCkG+nW4VoYjIIeNtJ445Tpt/tQTEjPzoKlNSK1WGqCxgLSkSlkDX1Wm2nA6U1uStqUwrkF46Ts8lf79OokwztYBga6ykhvIMVHg82hZVqMIWwM0BfpiD89J/NC0mMVsWPpMPC+kk1i2jJY3XSadV5qw5/ZAi21ZAVr+M+GQSYVS/3jI6zq7NZ08fe/wgD4t26UcVBaReJfS3LncI9TNEWxD9Ee+JrjRl8npssR9mnxU1Ax7Hk/HnibU5NEHsTJUDuZK57d6JHntxbY5Lf2TPwPupSFu0H799qu3enbNs2rJh9gx7GTk/JXayqeNXwsS98lucg01+8cIkh+Doz4eftRz87a0O4ke3axWgeRhjNSJfBJdB84GuhkjQiV2NlstoC8ZpbNZthdaxZjEYN2sdga8HGoMFUpeguikt8Njx8h7ddKXzeEAY0HM0sE6OUAJrhOGFfakLt5PcwZCFGKuJDgGipsYTrHVu6dauxqkf9nV9Y/T3WVl2comEldzYXiSW67X4c8dEyH/qKDwEnmVwtp45M19CuLIeKuadhvuprf2+tD1/HgozJAjB9dh2dY3byDMvr7UWI17JcSay+On6eWrNZdr8VaNDYPU+YpChKFkm3QHZi0u4w9ZwrDgxZSHgM9afz3jm3rZ16VNf8HFsJmVnlodifSyl5mqqHsPHnZNtSO9H3cjCPVjl+ac6tmCc/nLTD75+2c4e32PzsN6yK1abexEpUK9lCo2CL+LhpSTK1DTFPfb++U9s8276yHLblg8odvDB829KndMlOB0Usf5EASr54+Zzvia5Up9LcFHKHu8DYOzvVjdcPA4FcU+BxWboUnUCd7NVSi7ZRv/Sh1Y8+b82Lx7iF0QVP3E90g+z2Ryyn9cJZScrxa19dDxtHmD/ySW9++JbVDv0KzFBq5ZrSTmmU2fxn/xUCPjFkRYPUSw06VLxNV8po4xp1oQJ4gpqkLcu3WZPskiHzRHRbjb5ud8uo3E6omwbt2oVPchFNzM7W7dChC/abN87Y0ZOX7RSzbS8SRkn12INAOIhl8949Q1g7i1htsjY4qFW98NskuLwmEOnXy+IEhRIjDC4E0/u2v7GBz3aybKCKyvdzXZda7fXlRZd1DAZ52lkSHo9OecMm1Zz6FmYi98iajGDBLJO5BYQGlA752CLOeJsJNKgFBFIIJyl4Whb6ksKfYL8MoivJHGrluOrJg9ZgCL8x8QGCC3FY/ZU8g2tRessDloWnyeV7ZQe+nNda3VMX5zggjNU/eIWVu96EF7GAgspPYVtqf/diULrnSQK6s6wkD8hYJfpr0UbVb0o4T7X5IEIEzyIsogBmwF6rAon3ZBktC0k0LGun8phkqFvdYh4lbsu2Xhsahmf0lXBVURxbDGT8q1M/CyjequNevucTxPq8PFWzA4embGaxbpemF+yXz5+yvfeMEk2C+qKhdHQfK6pMPFnhANV3SNkU/zo/P2yXFka9vH35SRtm0lOKFbQaXA/CZ/j2O71dRu1Ov/kq7wsEc+NUQDXTWESMWvabluC5Ol9t5y/BSZq4ArOqsr3dta+Fjd7rq9jMTlrj8hmI9CyzzLBSSOPhf+vyos8a1bqrGRpIq5WIWkkjDrms7W0S8F1MYR5fF9ZYnwIDtHAh6oSIgOG4VNGcZAHznxghDZ4fka+uSMJejVwEEXDXbSv2VVltIN1quRpUjsP9vNTv9Vex74Sot7Kvc+G8Vr2amlz039xsFWfrBbvEb3axyvBDHatCxaY5vogQepY4a5OTfVg2ewignbwpeaOsqGLgKSsiaPaivQ4OlG2Adan7mC1YZshxCMvnrl3qEMTQuV/fsvr7da4LU4LYlR8mDN2qTeebkRuKMA8p7LJ11wh1YE534YaV26RN4fQ+edZqDN83Tr9NR849ygdFQ8yPxmPpTff6MqZL9bwymzV95MwIa0P99EGrvfdcInzSphxWcEgP7LDM4/8UDlUGFv6JgXifxhKUukntXw2MbRKCDIVK98C0NLkujdTgMQHb7U59mQQR/4dMF0YBVBf6V0eZOnt62l5/65y9fuCcHSK+4HnoYB5hRha3bWM9tnNrDy4lOduzo9d2YKnp6ZH7i2bHEvqH0QYJnh4YnWH9AgKSRiEycES9U8qorEf6Js3U9e/X9+j729+oGIgaPlY745M2dGrXlNdTmQDgHlyfephfyNgsmNeLCJ/uR7iMpZYWTqEcpunnVK/XSjImzDLLefzd0zZ58D2zy8dt28BZlAv6bawwaeoz8wDWdYTPRMRdbxRIOWmLTSbD1lhfvf7ur1z4VJtUu2uhJOUyWH033wf9EcqIc275RHiTvOCMR8KemzehHvmPkCTcFdTxCfpV8Psp6kQWzakpjQyJdlK2aazgCy30MNwu1zIp7aq7GkYZp1fuE5/ctqXBKEONSbdNO3Jixi7P1Owoq4e98upZ27NrxDZvxgCm5GXgbdq2k94tmpIxTsJvBfex8/NMFEQAVRvqy83YUGGcuob2xL/vMv11lfAZQBSeIsobSlTgEv1hFWhRaRou1rJxHnAc0L2hUTNL963KWOd1u7QQWRUkRaTQ8PVziQIBRh23VtrRGuNpKi6rBrmOkqyC3mhlqQSQdAHc6Azl19JCaEshjEjSQN5Ac4LBgZkzNDViWf4418KnhEPHm+UUkNxUN9cG3mu4TTzcRZ787SCmJXg5v2R903389JqF+arNzbLMJkHmF3n3HN9ZYTu/UGPIY8bOMaQ+Mb5gp89OeTDfiVlCx9AZhfdqSz/vTL7AeQXXzqWqCJsL+OlUmA3MEFjfsJXw0Rkj/MXO7cO2C7+3LVuJY8hM3yKMuMzym5otKEJukZnnTb7dmYRykhAFHCNp5UPDJbfoJlfEmBhNwFrnK914/XFFgijPOPC+Jy27rT1zOgg9SR5JE1CbqtPB1yZZL/7sB2ZMDDQEdmXT8vZB+2J2dX2B9b15j1PU1eo/ZLrWtmq3bQw0eah5jvKniLWJMuMz2aGpBsxFs9FTfWPAwrAqzwh/WS6Kel5lpl16Q20fi3FoHWjPI7ljCRkX8jjnQo0aI3jyGD7MuJhMLdpZLJwvvXLKfvqro3YCuhBdyYI61Fe0raNFe+LhUXvkwUGULFn5NdOWuJswyhLt3Cfwse8TirDc+BAgVrdkIgx1SlnlmyKFM6tv1sfz8iQUGQftU+pjly0v3U0xS8De4I6K7IliifU4+J0n25fDJqkiLJ8I8AODWiZaI0TG+t8Zm4Y2kR+SelYlqo9hKzcjYShetJR1yLC9lUHgxPFJO3j4on343EW7eBB/fEZ0Ht3csPuLc7a5jJ++RnWKo0534mmKerFeUgJXYslsEgmnceYDfkfBEBcEAQxwrbl5S48dtswc1sC+LU4LUqo1kifF24O2kJHzN2XYRtvbLu074W2rENP9YKmFAsaZYS7ayCN8jm1iSU0pF66w4abCaIayTBYrkYuYjpNnH9nPpCTmEGhU7cD7Uwigi/az547BfwbsM0z0Gx3tQUmRkLKSdvSFLnwieErxWCCKzKnFQTtf6Ufpb1k/czKGC0wE1EK6oTxeyFVluEOH3SN8OhgdpV6Ja8eFVbs0pBYVWhne5RqJiLKJAKrHMyyNmB7YCYExQYKKulaWaiyyCMiPilpr39e+WzVKUqU2EG4yCKhZOlgXSpNLa/6vkxfEVMGXr8LM8TyEJ6KRgOLFBwpvo2BTxfKpVVEkLEjSbIF/A5+1xR6IlyHFllYYIqVSPWZ9OyxFjMEE+TaQ10DLn+ogJt2tc4tYKmdmkjhlswS11vJ90uokbJ47N2cn0Qovnp+1S5fn7MPzECo+ZQt8X5KfvoO388sx1uQ+bDDNvKw4dOz5AvHXCL6dn52yPpysegnq25+7bJtKp21T/6SVduywxt6n0YwHXQDVeta5HCtQ5CWItUnH89fHJuVmr3uT6gsJQCFbPjw1bX/yp28RGSBv3/n2ftuCRl3Cv0+CjzpBWQBQsWj4aP4VaCqNFq86Zx6aKx6U0q2fnmci7HQWPORRob3U5GfEsxkNKSLkaKhKCo2UQ/fBle8a9NXplrEG0Ows7lX3haGWABbNaJhU453pnhLCJzgQPkeWF83rW8CPNkWbVhNyBiQhQ4KacJIyja+eCzKcZ6yPOkxwcwpR+B34UNLgk89weuN0g35K1pdjxyfs3fcv2TvvXrA33zlrp5lBrTi5A0xwGRwo2Eh/niX+Bu2xTwzZIH6d+g65yciyWmCCk4LDa9UhCZ3yy5b/tSZLSDAVbSmpp2i5qZN9yg0Pp0xckFY/h+8ct7nCwSnOJJYXCU8q6LrqTMFBdAIebVTa+2xICVrJfudfZHjN/4AeaSa0k0lcvcZzdavkieJBnyzdz11b6P/ULrTMsCxlUvBCSt4ry1zDXn71lP3nPztgP3/9RNtyvsuFq7/98DH7auGS/Ys9P7CR9GXrRYFcJMZkhrqjSayjJMFT9McQtHzUMRzJmJQuYGmk7UpREn51xVSVBVTXpRTyT+cl6GdkzMKQIbrVeQ87x1Z6s2BfRn4ZNpcTaP8L5HkRnqQ+rYAQWdYEPUYJRFNJXNcE7LTc2Xiv/LBVv6ITTRbcf3/ORoif29+Xt+dfQ4GAx/2f//cr9saB8/aNr91nn3x8K0s/40rTkbxtQU+yjKu7maml7QwKxTh5l+hfBihjjnp2mtWL/AH/05HLndvtDuFTxEptuubshHuDAACgh/EY2mZTT/0LqzDjenGeCTP4Q2liUamXmFlj2613eAy3IybMyMx1laRGlPiOInhSSVo3Vf4gvmqOnuGb1ElKI9JwVwiCfpWs1uQpCSPuP0v5tOSel18YiHGIxLQFA79H1mGIS1iqESsWZm3n4zZJQN2FadwWaPjS5kRMhdHt1rflQUJNLPdqq2vAcZe1EsFyBivQFD4ucwsILLxfhDw+vmjHmV1+Cv/Mk2cm0QIrNquguTwjKcirVEN+ZCwviTw7YwiWKJkIm8xRL6WtiLWtxOzeQdwIRoeYOMHweV8/w4n9CD2tSzYPYS/yHrd8N5lYk3rAZvEBqg9vteLQZhivNE3WOMfhW8xYy495gF6sQJp9qLIGPMQAAkPuusaABCPBQML7z396zP7+hWM2ObuIK0LNnqQz+9QT22xkBOFQHS0zGebHHrRmBWtcHisJbUPnM8x6zhDKykb2YjFLfM3CrM8VZff2Iv8jfM6gxxzHV9pVRGfJPRnamE8+Wd1Aug7EG/sg9SlifrKALML8cuCQJBVQV9X3q19p2SJrpeepE5U/pGahz2a3POqRGLxf1AUaeFaT+obvgR+285Em0IGZ8qugLEjoPHFqyq2cP/vlUTty6jIKBHO7YLzDLIG5c0vZHrxnwB68b5ChPK3pLOEDJY1+UisSiUlqQoXavX5Zn+gAnXGPhvKDy4vep/drJZW0W87oQ6HHheG9uDBNY10ixqj6Uu5LE6YpS1D6xtB2LDEQqH94x8eHwq+rbVLXXiQVdXVxOZaiL4FEK0IV+WEosznoYpyZzhMD99LvzDMio7rDCr0ZAWlMoZZYSEP+iN4OBC+jDNDQJNbtV14/bf/r//Eru4DFrECb6WfiV5+hPKYrdry2zX5RYXGOQ9+w3xt73p5YwDLHBLASvru0xvZnrv7ItVchapbiRRqtrCIIyvdcznLLiT6OAy1B20BBzNAvSpny5syz1cEd1hx+wOrIFOozldTms5tR0DG2tGH38yv/gCL3y5g1y2iDjF4lCZbUryblrZgsJJoQLXGPG3twZ0mqIGkP2+Fj3/xdPZOyZ166YBepzx89c9jew1XmX//LJ+zLX7zHo07o/a5waoc8m5miXcrvtCOU+1Jj2GrQ4ybCKw0P9FqNJTXTfZvh2+113a9okMrkzqTuED4/SllpOWoAWgqqWCxbdWQHHtsjWN/kDIw/DJWa10xMGGUJC6g604RQ1eVf2Qeo0hp0nor1CHvF5CbLhMw8/JcFgvMY490y9FE+t/ufkcVL1i7QgVBSaE0tBEKnBll6QUUYhA7K423CiGQBKQyMEMPsU8ximHNhwq00spJoQgKxBnXvIpr8vAQNGOMcYV0007wCc54H53ncGk4T5kVWzENHLzL5YQrNEa2fzrQhAVOk5fXNzHgYqA8TKiwJIWDy/LJZlA3Wmy7MnLM+6n0zmubW/haa46wNbiYW4f33WW7vvVibEmFaHbWGrjS0uTBPIPqhXfgfsiISx5SatqNYiDiGE+C+h7ZTwkenR8OOzMRX6KdkuJFvoVPxyRby21FDAabADLqpvkOdaUhXwr5++/eP2L2vD9rbdGR/+ZN37J0jF/B/nbVvfeM+GxiAAognN/XA12x2++dwY5gHJ83UJuyOsGBZNv1G1amCd0gryi5BVzRFncsPMCMLl+B3yw1fJIVGS3rStmRB9YgFjmE7P1X4Gk/C3f0zaVcZyqhlLeU/LRzFoJi/4PvCyC3OAohiS5FpDu+0C5/9t6ylftGZpxqXBJQy8QGHWHRhBNwThESbeo8mEVXt3IVZrNpTbuV89sXj9t4HhBCDaHqYzOJ+ylg6H71v2D79hPzHpDyoUlj5RIKm+3Ni4ZSFRm0bq1Bq/oKlJme5g7qU4Akty9iaZaQp3UOoFr7JU7u69O0K33R5/zdtetMnrYpgI+FbAqj8RAdGNnkZelDofJIh+a3vBDDqFyhkG6IVxdU5WaEl+GjovQfrXBHs51oVuzxyn5157AmrDiVKXgEe1jvQz/D8sPViIhWNIpd4/jXa19sHL9iBd8/b//XHL9s0k1XKjPDsHMvYA4tHbG/1AybbXrQ/q33LLqRG7bV0rxVndlv60qh9iigMTfrRFss6ej92tQ9d8dXdf+DtFXqT/7/6ee/7oTOZLaXMudIE0fgkWwTQAvwA8dDrSEL+7J7P2GRuk80ws70uMyJ8KIew3zfI6ACyhiyWSwJfUgWq5qQvoy7Uxy7wrrzCkYkXIlssCZltS7/6S32Htr7YAM8rcoT6gxa011yYsd76Ofv8vZdt5jTuMocJicbEwUMnxu3f/+mr0FnaPvfZ3bQFLKDUmd7vCbo8NfJ5eym7x84aURHoaHq2QddPPmnz941ZYcsODAjDLiOFR+7GtquETzWYJQCvh4aIGbATjTHtnWZZDI7KKOCnJyuNC58aMmo790pIUsd5bZ5GQywMIMBuIv7ckLuG0AJ4Cf9xuG8SkLmF/x8ZX+/Lbt211UDcbIew+vnwZdfIxwUHhCjDItHqH0bjG3TGqcfEH1pYPupoTEz1dwLV/W594byG5GqEVJH1w5e61Lt5SCsXzS9AhMTSnGEG38T4vF0gVuax4+N2HEvMJQ2j0zkkw5OJtlglhIVPSKBXLajO6AhcO9Sn8e0aPi/xTlkwd7JG7egmgtCXpi2HT2H+zR/6/ZqJTlQty0wxrN7qt/oQxL37MV8OUM7jst6oasUk5WuTg9mWYJDu78uni8n7bN4+YiEidCqgvcJcyMczo5Ay4OQdCfkks99dPPYOQHh1a0o6ZA3VNW3rjqJ9+dM77czFOR8eOon/39/8/SHbvrXfnn5qiytrWv3CfcvoeIWpOkoNHclhPoS5co3dicorfanoTssCWT81IGYaNVkvHA2EUzCBOufBuUl9SJhR3v7jXZ2d+lKGa3Yn6dOalDXFJI8GSheNx8uqif8tBITOTklllyCSlz8xipusp1m5A9Ezqt2VUehEb7JEii7U6GowOfk+H3zvov3smWN24PB5m2AEQW4qOYSKHtwdNuPXu2d7H6sRyXc5bwN9YngIPYQyEx3ofSWtv05bz0LjDOpa+vJZaxz4kTVPvcV34PfNv+RbsZZ94d9Y4cEvUoe4EfjX6Ut0WRMsEKDIq8as3gx9cFq0hfIhobaI0OQTlhgxcOHTu9OVbYdsNkwSpv7P65LZ0AzZFBFAG4Q4Q12hLhi1gafJKp4Hyz6UvjJ1pcUzghVNI0Rnzs7ad//mHTtIBAOtFa4VdTYP5u0rT5Vs6MSEDVw46aG+PlP6jf3t/O/jPZO3AzN7rDQ9gvCJW4cEMn4+tL+u0Ecxgy81cVdp4EebYsGENLOTUaEsDVlpT32Yt2u2LgQi5Ltv5uAmq2FF9FEf+qcMdFHox6CCEiWlO4x2dcKlPkz9q36KsFKCv5ShP+cX6gdXUEtCL3rGBVDlST8hQ1mBfrA2fcZSB39qpXPH7dFW0c7lH7Tji6NWRfA9hZL5tz8+xDKdvfbwQ2PQXFACaU2UYwF3nQncNRYRrOluMCjkbJC+vdivME9a7jZRMFX0u5W6Svi8URBaHQxKHbK09hLDRh7zUVYEKl1DP96p0hFqiFRWKlXKtZI74LLqRmX7ozafxTyNE7K0IjUahRNJs7RVClO8NB7vL6+V0cc4r0bok6Xaw1RLkri+m4YpXzFn5LzjWmVRN66hTNQ1cfTlr1HR23kkK/ksX3J64I8LEiWG+/Y8bZUihKfhCvIQk1Og6jzhpnqIzSerjQRGOaLpVfKc1DBthQZ/ebzBbPJFhnMrNjN3yRbx60OedN9NMcMZfDLHCemiGehzPoTPN/JtKo86Ps24leafJ65dkQ53ZLCHCTGaZU495GHEXM+jZGj2+XCfYg3KQsO3k3c2y2owCvbuPnV8nyy2KK0ZfA4VgzCvYUvKofI4fpRNzF2uBvqp3ehjnPmjgWoykToatS/NTnSfNwkR+lbdqa3vCOruF5qWmgPl1AzM/Q/02aOHRuyFA1VboJLOXpqxv//VMSxiJdtNXDkJCWoTyfAr7UlCqFvImO0MHooVqesOBnXg26VmpWN+spbLhWFwK0P4swiaSZukm8UvgvBC/azUkk0EmCQDnrnFyelKltcrktrcjVGz5yGCXAKxMzO1g3Z5O09rX6fBoNK/zXID2xEAwMDvEb2x07cVXxHKz/P6+YgCNpgCM5G1UpcExCptU0lYF7F2FbTKCf0eOjZD7DV8n2ftVUImvabZ60cvsVb0DAqc6irjs9fvv6ffdmP5GGP99a1bFOpFowXQjaz49I2qR7VzTSiSUCtLqU8wnL1orTOHrXX6EP0SfYHKyMfLd7NxP+Gz9szT5zJpTPTkX6iy0u9CI2XyazX7rVrC9cX7ERRH3lVGKHXXFdqPP6c81SRCBu181ssmae3XKY3KDQah/gcV65MQbuoLtdhFvcHoHViWcXeRQNSD4ldGAJVCLJ6mpOHd7//oPXvjnTO+ko26vVEmRH7mkwQ2Z4JRbp52VBu07Ezdttuc9c8wCsU7x63XTi720h/XbXiIh25bHSSCbVLR/sntP4FudHi9l0sx5ZbkT/vZ5Y14vTBcncJcjrlawS4s7qacWOBpi72FBRssz9lInolGZSyBCJh6v+pAClELJbEELdQQ1FK0WckBerf4r0Z8pFipjauOloV1fSM/chJPrLVH7cRL+sqauNsuq7qbVZ+qa96/+PsTf+osvrjZuXHLXvjACpeO2bZGyR4vw8fqe+zD2k6brvbYu4cv2T/gUqOJSVu39CZD8HzD3FzTzp2vEd0F3sZxH4LmJoTUgaEB+GU/fA03MvpxV155591K3Sl8/hZAqMakMaiyqNwCAqavqtHCaqfOkX+CVIFjdT1oKNqqklXZq5MsajkEzIUc3jGbHmYIaw5/EGa3c+//z96bNkl6XQd6N7P2fa/e9250N4AGCIAASZAUBVIaUQpKYys0tkNhez74k/+D/4Qj/GHCDkdMOEYjT4jyaBkNGQJJkRRBgiAAYUcvaPS+d1dX1561ZPp5zs23Oqu6CmiQAFEN1O3Oyjff5b53Oeeec8/arQQMZqSLXWmzSM+9n0QxEPfCudcI8v4SEGw/LLTXPozuTM0PfTk1aS9FH9YqgZ9cWLp8Ii28+0IEjL8L6ezc+gZS8+GvYLdy0MFZHgeHQxtZmayFroE0ffAbaXz48ZBYWmcLSKfUohdi2LTUmSbOT0cYowkYvgnsUManZtMEC+D4OGGNsJ00jNE4kpexOzN4beJwAYMXI8aLnIMIYM3C2QdSdhE7sJPFtpf4Z/2DqJ3YRLRxjwilg9AoWYSGsFMxRlozzj5ciqIkRQQ3DV2FmIVOfBhyw3yWmaOytqeoS0pIljQ0b2bB6OV9EtmwE6aigAM6aF2qpF1gLMFsQ5Alylk6qlqskJz7XNy2/CczJss/N+zBcrPpgBLN0e2t6fe/vhUTiMV09spEuj4+nf7pl+/DhDSlP//TR/Dqh1FgvIqdvM8rKfYj86L0xTH3/GreswSTGZsZmJPq0J40feRbaX7kKGpYw4/IiIBHxLZsHtkNfuFxy7nlBbqYi9UD/euOLJu56p2rME0G2a4X6tZmzk0l4uwMn8W1tb5Vg7Ehrc1M0FmQsyjARQmcKXeiNaE4FkVxnYr1B2ZxevfTaRLpRSVsIIVj4RkJ+yAJClCTxW/GMgiCZj8+yxjLaITNZKxpnGPsywSOHrtFCJb3r2OiMoEz0Y306huXkWJPhgREnNJzfd+u7nQUSedD+3vI56x9oGsfWgHwXAIaRFTmkzqDCeVYYhrmGTqZTd3G9IYNncG28XwP5hNcriFRqZARDO9E1Hd9tCwz8PY9B6dHDciaqe2odndu8Kg0pDoKApTYRVD6dWCnGL/PwrdrdTAl9bXlnj4F3LuxYI1HC7BzB2kUB1CnY+OOtQsaI6Nq9KWhYeYLXAwb3FY2hSG1VruU0t9/72T6f//mDVTtbMChFQOkP/29r46kL30RQcLUZFrccSzNdW9Ni7eRpE01pX2sd286rayxV1iz33zrdnroodG8/DUC8D2N/fVOVMG7qnAkV9ZQSoQ3KnfpkCrz2HBh1aGrcs3IGoRMkkY2Fm2HS+Beo/2r18U9adGbb11Pp05NpPdP7YAhG2DDVk3drXh9d06m4c6JtOMWzjuz+AAowKANEY+ataFMpsQy49OJg6CxdWlB0GE332oI5DmWhRi+UPLBzkzp8eSUNteasLGvBMfNhBdEwzWnPt8+0lgKnsQ1M+gPDEBzZSJ1kOzGYPepZT49PXAnbWm+nt6emEivLz6Wrk6U0t//4ES6iUbx0L7BdPTQMIHs+9LJU5OEURtD62hEjJR2bGlPjxwego4OkChiACaV1NOhPclmBnGTDfstlw3IfDLJDEIxGeuNR4TeYWS9T8bTRU8QyX88cKLzZPvLsh7jKYFQamoMLuvpgKh2oa5S3O5i7EQZ4061q0yYBDcamav9jf/aLhf8pbmpVHnzR2nhe/87OmHDPDkSQjUAue9JbCu3IH3dnj3NudI4RnmBY0Hhkbkzr6f57/0fWK2T2hIpoW1VWtE0tIMdMxKJwT0QNggv52P3FgAPAUIa0Q7GVMgvuzTXnm5fRUo5NoNnOUbZvG+pdAv7M+y5QGoDtd+eIJamzCef2fpYWV9GIBhI5qUPe5ReHH56yU+rd163MTLJmNOOBX03RLIHZrEbpr4PCecI9kkdnaplQWLnj38e2bcYBxYpvevDfoZulSGIkGMWJOx8YTC7CT/RTFy8MkxrGYlrWWILI1XlPSWIeC/pM5Ue5EXD4c3voJIoAT8c+VMizeX4eDFgySu0JZoTz3olX8tHG/RvvWMy/rGwifXYMWsPtWd/W/rOt7ZixN5FYOPx9PaZW+n7PzmFAL6avv2tA+nQgUFMG5CcOBiUPL954yL8WN+aeOU1OEqz6ywMbEvz7QNpfpTMNjCfNkdJshKwtk4+5DoWh5fhuf6ueOFv+EfGeen866ny8j+QQhUCWC/BiBFntPV3/20q41hWVpoI8V+r2N7F8atp4eW/JVbpaYgRmx1gwTrgzFPTY99KLY//fhjxx0bXa9zhsRKSNm3Stx1I09gVz0wj+YQIO27B8JGzuR31upscz/nx2cIzNtt/gQUAnXbTlwgh9tqb59O7791K7757I12C+ZzAAc8A8Hu296V9xObcNtqWdmCOsm8vG7dh1hHGU4bVNU6JdTCeMDLOQWzYeGdWgaueBPdZK7TTrcnZiIngVglCbJ9rZaSw2Gwv4PBXRqXXGqpasbWOoeCNOwlTb7qehCqX9xcw4sY9/nHOTbXItDzv1PF5K46Fc57Hn832tjYYBKXRJTb4s9jv4sT5zAi8PFIrcEUbc8fL8TR24/e+dyL93//hV2kSCXgXG+1BIhd848uj6Xd/Zwj6hZ0iG/F5MupUFg6xVpOmk8/h/oV08odIARn+W3hkv/Hu1fSn1SOBl8K6c/lxFOuqktlr8f1/IXHJ96FBMo53a2/esi+1gjvloV2R6WwtOLAONXlLV0+n+defT0vXz7mw5OZBJ0xO0Xrsm6lp96NRh2NpuXT5TvovqKV//LOzhBSbjIxBILiowF6KFM4wnLUbW9OOyfZ0fPZcevaLVdTXo2k7zH/EWmU9cnNoJJ1Y76lTlXiAt4KI+nviopVamA+Z21tkobp2mcxwnLaurVswP/GZ2GCI31yw0uK5/HSugvMKQ8LjnjMKYMoIZsps2IyY8RB2u6NIQPvLW9MrU4fT2Vvz6Xs/PZV+9qtWcH+A9XoYR8PxdPLCGGtKOe0c6U1feHg4PQTzOTg0iPq9j7VCbZ7mY4yVsMR76j1oaMknf7iBmM8As9zjNSZl9VDEYDlwTJZAGx9vumcUM5Ja5VrALRB43kVY5lJi4eQsstPSEUJi2xwpHllMAUaJBMtFvKZ49+q2fZTf9jo7gpDPecFYoiBUN2o4PNN4GVe5A29kmW3tIWUiWyB6Sp4auxqjB9BWuD6vbR27szLEtQSz7LM1HHusr4KkcG5yhlrxwsX+ZZwF7jqhV66jCp/ANrMCgJv95Pr12XTt6iQBqKfCuzy8drElQh4SiJcZGcfG9GHNaRvM3UBfR4j+27scQ5xTCGas0Xs/4XUGer0mk4l0s5s6iAEK3QokFA+J6ssfGNzIlkPfAlEdb5nNTKjFZnf8LagxPZaIz+AI00wommbsWHq4V4ZTezUdKXyHbqKL2tUxp7GJYMea4SXDQywE8eYP/hOLPaO2DGcffPuGuurwWgpmyN19k3DMuCpV27tvgRA7fWnPDmKW/rScXscJ6fs/ew+YmElPPbaNhXknKUS3xsbMrF/+YyQC/tbCAc+FJI/3yOx4pw4sneDPfBebH9oiHklIleSIbyGN5rww7XU/jfDNz49UwPpYG0wwsXD65TT/8t8hOYH5pB1RMUxjbQmp7kHyY7OxbGnaGsQmk667rxI2jR62cPNiWvjV/5fjlXoT6wRXUm38Dm3Hc3v/02gWlCAqYcwtd3GXwYwXUo82y3NstmTwvMU5MIJCJ2Y9wXwGzHOBl/qszK3ZgG7cmEvndSI6cSO9ZVaiVy+lMbQNLTCE7cD2/p39SD560pH93enA3t40MKRkmrdSn1E+Au4ZZ9ui5Eam0+MCh/12TbNUkepK+HTSMLJHE2012H3WttAJB4T/ehGXccjMpkkyzZmJirmP+uwgFUKQG2fSfvN4nlvqCiECvz8XJeDC8VhZ8ghBg8CXDqJzDPe1hkZoHBOl89cn2Vyo1clzJ1wYrUKhwM9fvJD+3b9/KY2jdZLxfOaxwXRgT1f62ldxnsTGuh2nzIzjSp+XWIO7MHtCkFKeTg/tmE8XYTxvoaG6Qizkyxem0r6HjEDw8RTn2I+pVCsnXkrz//yXtAUaxPphqUFbl4iEkrCrbO5E8h80VpivX/dp//NRVb5w8d208NLfgH8noGm0k9tqbH5K3aS77uxNLTgBNfWSyYfndWD9yT+fTX/z/eOYEk0zdqW0mw307h0ycUiTJ4gKMDEfYfnGkCL+7Q/GCEF2PR2D+Xz0kS0wa1vTwYMDoZEDSaO9/hFHatIV8Coaxrsa4dfQZgqsrl6dSJdgAL3PeJyjJG0IIU/gRb26ej+XK+fA8VLY4lxZT00nKPqpLwsLFBeh77RnAOHN07smUz9mS6+dKacTRIMxYskb2Hq/8u6V6G8ftHY/cUGfODqUngAu+vp72cCgwYUvWGY8fbm4vUZbvPRJl7sj+0m/6X7qd/T9fITy4QPHwprhec1aC+CJXQArthIe1a0SL5nCWJYFGs4HQQD5cyPzuTUr/Qgnw8M8djqGZZkPiUOb7xDom1ApcK0GY6YEQWceY5IpUQqCobSIfy74SngktHOkPJTBLIEIC5ghzC4OYB9CzvIJJJbV7nTn55U0d5psK4RGmiK0kRLMSyDLdZlMVOQLEmXq1L4v95l+0/dWJIj9hCeSkeztwwapG6cI6GorwWs7QAzPq17oxZu2uwd1RScMsswf9dABPtRLjuEqmZPmbxFUm3/uHp0bj1uGd6dWJFAtdUakIGbuNl2Us7Q5SwhCSsAz2mk6X7UK8dTwTG/rG4TeMUZIb3XuSNinVruGUMsMxPM+F9JOX0rxvcUisnrKBMN8V77y4XC2uoYN+Fs4dkfPoigToorOwdLTvH9wnnBUTekPEraZdP5NbAdfO3ElIg+ceu9m+tOZh9NXn90T0mxxVMYosKM+lo29LcbKb9WsznOo6dkIaSscUMs1NxLaGLoYerz8XGNlv+4xbZTJMzyanqc1NpYl0nmWkRAKdBKupQnsKcGpZjZ12jg2Ca+MUWMRt7g1e7wCh6XuTjZ14CZ9QawTY7doqDI2bm3mMQ/JVH3d4D0Bt1Qo3DkG2ltZp/8cl5B+0v8s+RUcaQPFzFwnYDbfPH41ncfT9X2cRt4lYPg0m8M26tmNs932USSbeELv2dGVjhxQtc588h7+8z7VtdoKZptBnYBkdt1c+8nMbWAAb8t44FoYRS058xRMMutICSmnhDDmnXESQLye22p7/eRnV86h7clVLv+lf94TT9jW5Quf8YNibNfpZgg5mJ8SEup9u4ex0RsLu/lxTJvefXcM04nh2KQIyy+/cjm98saV9L3nT6QxYqi28dxXnxpJv/OVkbRllI0cmymjcwhrCk4iKD143tNj5BcTSkymZ56upJmXSTU8ORs2wy//y6V08PBgzHkky/gNJibgm3leBE7moUczCFWmymTZAW/aUa21E7u0jJNTFYbZOLhV/BOa2QQLswX8CCAFDS4y9tTUOg5h3mKsXPDU/Oq49ISDahW62CxukBzlNNqbXxDndIywfE1s0HaMdKZnnxhJjx6W+ayl27eRTmL/eQvm/sq1xXTm4lS6RkSHyz+bTC+9cSk9emgLoee2pm/+zv60A22CuCmgOoUyoFHq8+kw2V9xZZG+VDB9uEhIwHMXx8Ax1j98F4bR6LkJ8EPD4/G7GJOrK05KuzLuccBN3u3YSM7kFWB/OcP6zdgdYrMwvLOP9Lct6dYdfC2mammCPjUjcNm9sys9jLnNnj2dpPaUXmPnyXqQN7l5cpfHuqEJv83DjcV8/jZ7Xn9XATxOhB5wTD2T7ELLbrNoTwnCBSBlZilPnAC3evLyYlw8lL9X37PyKr9EMt4lwLnbUZoXkB43xsV8xPvcEUFJEeZBtHnG+JwuRnOGK0IVNkN8zLCzvAJSTvWn6cWeNDa/Nd2Y2pIuj/eni/Md6cZlMh+U34meFosEVdmIYAA6EPMrbWwDuJWsKLhppe86AZnveddWjNi396ah0aw+b2nOwbEdm2CIYUpUh0ts3fk5btEfomnXlsj4cPktwnuc5R7HE+IDYyoet7d8I7Vt35NaIJZKNr0u4RZh4z4ZJVBfhA51Hb9kShfbCMmEWrM2uDUt7HwkHMXcNMS72SFXMVNIAzvDjjTXlZGfx+nyvXPoeUue5Xz8wP91vaqXzPg5pjAgLIy1Kos3Eq4YL3q9e081ffmJrSzGpCQlN7Hw9Kt3rgSsb8Fbcv+uPlR5bgasaf3i2AoT4lOkXmROtWGMueHJ+todc5znGWLCM5YPxZm468P/WJ2SOVXIwrfvzG3OjLO4p4SPm7BlVtIAIjAujcU7ZZi9z4xPxVBaT3FspidjxDaDn6rMmjBpiBfxQu+zf4EffNtH77E45mG7J0xz7zxM3vSMSRXmIkbnj350Ov30l2fSFAyfeG4f+jBRGepvTwfwXH8UVdrWUcwryVjTVLmYardwyJORhRnRIaW9iexcOE+2IV2VgOZ3sYFjXhrH+F48sGcw1DAxtVZzzuOQIQfO6RJewyUY2ZrmO8UkRm/u80/9mTwP9/nMA3ybI1nASQF9a3Un1suYlzKMQ18aHe5MZ2BiXNf/BWeypx7fmnowX7p8dSb91x+cwsb3UuT9dh53jXakrz87CiwYg9hNh45JmdF0cxdhvWCOhAnhGYE9TEk19Z9kjQcmxzGfeh9JnQyUn3IkC/jNZkiYEvduk8r49NVSunZnW1qcIWg6KuOR9pm0tXSHNvI+8KpF3HKDuBL1YuCCLoJfStoNlyQ5sWXROv7k90A/lYJyzxztV+189tJt8JasPmgVjhzoJ2tXFwkV3DctwZTjoLONTWRTd7p0Hh8D1rNTF0swbzjEIkV+8Y2L6STaH9fIr35pN848Sgw1i+G9dfiNcWQoa5ElArtaUm/LfM5id3392vV0PfK6K8jCjK9DXI8WL0ND8eteWMjQUmVtqBp5BjxbmmUOTfbBOTewLS3YyhNGEqKctpEVa3h4mHWjGRvXWrqKWU478XT3HehMI8OYDyIBzTaqhgh0Hcprje+9F+/vbc0neeZzz3w6uAKUU17FmaA6S0w7AapOIARz7UpSCxAEkFrWmrQau7eqBEwiUS/Waxy8kqo40WUZAIs76t8SK4i0hFnkt35+xCLhsU1ZRAJRqUAk2UmWjY8YTFsVFQIxMsnVfOXyRLpG6rxzLFjXztbSzM2nyd0DQYNwzOPtN7vUluYAXkOXVkk9EkgUTZLJE46znWsHNipDhDHaOtqbRrbgCNQLQWO3qPRT4O1CbdgBcGOux3Myg44JiBGYmZEsM+kyOPljv2s6309g73blvVS+ehyhLtccD/rmwtM2RED3R7+O46+x63zOukU46mcxlFDHXDRiLdCr5KiZxbYyfDCNHfkjTAomgpmS0dG+s9VEA0hVY9HiWec5VIi8u1hIOPXZLY6xnY7i4OUBdLqaYAirqGD16o/546R2oAf319LvTO5MP33pLJmjsinGm8QB/U/ffTP9T//940hXjH2KJC3mp171qq/GsXW8I/8499QxKO5WChuLob+4J1pme+vFTZnnGzpQv8I9zp9PNNxfPOe3j4k7agMkcCExyCcZDp6LeuGpwFnzOKtZyP/yCC0PGXW5IZT5xIokNyW+4wXRZiVLS6wZsXHU6FpQtfCOWAM8pJ3Ce/GoFcUYcUJ1XQXEvHFzJr13+nZ6462r6dXjV4jZORkqVdcFmf1ucO/Q7oH01BeQcA1DWLuRJBE8uunG6ZTe/yV4NBeMp8HKAy92PJSau76DSnILOEWzQALxwNK4hhVzVb+UxxYJ3GL3trQ0cpg1TS0Dzlq01TnX/myJOKTtEMb1xj+/ZfNvjHXM+vpD5bgHnAjTrHM6Vw4j0dZkaQqnkdOXxtPxE3g+Myff+9HJ9Mqbl8LeXlrRD0w897VRtE7ZJyHCxrHuRUxi6E4L86UkUwbUtdQwTRWk/9041AwgTOjj+VskmrgN4zXDxqcFqVlsLG0U+JfRRKhtLPW1c13cy3Ssgo3y26em039+pQ2nmC+AA0rdF9M24jL/Xvf76cneychP78bGPPWtrSvfI4zSbJjYLJiJWMHeYqNCm+a3OC7jCW3keHxsNp05Mw4jWQnThQNILvdvx9Mb7/+2dsYhns3jbY927qqlb/aNpJG3OmjrbdT0M2kGOqtE+a+//266dW0mffO5A2nv/r7wWRC3CrwNR1UcgpZOv5gqb/8oHGtnb2PKdmFrukNOdQUo7eCti4S0MAQnsWI0juW9x9ZvEPglIoTURg8SDhm7XdYImWm9HKod/UiAd2eHTTeZjFsHfevtrqUtSHlV0/f26sOifbfXDc1VOEjl9+W18953/zbPbBzmcxmo6kTotzgKvnqJQLtz//yXANJrLBUSvXoDAOzmR59NLbseTqW9z+CYgBS0AekygmCA/+o/YBD94/pD9S+BiCw/bd/+X2G28OxbeXX5V0g+YcBCwgLxmp8jHiDAViPPuPVX5lvS9ZnedP5f8CA/dQpbTTL8sChNgSTT2HpMwIBOg2wGmRbpZkmXtlDblYE+1OeMKbHNzJzRCwNtWr0+vcvJdDI8Qoq9/hqSR4zTQRSNrDtZnIw3192TbTfzYEi4MiJlU4W8AMm0FGrxLOHJUrFANhlvxkA+enGGsExlttyVO0htJ0EQpckMgWo8Mry0zN2KOJx6QSulkdl1mJfH2h+U/DcOqQeVBEjV6S6QhXm2CZWmge6RQlEJalbUDDCzrWt2omsAAEAASURBVKgcWlVpWWdU0lhLruuz/FemKrpt7/2fv4KR0LHFoqmJC5QjVC5PpS8/1QSB2pXePn4b55bbELvZ9Dx2oJPA3jOPbk9HDo+mo4+MRNir5TmKmu7+CXXfDA4TYxfRI+M5jWTAtd+JLxFeqNw7ktLgdmy4mDdOZ7jKz/u7Ss736u0rYVaxPPMQxLLe5f14qUeWjnvnMuoSi7lXbYHSE8CfCtkcYhMdAxCbROKYcq1QS0bb8uuDqEU91OE9pqxr5oYIVs1GsyYsWwdfwnfh1R3S04LFFt6stAHucp2ZqEpYZ5FsvUXKvBdeOpcuwGxexwzmOjH8bpAXWg1ED0z+FkKN7drelQ7s605bR1rT9q1oB0jxStOw5aZvt86n5jMvhgmMqfxc1Jsgzi1z2J0d+iJE8OFoUcA/bQkCXPSz/m27HMk8/+AfeFga3JHmDn49TQ8+FFElvEHJqk6Lndv3sRbWs6Q4nwLVZll7BAQBrhSfe26qw4drplJrJVePHd2CzfUSMVuvh0PnP5DZ5gVUye8RYNzEHK6RA0i1/ui57enJx4dgNjrrMYmxFyUqicHKXZdLM2S2Gr8SkQtKSP1aUFW3Tk6lrumFdHRnLxKz0fSTV8/iCT6dTh5HvU/yiRZEkMImYUQwTbkeeBuND1BmfcDGstwzEh7mq/sibBndQIntScx1vosn/qvnWP+rW7jVlaiUzlDP2ERXutN9M30FOtYBDWjmhWvDJfUB6MbMNB+CGgryZWaGGoYT7IR3RfvGmm+KzIs4Gr11/Boe5/OYo3QzNr3p8EMwn2gLjAGuGVdsNKOdS4w1YaYGMTuCET+4vwvzlhmev5Uu3phJ75/HlhLJ7fFzN9MeND7PPrE7Pf2l7dAbhEnQLp2LqpMEoX/z+VR57fk0y8nrY/Tr9lfSbHWQzQP2nvg62O8QxDjPH4QmXAuhC20sd/bAeB4i2UBrmhm/heCJNYeawnSGBA0dmKi19hoo3rlijYv1jMUoaQ+roKju0IkvhJJPHaWNMgGmxiw0hqvkoU+lbBzm0+47uvXiIvihxYWdgS+I6937eRpEztzN3bPrHcHnpflpYuMdfylVj/8YG0HkMzAvTmIV55ySOzKQvbrtURZedhC0zcU2iBuUZwmpxcKJf4YB/c88K0dFsS9qqvoPpfTsv0ktAzBCihgttNtdqzsZEVVHoklsey5fqqXTN4+lq5PYpMBQqkKAjUoVFoOpUn+6c+5Omq6+E7H99ECfB+lsY9gy8loBVwegHozWuzjuQmLZiVq6q3OWuJhzqYu4mN1IQfoGCbeA3Yzhjfq03ySjZDjnFOwxdTr67sLzOGbGM+wv6YPvc2ELNR4AHUAtEyrS8O3YBLJx7IIyzyIxj1RmgTEtw9y2siNrImet86PdjmE0jP8YTAIvdocY9ThWjcX5pm6H1jFUpd+CdID0RHwbMoa+4xEqwyFSakuobaO2b6qjHJ94lD/3AV1x72fhz1qLesxtjDUSYhcm5kbP2EIFXiphF/YE3tO7WtMjD3WlH/98LJ3Bs/qHPztDJpVraScq+Ge/uCv93jcOph078VYvJAL1AXOOqkQhqLz/Slr81V+jEr7iDi9gQy9djHtT094vpJYv/xmxQI4G5DknttVn3ZDNn341zb/wVzj1XBW4c83MbdNWzDO+9KepZf8XYVxRnwETaxbhhc8CqmNk+6mMViNlAZ4YTOIEzDJoRw3nDF+6Zi3Wzf9aU2taJN1hafEmPCyL/YzSXNpkeLeijqKN9cZEffW22ZTAdVTr169Pp/OE0jn9Pnac799IZyByZ86P54DQ1KGdmA4SjxE8+uABI0XgtIcTyuCA80S7qbOJ9mSGD6egpiViFVYIm4p6HXwosSaWIFalBTQN2H9Ll0ANUSfjDgfRtoZBK35bp7itU1IHXtKLSMeXSOVooHinTTVuG3DSzbvCUQycz6Y1DZVtHq4aASGa4gSsKsJ7nse87rkBnC23pkOHulnnCR4OyXgDW9/zMFXvV8djs7cfad6uLdj0HelMjx/LjGe39pyYVzhvGZ/xWwD/5sG9xfdfS9UbF4BhnJUAhhqMIat+Orrv62lm34H0k1ea0gWkqz9nA7R7P7bzwBCUKS298YO08MJ/ik3OMvCwTjeN7kpt3/xfUgt4e2+PcOiB8Xvp5Yvp+R+fTq+RcUm1+v7FidTdPJFulHvS9XJ/elNfhHO9afLt7vTVndW0vQc6zlg4UqvrlGFV+reE+Vt5FpohUVSogkR+ic3ZErigvGhqcj7so3XSUpCyh03ant2daZQsd4ZLVMOjRsCXhDaDtaQCXM/OzaTRrfNEhmhLe3d1kle9M527UEXzcyFdQhL64msX0itvXU4vY/7w8M+G0r/+g0fS4aP9ub1EryixtlUJATXb0p9+dv4r6VYJhy+0dQpxHtoPDkHH89SLd6t7dxcgvOJ9bkDU2i0NjKYl1q7mIRyEaae0WFrrHHfhuGkSECO/qBnRcXR5o819RprwPvFVnkXhgniax3f9NtxtzSd/tLGYz4/QXwG1OnkzLb73IrHoiDnHrAmkbtnKOJk0738q579lIV2v1Mkck4Z0EQB031Bm0kuIrCO8CJOodMFc7qba1OuuScYGALAoqdQJaBFpkMAhF1cahJixSvvcIt7kS0vNaW7sNovGMDYhIAhM5Q0kGxKf89im3JzIYn6zUuhkcBux/QQhFAz6LVNsm+yWdjhYOEKkUS8AREpE+tnhbh3uSaMj3amnT09JdpAQocXKLO+ew8Gnwv3ZuaQT9Uon2Rl6BgkyS0gp7X+CYYNpKJhKGTaZkmAu6WMwkyBxMJO2gU8wnYyLjKf3+9HJIqtqZFa5zwbXF1rHSGJpar4FFoxch/3hHooEDVIZOzfjqrYz1nGF7zyn0f24t6gzrjvf3CND76s0rM/hsroCGYudpu2TsYr25Zrrf3OVn9+/jmJeCmOemThhLKTwSihxDtOUZDspGIf6u4G1JghJX/o5jgnX8JK9NjaFFGYMx4fL6dmndqZvPXcICYKelNbjxgyhtrgxxsJ88S0AHxwF1pgocMX65duw1SV2JmARuaudCw7j2UXwaf7a+bR44fVUmrvOBtDNCvUiJa9VbqV0gHSuOx9lblH9Co91eLKOogjLwnZl15Pp1jOYntxBCqu0hMbZ5+6B/tQ5fIDIED3hiCVgBGzVYS9GCAB1BakSIP7Gk3+eZm9eY7NoukjWAdrTQezYjl2HITRIg+r4U0CsqUOFf9cXCfKrr1xKP3/5fDqPg592dmOoCMfAf9vZQWiivUM9aff2/rSfWH07tteQcnYShSATDe8J5yzxlk2VKtS8+cXBAGahE4fAJu3SNPFROqQ0hA5oRqFKUycE2yXDXDA7xTg1fntNqZp2nRIrj1XVanYgvjluEjKdF2RCQ5UoAlrq45Z/bP7NIyBEN5T6UBVnGuci4NUxB03aiWl8YDeRRNq0s25LJ06OY04EjCCd20t2sqH+ljSCjWc7m23jNvb09jAf9dBZ4JjM2IJweuEtwoO9nZZuX0LTAG2DoJTRjjVPs4HYeZBg6zvDLnIMO+NTZJ2bwEmnDVgSKZcunki1Uz9JcG7gLUwbsIxhMuZTF1J68o9T2n4kcqIXAgex16QHZ8/CyMJ8vvjapcC1XfgHPLUXRqjaliYAyrPQuBOXyuk8GYf+66vQvHQhfeN3mtIXn0SDpTqrgCcGyeHSE35xy+F0+/H/Dlp6LWBawY0b3vbegdSx8yHgsA2P/Yl0AqmlTjdboImPHtmK+Zghqoy00hOhFIVdF5lg2KTf0Jy22fZIH1whNXdz0zxjSbxVXAX2MP6vvDKN8+UtHHpm02nGx43iSfq3H5vrR4iNurXpZjo0w3ixCT0+tTc9XyGWcTN0Ggagt2UhHdgPU2g2N0t0Jh+u91ftogxmO45T0tpIqYr00vXG5zP+yVAasUI7VIRijEXwQ3QszCuo3PuyiUwWCLlWFVqY9d792z7/wDGfDnJ8sLFavHI6VV76O1Rz58K2MgZPotC/A2qGFAAv53I9e8iaAysQMmHuggwxVGJX6GKQSfJdSDHOWGTAAfFauac5iLTebT63kCowemWy+2iHWZknCPtMZ5omltiNO53pGumwbv3NhbTQNkEYpFqo2SbJAHSD0EY3+UxOV+oe5uIcxAERhYTU9SOCrbP4qwIf7O/EFkg7Dj3otNFsihiZA6jO+wlx1I7EtRVVXCkRcxNkmJ4psxCYIcNz1IcY3lSRHaS30+NRwqEoXiCWeZRBCwcI3p0DiSvRkI1kkPAmTwYJHjvPGLED85/XJO49Q8RYe5xnjBvKmLkj9Zt7xHLHxMKsYTvmN7+V2MJEeE/kunY3LpPKt4jUWPLTjWfuHi/PFYu13tfGMgQjAz7iLseTg0A8jr1f2Mntu1vP5/3I+Yz/fGlX1XTyR6mZdKXNEi8kdW649mJn3LZtL4HDR9OZc7Ok5MRbFE/ZF1+7SKxJbI1R2x0m0PFhAh3v29PPxkZPcqM3uFkDlpQ4SNRganwX4vy86QCHmlCFyxx5usBviYL4BWASoxWiqbc6sKkIr8Q545AugLOpTQc8n/QjfOWjgA3xCLhuQkW1hHR8fnIaYpOd+lQft+GB0NxHWzFgjjbmKqigOLBGiQBwRDDs6q7HUqV/Cgc/xgVmDBRAgt+duvrrdXCf/JcSTh2EzhIC5czZ20STmEyXcUB479StdAJHhinttrnXege68G4mJMqu3TgS9ZAGc7grbd1KRi9SwpokQ4ZWKUaWhsDwoU71WNWh41sJIkNdNDlg3RGwERa+ZRqb1A7pzSEuNnYt37X8t8ANx5k3c2+2E1NaJBPt6DquErXsOe8akOfNShrNJpYr3TwImLyfYXD80vi1lE6+mNKVs5hNzKYR7Ca7QIOBrvm0tP3JtONwLxFFkGSBX8bQ7cBBMzKxCRfAQsEIaiZipAfNRGowaW7eyggdtK9vZiqb5vA057ubMHm7t/Smd85fS7fHCel19k6gKNWxThPWT7wjkolpl4P5VPIIc7Qg3rKpEubq0MZRidB9c+lFJIanzhDkHLMwfQQOHsT55QBxSPA96IAGtpJMZI715AzOr1fZyP78tSvQrzbMSfrTnr1EJmnAPw8jIQEhmarEuq4MTUJj8ZQH/mW+mhHAlPiwaqUr19EmsCGexRRtgJBjO3aaGc/g/HykdeCNTJnooXMxCgO+GZsaGy2YR0gtqSuh4ax7xps+ROiyNujayNbmdPXGLPbYU+kCYQmPv3+TNXCMzfedNNA+n7Yt7iF4fysOvdvTHQa3GVrUWZtNh0vXWVv2xbgEnnwA7nET7arjl8gMbS2BfwpNcrxcJovBkJYp+Gmc6+iQzzP+0llfEx/uzesgdfkCSr5e/MrnPq2/G5L5jOVsjfEpCFPsWiAiC3fYBV07h53fRZiOelc0XoYhbEJVVwrHIVMEOhlrVJhnIyY9iEl9BxFAINLWr6sO1nNPxwV3IAsAxjQ2M3fwBL7Djmj81p1UuUIg6YntabrSh/F2H9kmutPV8cF0ZQo1w+w1HH6uhiRTwI9+yGTxX8/hdlRbZkJoQzXchsq8lcTkLRipNQM8Brw3RqYed1u3YqsZaSZlTpXq8KFzSqyQLdJaVdcgJAw3ZscgHG3mhS5IqnMU5btQaYzuwuU5CUsZpDTsjsxnMJRRL8QKJDKgdu0OmSWun0hLp36B5GkymIAYT/ChtuVAah7dD3OADV+04O44e4//or9+s4PlxdzFAoADUtRPXE/crtNiMwtj1MD5j1Birqg7Fizp6xrP3m0Rr2RMP7/lw/rOfCMtr77zT6lMSsVmNwMQmBo79wWIxfCOSVL2/RlOCm3pwjU8ZJFe3MYr/hJqrh/89L303nt96QIBnZ/EM3cPkoGuVpxwEPe3AOuFw1GxUPpt3eHtqi1mYtPAxLg4Br6BZ8G4ctJn4zmZJw+pTxsng6A31ZmiYk6LHvrtR0lHO4S3C0md9yoJlJFSatKFDZjXlJqLI/FAUVH9W3ARx8xo0gneiA/tEIdCEqFU0DpCGolUcQKJ5nXsxa7fnklvEzvwJNmHziExuQ6jbqxc2z+IzXU7nqqdbdU0Ur2cjo3MpYPbrQdCy7uaicVYa9+VWlG7yWyKo37CfER8pa0yuI7TAsf2kyUgNs+GZZNpiMWGL/E/NnQxhtzozeuUAje8JW8umTd+SADFM9tuyWPiWhGrQD7p+eWjzYPlEXDMGsZt+XzDQayPjK/gXb2NevzET1Pp4klMHdC0yawx19vZrJUe3Q+zuStgTa2VTFUHn1Czy3j6qa9vzns44oBHSsiLufFb3sb10intwsRsB7D31jn4Xj3T37+FRLUlDeBFXYbesWJTiqfjh0AFPTTGKzAYZCIzPLZfn4O3TlzDhtRMYERnwGRkzy5U3pg+zkPL3DS2ItU7TOrQcWjoLbPiYU/+Nqkij/LZSprITpKRxFtpo7CuMKQdib44DOKntgWTF4DD9LcD/NMRdm4extf6wDP71U2/0LQzRpiQQFfdsMl4Wp/TocCpNgmjP3EtlWHym5XosuENvDFddOcI5mLltIUwRt0EZh+/08V6hsSReq9cnY64mmev3knn6fObaTtjRTpq6HgLhqmdVTz6MZE42nyG6tRcuLaAK/W5qY/iPV93r+d+O+7OZ4SAa4ChwDs3plHnymrqt62cMQak2BiuxNiVz/62f20Y5tNBk/B8WAniBDIZ3mSJtF019HdlJSrYVyhWrhHmR53eIrujLMksdgKrEKh4UbyY54RYC4hVA+m0QdQ7TwCsVNi1kepsESSptpKlAab2HB5157DTunzlDtkU8DA/sTONzw9i14iN1BIOQ0gaIjcvasjFaSQ0vF6JggCjXaapu1r57kZlFnnKYTBHhruxTzEQ+zwIpXt4vl8POzMldHRo46jHIAgJQMdiw3cAo/XDPNqPThAzSyritYFwqqSVckZWGXfJMpwsBhkhVV37LohYALRsJIsT/5YQVy6BpLXzb6CC+RVM4wTG3lx3uDB8r40TouOxP8STaSRsimKUYyj5Y13cZp1l7XKQRCeyLC2hNlXKyWm6KPFEJT9AnE/a91HLXYRd/8loE5cdm/u5f/2aHuwrxTis2YuYM80fCGly+XRqMa83AKGRfwkCWEWyX5q8lJpRAz/5he50cKo77SAr0i9euZquo+aawGP23fcXQqX8NhlTvvnVfemLx5AcIIUog1OgU8BM/uaH/4WtOjMINeFFwlXGxVBXA8fBeNpg8dNrcagqOzOecdrra5SQLgLnEmgZME1NfE6mTYmozJxaABlU8SEc6qjHdzSOlcxXG0Sux+eAfYm6DkbCkh7IJQhMBeZgGrvt82cn0o+0dSM6gJm/jFBhCCVhz3fqZbyXGJ07kG7uGphPg6f/PnXhANJ5PG+gAgfRJrR1fid17tgL0cZODaJn+9wsZtW+rdPWM28+S9gI0js2hrRdRyiHcglmHsmJ+JXHyGcae8XPNcpqHAn1XeN9jYMT1eXN5ecZrxqH59c9dtyrwJNxkEvk824Zv4RQX20QuKMEEqauVkMiB53rQIJp6lIdSRQmuG5m8yMmJBbVjCdK+WNzxpzl2RcPNd/KGyrPEQo0bdvBGgytuY0w5SRSvcNHelFTE3UEXIknfV4gotQxMOMAeFCVDvGsjKfMqOmWL8B4CvvChNL8Hdu0E+4Pmu2mUfwz3NE09OMXr42F1vG982Pp5devpCOHRtM+VPR2wz8yi8J+Gxu/btaIZnDBTanmQaqlNUWR7lUwa5kiGP8MaWHbEOQMIq0NxjQ2hhl/pL/LcErmpaUzv0qLJ15ISzhDaifdRPubzfPeM5rKx76TmowPDR3200HmvL6eARwtB9LzP0SyS3SZitpO1pUFTOsQL1MHtLc8n3Yv3k4H0uW0d4BwTWGSpnpcGptpdQzkOn8a8U/NCA/evbMR9+Ks/bl7ufHontPMX8GANt73aR5vGObTQXBsHfw8ovcMX4yTUg+BXMRSVe78lFjUDdsSBcZPmeUC9mr8YRFW8gdycHl1jb4KXMC+kth6s/xALdA8i9QBjbDK6huzPeni+NZ08tLD6fZbqNJ//CYOP2+mCnXOzfF+nlsA2Cu8Z2EeuwwC3rr2CxBlqHZTeJCTxAEGcwBkGMWmq78PFQS2XMOjBmKHMIO1EhEZSj/Ql1BpYYgW9RSSyCLEiSGEJAjahYiUBfNoHwO4AdYMkJmZdNclAgv8+T3FMyI2z3gtiH592GMQHSl3ziCXiE4kgDSHbV51GvUNA2aqFvpcrcKMz6AGmSHIO/e2BILxaAx0/Im2hJqO9IUl4m2OH/tv0vSOr+CxD6WkoUqMZAo6yF3fje2d8ykc5KejMff1p3hmreeWr62Hqff1hgf5Jkdg/SJBkdkzwYBBoUtIP1vbIFKaZiCN1quzGeZylhBdszJBxMvr7S2lEfKFHyKe3DsnZtMvsQUdx3PVdKuvGxgdu8Z//nl7eqZjPD2OTdUgaq0OHI5a2wzoDgwp/WaWlcqI00G9bGb9I4FSepPNMRST84zAgXSiiiOd3q9KQbxPPPax5bmv/wCywRM080o9aXcwnlF/XhPEHSWKSoECR4JRo1WNcEKl3qf3cKjAkcCo7nft0Xnj8qXZ9NKvkPrihXwLezljBZo1TJVjDnmE2QzSn62YzTzxyPa0bz/2nWgkmhZn8Tq+mZrfeB85y2RqnpORpcV0q7VyO3VOXWF9QKWKWjUc+tioKuERx+2w66R9MopGZfvDaXbi99OSoeJiVF1TYFRH96ZW4tyyFeY5lvrg/JdHiRG7txR9bySCK+5a9fi696146PP+Q6BbvziGwvoCdGUJB7Eyu4g2mJ0mNjZKPeehZYtENViEqVLN3k1K1sJsKiTjARd5YgK8fVXgRmYelce4AayRDc4SYYmwlZYZa0Z9P4QafwAP7gkckc6jVr6B6nxkiKgn1BEKNTSJJhmwnUrVteCoog1xzaipuQrSi10zUv833rzBGqApWS2N4Mx67MgWQrP1wihnGap1aA5QwXTFNaZa6ySZxTXMxObTP/3iTBrCbvzP/+wx6CQaMmDdqtVSdJRygPScpEEoz/iuYGOccHBnT4+l8+cmcR7Se70D05/BSKesyjpwHNyC2gWzqAmmmZcWT72cFt/9KX2UUXZcoGEwkU0dOPkc/RZSTrQPBMTXFjQzzItIUxfTf/udrcQ/Hkin31uIVNOXLpB2mvb3kcHp4dHjaYDc8QPtCL/2HoNp7otNYzO0MQQ7rlKOY+MaQ1+KIv65HrsZuLug1a/mKS5uzd/UVTCVxZgUN6z4Tb1rPV7c+2l8byzmk9FywCzrDVShTjCos3ZhLSBnECYJmEUk40ublMgGBJOE2M0L4KOArxOQtlDaa5rpgJAK742lt9+9nM6981SaHj8QzOW8SIIKu7LUmman8TyLGsZikYjdGJJLaFIAlGqEbsT7HRDSHhaCHtJfdRHCYWhgmuxhZJsY3R6IoOGz0gvzMPtMExILESxUXNRvn4PZlAiJLPWPTKY7W4mgdmCZicwMaNiqeR/AlaWWMpQZ0DxX1Cmwc1vUv2JsC6BccTLjh4xBzqqEOoLxkviXYBZpeCxEtk9nLKXMejRKJO/JjkG9xh1zEWgnC9FiaW9a6B4mjM5stFmJrCkJOwyHBJMQO3jG4aOWVc1f8fgHXVtx4+f0hwxepFVkjufI0AFospkDXoDxZqT/SuhL88Akm6glbKfcJAlYHQSJ7iF+3hZg3CDO584vpuMY558mr7DB6W/hlHS8uTeN1r6VDqWJ9KWhU+no6HmYL9RT6MSqYZuNPk6MXWaMnC1+A+c1kgfoYV6dQZXG+31nCaeFWu9QBD/PAO2zKycuwojUF2/JVyv9ULop4QsCGhXBvIl7wH8Uv7m+/NtW1H+7CZvFeXAO5noMQvf+6fH05ttXCINzLd3EfltnolmkOK5NSjd12NjNJvMLR7elXbs60tCQnq9IPXESBA1AJexZp+kTklJXljbCvLQyJu7pmrSlw24MF5+QeCrVykxngcsSJ5lLpT6MIxu2uZ2Pp8n2LaQVJOYg0qhgknmupw9njMHtwdTGxtT+rhyqdX81jsO6N3Hhfu/7oDo+N9cY/wyzd3ssrfITkRDAP01JPNMMzIY5FGtwGwKAReBnhrU3VO1hs59NMQqJZ8A1MGxduTDTvK/SuyO13EGLAVNbQ4MBiIYjWlM/YXpw1mlq707bEYYcPTiSfvH2RcxoCC30zniS9zsA/s03DcC0st678RMfqLzcB/4ZiivelnGKZoIbeIa/fA4JJDbNtMXoDI8f60fQMhDOPsJs0G+Y2Wm8xDuJwlJmfelESPP2+7gdYTv+X/7xRJil/Ml3jgadlGaJw2VoiH2tEnkm+ko/cl+rhBucTG+8czWdICqAQqHBXaTSxMu9m+gupvB1vSqknmosFtBEzKNqr83gqS7jyYJXA5cMgm3ms/IC4frgF9q1FaCX8wum25YWopGEbhn3ehC71cHeGfwrqpjedRPmkLBUaD+62g/QbiS3aEpq23chLcXMjTVTX46iFMxi8Xv1d2D63dtXX175m3Eubi2+ixtW/y7Ob5TvDcV8FuAkHRBYWNnyp2G0BDhF3e66BGSBfom0kFUmvop4swqCzQFIc1Ps9m/D4BBCaerOfLqJwfB51OSnzt7AeHgqTSq5FKlB9nniYirFrOBNWK0N8QbewrsVe6stlndlIxoOQD0A1g52crt2DuIABMOJ9LK1bZb3TUOcZgFQY7koWcFGDLuRboCvj6DtOvtoZykCBTNJG0tKL/ktExeSTd/H73D4WT7HjgmCliUzAJoEhGsid9ho8kwxTILh2sRAMFxJWBuGNJDYO4riGMeHPzoshD0sY2We51C/uIL5oQSDyiZAoqcqJIuY79ZmG5tgLCSitt0dYAfIaCrRYLRZfLRdjVhkMKHBYN99PN6x+eeTHQFnUlwSr5yXNo6ZqjpcCDdI48RHYHYRONbGTHhUGuDmpK21gjqZbBtbF9Njj25LV66MpF+9Pp5eJc/wBDh1hw3c2dSXXrw5mnbVvoYEcCAdJVRJ/0hfGujcknr0RLPwogzLbuzwUt/zxXSbKBHTmHbo8McNwZD1QDj7WdhbSfwgfNHU5QU4qvEX/wvmkcOQDhQw6z35ATGmXuizRMFOx5oAgdKjdgEp7bnzd9JP/ul0evltgnvPEJpFRhRmU4ZToqK9dk93SxokhNiRfaPp2LFeiBOBn2EoDZskXRPPhXPHuhk13SKOezUky73eg6avlXVF+lRCbWcz4LLvtp8T4rul6JNai2CoIXJVmMwaRLYVbYLS3bw5dv1h3cHLt1XzGp7PNUQ1m3820Ai4lMY6ylqrZF+HoAAB1k1hAl4HfMBHL2AtM52ZRigJz7Pqt7BVzLH0s4loEuNH/zDN7fgSPqOTxN7ULgMthgIQ4KK5qx/7/+60DT+DI0e70s/fQvWO1P6lVy+l4cGUtj7+jXSl80B4govrvkMTkJ6h4TQwtC+CujuMrh16dOsRfgknWm7Fi741bUMCOTjUAW50o8ZHmigi0EphVDOWlpY7aT/txHoALSFRXpCYXsMx7x9+cAqmrT09++xuNrc6AonhFN5vIPmiiAsmX1FqeuEGSVbG0cxxeQA8dFOsD4Vqeb3lXSdkKGPNYi3RabCspJM6I9mFbbPh4HwVaa6CKsdYp9z2GltExk06OIcJzzRtb8JUhkpximxNvdjHzsyAh44R9E1pdAeClKFh1jal1GpNxP96w4s5Kvrxef3eYMznymlYc7kEuIS/JSQb8y2ESCHa/xxIdWsCR59KD0bH3eni0lC6dAdl1qtvhqPEAhJOiYWhjLRJMUivOxngLLA1FnYgolXkQvxgVogu1BBDAz2R5WdwAGRhd2ROZdVvPXjm9YIc0A6FgAAhDC9SoFk8ASsLSliES4iSQAhmdeFhLiHQc1DpoESjSXUfAKmqupByZgciiGn9HLAdCK9ti5Ko/C+PkQtBsfB4hp/Fn+UFKN9Z/M0gXxCv4qzf+UrjmXwsMynSBVKJlDD2bO+iLTXVL0iEINlBEK3Xfy4uRY3Fu4IYerZOBF2E2rDZtT/BQMOAGqJHZLcfyztDBzI6ltuz+feTGQGHOT4xl8wpY76EGljb5hh/5r5MTD3hNWyHgetQBQOgah9mCZlCPCSugyNkrgpJYyu5xgdq6fh7s5EffhbYuUkqz8nxpnTz3VJ65xa2Udsq6YnH5lEj4tEL/kQjhBPeH7iBh3nz8C6I6EA4JglbhhJqImRYs9fAIWGrKHchL5+5ix8w0EL5alii05Abq42iBFgTnNMnb6W3cBbSi99g79chqleJs3gTz1xNE4DaqMpUtPt3DBDEuo+QSMTVZYc6hHft8BDEHfvswGveKUEy3mw4JdFcTYYWkLgs0f427bnRSLK0RDFqg0JbNwJhchDqTgin9XhHvQ/FGElc29vzBkGnKJ9z7QmpqGYTnJPwFc8t15Nft/n30x4B19dYY4FFvmUhq+BaCS931cABnKyz4l9eKzN+3IVt78jwHfCRn4jNhtqm1v4RtAdoELpmUxMbJ9fyJmAi0hizHgsnSlsHSSjSByBW2GzdQJp/cwwJYZl4lYRJKiE1VY0v3Jd5tpnoDq2k71QDF+3gxbMwgOfevxPB5V0HthLq6MDuIehfhkHfo1bAIl5oh61gQ1wYHqmmYw/3E1R/Lr36zlg6d2UivfjqZfCoi3inbDQJEC/053cVvcxoqz317dvGyUZ4xHj1QbdHSMrQwXeYpfAu6ahFNHeslH5qt90sji1fYAzzIui+D9xDCs0/cUcNibRsyWM/9EMhivanmhB0tM9B37u5B8aefkr3DXvVTyg3Y682Ms+xxtVx2Fd/nsuGYj5j7v3zAcXF1WCyV6/OplvXYcqmt2Bz2JxuTPen27N9aWy2N13E4/zSZBOKPvKtCmDLVXLAfyWa7RAO1VktdS/zFjxP22EiW7hmsPJeGMzRIdJM4gm4ZZTUXzCfqsxd7AVAEUGANJRQteouC+CVyCxqq5IJT6jYicMmYIbKHelGxKPkvTKYIQUNhisjVkg0eb/fSgUtNKX+Oy86/OXfr18aF637raWGFHdJKZNiYOwBQ2+j4Y8utuafpS/2eXUp3uWlzCRwoG6RPjaHm6R94R99lYlfXsyKitaos7i0+f1rjMC9U7RcyfJQMxcLnUj/IUhuLeIR5kaVe00DfGA/VFl1YiIMZ/wyRImkcwG7tBpx8pTkYWYR6vJKGkcTIYEwfu2VG0sR73ZyAskDcNUGgdq/r0ZKwS4kItqCInUAplzAdRrQw1xppEWGU6lCxkXxSPjJHVu/e/decUnwM4uH7Azq9Dkco3SS0F7t3eM30htvXEkXsVu9iSpxSolUfRHRQ94MJx1Ii/qUGO3pTccOI8UdcuOqtETcd41xbcmMn8RKu2bbbN9KZXDIa0HEeI66dXiIBrFeBdLHnfZ4ZSl6Yp/FKefDMXEIJLYyFzIpYZrDWhWbBC7GGPmeldVt/vrUR8AVMBexx3U2teGmXcGxMwDCFZ95A0dC2gFcSRmKZ3zybg25Hv8KGzJCbWx6au0wnMILcCHNisgJai9kJKlvEVvFHrIlDaOhuzQ2iY3pEnBfSZOTS0j1soRF6aZ1tMZmp506cKKpM5+2xVSaVy5PhXOdsDcAw7iNIO8hdQdGhdPYBNkX6smZsjQ3UUCzlLZtqaa9u3vSqfPT2J7OpzNEiDhOhqQB4mZ30zaFE0WhKTEy9mWezaIhouZ4v/jcDgM9gH11O32zv45DsT7ETlPGkudic2eF/oa5R/8ezl3+VnrqPZZch0wzv2m3H/sbeEw/ZWIXwe32DrSvPGNcTvHRMe6A9ovztmG59daxWWIENhTz+UFzkkEBqQFSzHffHUv/9JPTxMybwLbsGDseAEcmULV7fGfGkDmPTAfhzKPNCLEEtV/rhPHsRzSvE9DQIIHaCWM0AoPZ0pINi0PSR2MidznPqVaLRR7Ey0idbTgyENpqjgKgIdfsfkQyAV5Vc+yCIKCmpGutM50h4RSI+QjcYWIQtXCuTkwLhLkHVOvAe895m+EgKTlZcznyho9eDGa92EWmBXM8YztUmh63q9FOx8LcswQ6pOJiCVzZMpG46IvzEUx3+FvebcvKJ+xCRvTozt3bNo8+oREABGF+hEVgHsewqaO/nxaunYXhI/xIff5asA1r3vt4LOqRMQObLwlQ7PZZYFXFz1XaIT4VmFCCWDfNpu07sAklrNCxR7ZCmErp3dN3CNR8hziXqNjQPkxiG3oaieJPf3kufenxnemrX9kT2ZIiPAo4V8YmurdX6QFqL5gqi8yUXupF7mpxKajBOmMjKFm0qdPWS/tN7cErHFf4PkfA6Iuo1S9dupP+5Z3L6TLMpg6EqhElUBY3qgaB70GyuZ2kDvt3DcIs4zQ4AkFmM6VDhBtax9HNqYRHb+RQ+6Hykyls47zaDserSQc9bM40YTBFZZV2hFE57yphomCM4ppMyHqljh9KOEOLAmIt8Y7WorPWw7Vw9OOaS4Y4ptRzs3x6I+Do3zMDzEnQAeDY0HqzQ/vT0t4vp0VSpi5i0uL9zmML3t5pcGc4ASrkyMKJe2rLneO0NEg4VOWt2ndxERtIzaOAkWAICQvkWiy9qCDZ3A1MP3FsLl17YYZ7obEnb8am6jnSd3ahghYTgKRgaNuJi6tEL0zGAqZqbOAq6Z3T1/legFlsIWpLCzE7jSbhOsFGlP75vH2tYUeAHoAc5eQvRwVv7db/1GOjaWyczEK/upSOnyGBjLQU3FLLuGWLWcoaCg/Y+0k2i6exM9fJD+LPetGadu7oRduIkyH9c+wy/amPlePtk7YbprGKI1MkiFGrp/MULSPURBao8CvjUb7fPshjiHMy9p1Ib4ORZU2poMr3DS3BaDO20HqPnQPbYP+8Xnxz+LkvG5P5DIB2qhoKSCMxMPTPJRwZXiNY81XS1OnF2YxETgNtY+Qx3zB5hJDA1qofABwe7EIM35WGCd68hWCx3XirlUG4AME6oyfhKIOMcFF88nttghJIVcEiWd65CXiZiEh0eNsycMdiAOxmBLMaCQPMKs/6fOx+fF90iRtRaVanyLs7cyfu9XTQFBnULtL4kb86LzL3joN1rwnEcWvxjnjRr/WneKOMsR7PpeHdaaFjIN0cfDicGiTgEaSbRa0Lx5GB3tEYnxiDmLu7r43FhsaqTuRvXPCvv4pSvC9+MwiFanDF+eLmze+PPgL1wV4PMjT6FyeE09aOrjR9+JtpYss4DBpOCsyHaidtlvuGhpAsEJqIeXcjlZlPcQ5my91/O06ALMKRsk7pJAxpK8ioh+iWLYvp4YeHif83lF57ayK9d+F2mpEBxN76KnZef/vjk+l7L7yXVGUPkfb1yIGR9MQXtqfde3qo1/aJRzJ5SvcIt0JcP4lNWc95Y1vyJX9q6KYFiGcR6F27Tf5HSsuLF+6Eg+F53n0K7/QbhE4zs1jEG3VtUSUJzncQg7Oti7FgLelFynl43zC2rAM4TmRTEYmQa4apLiNBg+YkjIcSDyUdrWgDwguZY+3JrDNMZ2iy7Qp1OmFblkb2penHfp8QbreyZJdxDsLGtaadT6ZemQyeFYcacSHwIxYLznMhNAe8Z+3ikxkAGutY+97Nsx/3CDjyMfrO4aq1sXhXMDhcU+vWNLwnTT7y7TRJbOUF7K99WtrTienWwPDWYHqiGqZ7zeqAi/wemUzgh4jPbaRYDptuW8L/EHj4MP+NNCF+j4xWCHPUmt54tyNdxgn3Cjj5xvGJ9PSTe9LO3TJ+qq/5CM9B05QsAs/gjNFnbmuaglmKMLYdZnGkm2gueIpj3Qx60o+I56zHe67Hh0Mqy7oidJsmUgL4lScG8V6vpNdwHjp1+mb6S5hK16B//UdHYEKRwkbJo+pG7jY4bJimO0TjMFrEINmJRkYwjzPbF+28K8ypP5q7jdS3K83t+3KagflcmLwdeClON7H+JehZa/dIfjYC6DrW9ixaT71ugvUPUdiUx7TLb6/Xx9X7Ha8oHPu09xb15Auf778bk/lcZ04gIzGB/Tg37NmGKhs1VwdMphJMmUx3PZijIKon6BHAJ3FUUhK7LgCT/wCOdoWFxFGmUMYzEwivhRovfsNYKi3VWNnfAFsAp/dYRyB/XlAELBlFi/dkMBVgIRz8thTnPJb4LN66mCo//L9S5cW/xduujlQAc4nQKa1PfSe1fuvf4o24Jd4VAO2DFoHbr/j78f8RhYq6JZoSUQadnRxSG8aitZtctdrLMLaqEtuRSsmYLHsURpMaaymanGstrhTvKHpQnLd/q68V92x+fzIj4HgXdoLaJi8ODmOfjKcrkhLnXpAzXJG2y8txMSFCLq7aJ/rtBrCKNGAJb3QZVCUj2nWZynUOSWhEp0CS09e3mPbtbePcSBofqxHUejK9g6frVbzIVX/fwS77ttIM4ud+7+enYeSwv0aV1osDwxAe5FuMhctGUk9WPcTVTrioq/YzzuYEDg+3bkxmFTq/76Dmn0G6Mo/0JlRtAJr3+xG+22GOm1Gfa+vdgWnNNlSPxw4TJH+vMRQ1t5H4i//ithoPN6KuFzCbqOAj5A3Zw8SH+IAjWdPi2qKEqmGNiGNTXYJHSLIWBxiDR/8YM6IJGA0kJ9wv86qX7cDQSBw3EqsCR5wvJ6UgZo33rA0h8cTalzbPfvIjAKzlcu88eEbcExa10exCUundbgLFGShewJy41EO0EO8JYYYEaI1SbNy9JF62QR/ZVgbzGTu0hmcM5xMbtvbF1FbpSAfJTvbc10vphy+cSxcwOXnx1YvpwN7+9Oc7Hg1TkyyAKeBZKaCmMIRYAl/fehMGkNTRXXijHxuYSbsrk6l8+lxausV6Qp+aRgiOv+MIXuBZgimdVWPQVkPSyIrvJktmbt/+pfSl8X7Sz86SNW0qXbk5lf7qb94IOv+Hf3AEnNR0xbcm7EsX08WL0xEaypaMoG7fta0PyathmeqCIesuKArjHGsV723t7Enze55KE/370/QkUSIwrRFf26BnhjfrwFY2aL9MMc9ZCnyLH/xhBbTpUTL1L67k7wIvi+eK3yvv+vz+2mDMZ4Gk906IV5RiGO3/6SeH09HDndiN4cE3PY2qL+8QndwM1Ir5IQYQw4wwEAKIVN6xSTzotkQE5Lx7XkZVgiHDKLHJjGgwowBZATjBXAqQBuSLXdwyaN/baM/UAbdYdtyBRtgGUlYuzYzB1OF1Bz5GKAulIkvYkaDaLk9NpHLncNjk+O7i+bVfsvJsTUcRgujK5IqmxaiWkBqVWjDetv/rlOX3OJYQ2bBZ4TiM11n4FrpJ88aiEzZtjG84UtQXxHgWCZomEPVu3/OW5fpXXVnv/KrbNn/+GiMgzH1YCbjnplZUan0swp0wmxHMmXPOZQswo8Qzq5zAk/oEhwyeY38WErhsS+3mBLsniJrp8PSKD5U8Kr5IX8di399fS3v2DaSvf30YtXc1vfH2rXQGVfw4TOMMEs15TGxUjesEdAPJigxp4EIdWOpNyPBNF5d7SX+jy/xR4K4Zhylx9dQtIQ0CbCGS5TQKM6t3+pYtXXimtqbBYdNegtWuATxofzxWdRZrSV26GXbbMJltMK5Kd8Ouss6U5mdlzBtG3PGp//S6qnn3dBJCG90Co15FYutGVRW9dXZCsEPLwj3Fs8V3UXOxJhW/N7838AgsA+cabQQ+QkPGTLuZlxEtEiMEgHBdXMp2wwo+xLfV0JDrLc6uvp6Zo5UskvWYHa+1ikc3ADlAvvijB9vS7ZuDaBbQMML4/fCnZ9LOLT3puecOsPmUJloHnfE/67xhC8dwynvljUvEuF1Io4lc55f/Lo2OodF7G1rGBnEOWrl06MnU9m/+t9Sy5WDgku3LuAAychzdUZIIDXz8MTaSOEctvLCEB/tcukh0mr/+L++EXerXnt0DPmb8vHlzMr3yLxfTDa4bU3fH9p50lLiifeB1pt/el9cvF4R4JyfE33Z8PJBWuaMk0gT4xwZV/kA6ZyKWLkL/xXpBb9cb09VjvHpmN5nO1SOy8vf6XMjK+zbOL4A+JHIQkUXiZVaxkVIFbnExl2GSiXQRD+cgvrMTQJZehiQUIiKyq8pz/RfoFPtnwiGwuhOVwQRBAisK4sEulIUhwLFOOOLF3FMAaPxu/CMVjDrYd3Kc1RQ6UOTwRBEc35hp1qfRM6r8Kp7gqi+bQYgyyK0Lhm25n8KdaXH8Sqqefz3VZlkAfNZiM1AlNO1+LJX7t8b71q2xoc2ZmXds8oInIZapjYWLMXOHKWEupDy+rd7deO3mnwdgBOrzLTwoteOv2y2cwty85KK0T8Yz4w13Osn15wpwaVyMvR+2iloykZGRCsbVTZ34xoZRey/xARKWRkdr6UlUYYcOtaAKr5GmspQuXJxNFy5NhGpN9bie5t7/wcVeyHTCcPJpB396YXyHCYk2uGdX6to2BJNZI+amks7m1I8EFT47VJNKPwu1ongf7aStwnfYbtWZUNcX1xElnbF28DtMF4KY15lFnrclKwrt8azrFwsUCRswD1LtyPMSvxgr8ElGQ5Wkmpdi/cl4fE+NK6rf/LHxR6CYweK7wCF/u8Zi1IVKOAtPCptjcc2seEoKha41IGvNjsdaLMyJq37WKpwPOK/D+OBgW3rk4e505dZUugxTdw0b6LeI/nAA05O9+7JU0fqUyOobIR2bIWzRzYmZUL93ENG+A0lqaxemWQSWb0KbUOKeGqr3JWNoKmHkefHGNinocaWITReaNDVtesgf2E9KSxwSX37zJu2YSZdoy49fOJP6etvSkSNDCD1I7UtQ+0swoG5OO4it29dtbNHsTCwvQPXL3S4kwp6LNQ4cYyCDOjajuZCm2a7YaIJ7sfGjjY1r2lrD90HnfpNnP6jez8q1B4r5FH2cUBlAmR2JgrtB7a2K8zKNYX/FNe2xBGqllUFUfAaAEvCD0eS3PF8wrR77LyQe3B/MoIgranilzsQtz7yQvfxj+UA7FCLYwmlmQ+riQqjlsQWzGndEYfvFd9GOSFnpzUg+RWpuqKdGy5LLNV5VVL3i21ZWJzDWPvMaOe9v8Cu3m1elJjIMlch4UkKdHxi/dhcc5Nw1viWUvlvEDNWIXurUxU/P0n4XxrtIer/t9OnNskFGIE9mzHMwRs4vkkGZt+VShwU1BUoT40rx3KpJD3iRwaLGjJcSGxk1YImP2cbER8OsqO5apJ6eJsItoS6rkQnJOHsTd0qpD7V2B0EPb4yXwj5U5jN8cxZVOWe183L7PKBh5enr2IFOAZlIOmlIB8xnPynLtuJRO7JlZ+rdh+036QQ7SXMp7Aas837bLI4Wm9Pi27VCNTmuValp9jYpB8lAw3OuM/ZBxrHUM5LKpMSMdYS6xO81i+PFpVhbMBlC7YHakY0nYxXSaU45RsHssnbltcH6rM0WbpbPwgismElhguLfmG+P2ASVIk10XIo/wlze8MtUrajh7k2rjuKu+7hXnI8NFXDehbPQ9u2dafeOLvKt4xxIDO2zOAmePnMbczZNUcz0xYuASTeCs5i7TKBun8bRqMTvnuZFTFnYdpqhCdO3JkKvlQzbBhDL4AnnAc71tsb6QBv1utdprgWpvxLH0WHMAPYvpqs3ZzGhMXXmfDqJY9Gbb11mTVjEFIfN6RnCn43haEQxOs0gZnfd2GobwSbGMvqex6oYsXifOMY/qDxPSr8QYkG3xcvgD+Anwpvf5+9j/KIBm38+8ghsGOZTkAzABDgFkGLO7zJ/GTnD1pAF292aQNrZpbWHMCJTmolCEAyue48EIqQHwFGWzom8HPsOEb0OX76Hw7WLqz/3izTr3sM1pRfVCcI7nXyR7CXkPOe3JfpDXMKm/U+mpU7yv0N9deYwzZkoYPVROd8SLuOflUhzWEYV19SKjVjBKUZt6/+JZ3m+cvG9tPDSPxD/YkxqFm0PZrZ7KFUHd6fm0UPEKMuBwm3bWiX6Wu937FK5iZruKcXTmeAWv+65bfPEBh8BZ66A75Bmr9deYKKQIqx7i7jFfWEjHQydUlOl/qqb9ZTtCFMZ4XwRBnR+oRJpPTWf8ZybryGkkwaofuIpvL4xI6ktQGQI81UhDe7kJJnHIGhLeOgbBgy9dcB5rYmMQb/4x9Rx40XgG2ICjEOxyaZFbNq2vrSAnXh1CHV2Sz9oQdxdJZduTsGR+EB8PWc4mUhPCZWNzCpoJmrX30uLP/s/U+0cmzo0E0uuBw6aBPVr/2Nq+/r/HPbaYsl6OJXHi3GBgS8TqkxGvrlMqCnGpCiiY6xlbuy4Ll59cH3Fk5vfG3MExKrGcu8aGbhXx5msCnelXWu1zfV8XDBR4LvwZVSWbtK5VsG/Gnj19S/tIHNXKT3/83Pp5bdInTs5i1p9Nj33zHAaHYBpAy6VOJ48NZ1+8csbqN6x9yQH+iNd11I3zGHYPQO/kF8xAlz1ftKGYoJT4Ju9se9Bn5HqtpWMU4uNqNFruP/wIaSZfcbJbkm/ePUakTLG07//D6+kf/rubNrSRlzRmY50pgLTOdCRnn50ND2ORLSHDWzGaaimNJ2+FeNVfMf7g+HGwRBGtaM+RcV4uCeVd/BZ17EPW+/yrGz+/agjsGGYz3sbvgpJAQR3aNogKh2oYqdSI2i1ACUEx93ck3c8mZHM0jpqjusAksCU77z3dR8EZDxnyX/vfdQz4Ap2MvNp4c0fpMr3/12q3r4e9mXF3UpHmr/xP6S0/ytpYZBwGti2mK2hhmQmYdsWKQEhZDWkOp4KNQDMazM/ajoJfkhxHNyJaiM3T97pErax5W4QCJ2iEp0aO1hTZUjca6hBlLaUILw1kWyNuuNcvd9epklr3lecd2w3ywYdgWJqiu91mrl6zte8LXBozSvLJxvrubvg582hqsOIrQtjKJMpHswDj6aum0c9ns1RCIkEU6q3r+lwF29cTUtnXklLN86yoZpKJOZM3QBeCaazNLAjpd1PpCVMSqawU2ttmUdwBOwDsawSgfMRBUNGkrWjqloPh4IeojS04fSjzbJrRiaIhZOihCcTLteLRY6X5si/fvVkWsIzvWwKGvohVlTJqrJ4+UIqTY4jacXMgJBqIVFdHo2VB43EEJZXC4cPLJt49YHD80BcdI108fygJbIRZz6sUx8XTMQ7oRvWp0lMjrnZBVR7pZq+/IV+4mlPpdfxOj999lb6f/7jzXT79fn07f23Uj/5y69XutMvT/eln5zqShPT5bSTWJeHhs5gTy0OIkVUiyjloLqgTQpUwOs27C3VELIixKD4fjAwtCLt7TpB5cQmPrcde9FvfnkolUih+avXb6WppZb0TgWpLB81MG1oTPaxUX380Za0H3tVGVU1B258i1KMl9/OhQylk6HWQnendYv02fvWvWHzwm8yAh+y9P0mVX/EZ4UKPxQne/WEB8BwVgaU/268+ONdHvAtJArEEg3OrFkCmO6tO+79DYFMZjGHmSFWKDu+kkiAV67NM44fDuJId1DHG98PYlvFc3axa0tabBol766Buu0HOy48hatdqPEkrHZr3c7E7fGnYDwl5Nmxg5Sfubo8PBz7swSHLIO8xEfv9fX31nfrLo7Wa8Z654vnNr8/3yNQLPzFKAR+snlk3Q8iI+y2IhFdYpOkCl470KpwzLGOSrNspOauvpOWLrycqhePQxKRioBfhkcKTJ7Ykap40pYHtqd2mD/zKrfFhgoJI6YvMqFKk5qItVuB6azBdPYREqO3tw8JLFISVG6BZ7aJtSM2rHyDLIE0qvdNVLGkN7omNZgjGPC7hAd+rcq56ZnMNJu6sHMRSYpEde0NXTEGq8ekOL/5/RkdgfraHr01iuDSAABAAElEQVTbYAtmwVwJ99oZV4nwIE8IcKe9++fTl58ka+BtvM5Rb9+cLqX/+GI53Tp+NX2h60x6b3wkvTK3J91K29FCoqofxSPfyBFU0UT4pTJRLmrmZ9AfGKzIoYlkPK2fgVgxFjLB2R7TOL7SMm/U7nWwfyJ948CN1HPhfHr3ZnuaZoO3WIPBhKju7JpLXzswnLYbAxW810RGyac4vxbtjFeudcEmri7ct6KJq69v/v6NRmDjMJ8f1g0Bpk5v3CdlIPKhAjz49j/33APXRd2fIDBFyi4I1IK7OxDGdkR76wuPRNagwVBVEIqdYM9omjj6r9Jsz95s++YztL+dcDY9Ox9KvX1bApmCGC73sejI6m8etNO803ZUI1sKP3iPIln/xUtplAS+hDQpdpe0KXLl+uLN8pkdgToIfur9W8F00ShhW6APcxnzKbOrVD2XGdJqON6UzZ8OMapiYlPD27aGWhzRKRs6JPhIOmsE41w0CxKMJUKQ1DqIhuEONs1ssNyw+o4ydmeRppPQRiXC1RTpbk0C4WY2wN9N7YoRkgEN9AFn0CaA2y20rY7UfHnsLaoUdSCcSy3glgS2SaPWqDRu2fzzeR4B4aT4bMBxyCu/sJzxUM2i7RXmW9tm0pHDHWn8Ykq/enGKfIGtaYaQan8//Xj6/uQjmJ5gp6lWDdqzpa8lPfIoznuTI6l6cyICxFcWwA3SgurIV+segCNVhSdTeC+98Zx4rxZCu0u972tEVVmEls1OEv2hZTY9M/hSOtYyTubCoTS72JXa01Qa6iKofcfvwnCyeYTpVOqp/WisLesyAhtwIj6HTXpwmE8mJ1TTAG8wdffCb5xfvudTmMwgQuzGTJcXJb7vLj4yheaMlSg2scts7kXCSVox7Ts11lYq1AQRbe4lzqI7OBwSgvlcq6/r9U8CGa9E5oPXMCyv5DETaoiwO113tSJ6fKjno1S/3ms3z2+OwP2OQMBbIwECXrOkQsLkjkmJh8RIKQZ4oeQSyaQ2kDpjEPeJfRUwDFxX8Xqt4CBQg5E0buHC/qfSVPcwkcYqIUW1TXqPd49sSx0je4mhSRxdCJvhoKxT5jMK7WnEA5qUi7hSqAEDt7gig+yxu0i+PA6JLb+5HSJbPLz5vTkCG38EZB5Fx2xvCk7A/IXtMzSolc3d3j78GPpPp1Njw+lcGkxTNfKyG58T2DfSTDtJGfZhTz1AcPfK0BfTzaG94KImL0ScAM9MkduxdTdmLn28Q3zjwfg0YlymQ17RT6MZHG9ZzFEfjKWbI22wIcWutK2ZAPy1GTaDldTexDXWBemljHNO7OI7WD94/0qs5vRm2TAj8EAxn8uAtBJm7w6mCLSChNy99EkfRfYlVIZm/9HLVuSKeJsyoKEilGZxzH+JqV76Hb2DqOjbUjNSGp9396czRkdvD9dz4GoNnzNa3k8PqJx31yCuCUSvzSEd4pTvLKHmr3YQv60F5jZuyrWuN5T387bNex6sEfi0cOPDRqmQhPi9fEz8Qb3tI3pFSENgQPUCDuYzW3TWkDAuyXgi7cCQDI14U5rZ8wUI4MG0hMpPB6aAfyWjAwOpta834iiaMz7CsFFv8T5vLFSQje0N9JGj5KDG5rCmhNasSmzqAq9lkml38KHxMjFqE6sax/DzfCz8FCXgu/ixgb5lPIV/2yfjKRi34bBnYgmZuW1dk6lngDBH89dT39KWdL6yJ00geWxGMtnZ1ZZGdnekYw91pqERzVEeDzttNXAKN5REqpVoBf+aO3upX5V4A941jkM0JGv9gwFm09i2lBOZtIPDi2o9iALQihSURKRo8GBwiSCjIEd6apY131fg9EZd7xq7/Hk+3pjMp0D4AK3fLjAhCOGgaqYXAviVCElUm0UP6EV2llXtaZpwRjA+IB8DVOu5r3oh8tvWmc9mEM681Z4XAcN5ob44gFXrwCov8RLXVVtUh3akaRybFgm5pO2MJgBKeUqcLw/tYedorEVtZ9dZBNZ5y+bpzRH4pEegIBxAZjCewrRgD1+JOi2Tk1KdsOlS5OZsATwqgy8t2EvrQCSh0oHJrEEWpSLdPd2EYSHPNYxnqNuB/xXF96w4kX8EWnG41Eqw/P7dYcNWxdZThLet5Z6+tIQGg7AUoLp3i/CbZXME7o6AzJywUsD23Ssb56jYeKlpU+0NoiAIITUntGgB/BnonEyPD59L++ax9ST155Vqf2pjx9U3uiMNHxtM2w+0RHD3FmNWg6dqA/wnfmrD2U3SBLOjxcaPcxHFZg2EKzAo1O/QKelgZEnrR5sxsBVbb7Kl0UbRrNwCc4sjb9PAcJirGSO0ybXAdcJ7NsuGHoGNyXxu6CG7t3GCOfAOopFeEOZueudTqYb3q84/biPLSGeaSddVQiJT7hpkd4bXPsgtslSRdIYKjzrEF3eFwXTKHPo7/sm/rk0ci9b4rEinCiIRSul2yyihMqbCCcodqAS3F2eLwYE+dohIfqDm3LlZPvMj8KAyQ1LsjBNwlaQkGki1dj7YVpYwJyGXJ1wlDF8nnrAwhjKYnRC3TvAph2vKAeztvdLTzHSixofwBXEVr+4TAZSz1oiPO/7IH5Mu8EI4DkYYNfDNVJjtOx/hux+8ZtMZlfrW+6z8Mw9/mx18EEZAaJVOCL/ynugcgj5Ful1SKle7B0kMUUn95dn0RPur6UmlLeX2VNn9VFoa3p96ertT/8Ag9tRdQe/C34A6S6rEYSJbwWFV+RFHExrnG9alaLTBOwJXebatoxscO4opzWxauHkRuoq5DW01nFMTNt6t+59I7X2DtJcYoQVjy/X7RnDetVl++yOwwZhP90oPZlGy2IzYP+04lsZ79xN8d45c01Oo41BfcL4Xld8A6vRmiJV2MGHDAoqJ5I1F5G/cFTYuCo33rTjmJiVFcJ9BhHvImsIWMTK4hFQVRDQ9YkdXB8bZSocIYE17N3eHK0bxM/pjHZxSHB7YJoRtwGKzBGm/cc6b3ftlvMm3paWpO4A2TkgSKPIzo/NL5b4dsaHKYdjEp9xn6Y/FKozx6+aMLV1IZj6o7z7mMxYJpESurbsvzZIdbJYNpGlCZXDDNg1ca+7uCelOaBeyuVl+ePPv5gg8QCMgPSgYUP0PxCfznM/tOESMTmjZjQvg32SqoO6WsWvt6k2t2w+lpmFSWvYPBPPZDT7o+BNFBBTnxFWFHYHPHq/SOqwaI3EvcNDnYCaVnHYOb0+zxOad20E7wD8FNlXeU0ag0kH0Cp0I24h0IW2N53m2wOFV1W/+3CAjsMGYT6EuK682yPjcdzPCWQhk6NS+DOLYRkzNdj4iSUhlCM/SYRgYpI5hFB0IKbLfi4giqeMgthZI+MENyeiaCSWqCpBVCap5gotA9yK/0k+lrREHbZP5/OAh/QxcFXbqbNi9vZH53OCrc8AzxKsk87nnK2lm+FianpqOoPSarnRA6Lph/NzYKXXMWYnu4lPw1/U+xoaOUWgksPcOSj7TOCziohIY8aabfM8yoosLZmHCnIVXRR5onJgKvIpQUgxsQcTXe8fm+c0R2IgjUAgkSthc6+AnLWnZeoDwRgNpZsdkmkKbVsGeWiZP3Ovi00OO9F4EK13gYxv0L+NAQ++oCy40Tohb94sb2QQAAQ0SU7Ua0rJ2HJHMjCZ9lMnVRK27qzNoW2jzQNignw2v3zzcmCOwoZhPgbIoEp4Hp8AwQyRVKRg7UOAvGL1QD2C03QHx0hatFUSSmHm/pUD2xr42Iuf9jIL3hBKDg/DeZcdqvdqUGjPRIvOpZEbVR0iBNpE0xuWz/Od+YGej9t+2BwzXGb8OGDwRq0QECOPpikMdEEYDxre1dwQhcsMl4Yulw6VERAwO1FN5NBpx63767lPitfjs8iTRjQws4dae8byduIOeN9xLfouvLo7u5y2b93zWRqCBlD14XQPOhV8llJpoKVU09JJmZS1k49KWWvxTJa9ktAvc7MQ+VCFLQVtWdBocLPBvxfkP+OH73Tj7nPiXQy/pwERMYINmU5SKKsxx46cmUfom/jv2m+j3AYO7QS5tKOZzg4zJR2+GoSpAFCWaJTLl6dHX3m7sP7zNqU2EDLsXnIkCOUESyeF6WPLrEC6RrUC6rP4zH7WBsMXEvJhIDhudjGyb5zbLZ30EnGnKAzXZ4BREqwmmTmmKbXfjJBFaRALiJku1oB654ZUbm6oM54F0y33NBwUh+yi4VTCq1qDZSol80rbBbC2BbJxX2uImr8Crj1K/U7JZPmMjsAx3uV9iXtY+ZPR7EJiiIkSRjJwOfDKfwreatArmZAX+tcOI6pDUjqOfQhc3YMpUch8L6lL/5quo975nnGekrMEES1sJYB+bQGkaRVyTCY6NH+0rtBsP1jp336Pxmbtxk/n8GKYU3jMELIF8SkAhihKnIrSSyGD2FKWdIkx8uP5hTkQftWkZ6ev1Fw83mJSuWheLOza/G0ZAhsOPxUXvs1Byb/JC/iD1RzwJqQfMpxu7DiSci0g93FBlwmNAaiQeEL1M+OrztQagS8Q+avEdBQMqkRMekL0E32ltjqvfocSow0qcB358drN8XkcAyHANEUD8WISHgImNDxcFroQDKxurLtTa7TjzKPFcYONn3Fu1DG7I3HiJg8bNFT8acabe8eWvot584sP/3sUh1wEdcXnnqlzTxbA21t14/OFv2bzj0xqBDcF8FgS/2CF+WoPx6743CA5Y4LcSmWWWpc7EeGEFQnD+42Y8V7d94y9xq1v86f/Wjm9mZiaN3b4di+gAhuzGXS0W1U+/hR9jC9wxSRg3MqDQPse+BdxCo01z3Rg4BpmiaxMmQc9fYthdZvHjGqlGYpqJ4QcMWIHXNmizrBgBGRedH1WRxmr4eRuiANkHp9PLmy6EJmVj66LWVsVtagdLYFvgnkeiId98iufipo/pT6ATL0EGepe2fkx1fx6qcU7Uwloa46B+2n3fEMznPYMgtAnRD1BpbG7koY8+NJwtCJN94lrDlQeol5/dprqbn52dTcdPnEg//OEP0xzqpaeffpr0cofT4OBg2Ddp05QZkM/AOMh8bnAoLMY6vhsk+OuN/idB+HxX0Y713rt8fhOvl4ei8UCm88Spk+nO+J104MCBsA8M+3eYmc9FyTumDY5tK2dCmC/wqYD/LPmH+ZT/ZPlYTcWK+1fWtPnr0x4B6dr5CxdwlFxIW7dtC1rmRkJtzqdZNibz+WmOyMfxbhnP1WWTMK0ekQ31WxOJ6enp9M4776S/+u5307kzZ9JXnn02PfPMM+nho0fTY489lnbt2hU2R8VivKE6sNmY+2cSN8fqtzICMiOWCumD/+Iv/iJdvHg5fYkN3cFDB9OB/fvT3r17N5Qk5rcyKA/QSxrXObUOpq+NcwV5axSo0K/G+x+gbn5mm5qxLwXj+d3v/nUaG7uVnnjiiXT06JG0e/eeNIRQ5dPU6m0s5rM+WgVsf2ahYrNjG2oEJJKq3N3LGyRZpDxx/Hj62QsvpBMnT6ajR46kb3/72+l3f/d3Qdrd4WW9udBuqCncbMwGGwGZFUuVfxWyTT3//PPp9Jmz6fXXXktPPPlEegYm9Jvf/GbaBwNqOJ/PbilYgAe7hyHlXE2YNwUqG3tS3RzQwgtIPf/x+X9MJ0+dSq+/8Xr66le/Cv49kx5//PG0ZXQ0BCqfRkc2FvPJCBS75WIw8u88iKthv7hn83tzBH7dERCyqoTNUfLZimPLoUOH0nPPPRcJAt47/X66cvVqmpiYSOOklLt582b61re+mQ4ePJT6iG334KnhGwhhhCDy9yZW/bqws/ncB4wAoFXglSC2d8++dOnylXT23Nl0Z+JOOsmm7uLFi+lP/uRP0kPgXD/21Z+mFOYDerJ5aXMEHrgRcGWXpsk/ubkbGBggRN1ievOtt6Bjt9DwvZueQ5jy9a99LTQQXaQ/jTCNv8WebiDmMw+UfTeI7fVr19P/3955QFlVXf9/I8PQhqENCgzCDF0poihiN0E00RhN10TTV8rKSk9WslLW+melZ6X3HpP8kphiNDFoNJqIiA0FG4qiNAEFREB6/+/Pvm+/OfPm3jfzhilvmHPgzb33lH3O/d6z795n73POfXbNGls5zpYqrHZrb2sT9AuVX9pj4lnTOiUUqbdTWtSh7dE7LOEmS8ja6FEe1K9BwZgH9csdbNcxffpJ+hWbfVJ9772ybNmTslndFQ8sWiTr1q6TJ3VO6NnKsFOnTJHa2loZNmyYzaFp777ZqMGlXPAW4mcHPcm9kOjn/Cuct5XkjH8jAkeOAN6Eg7rPMHx51VVXSc2wobJgwV2y5cUXbXoL7/ennn5aLpo71ywxgwcPkiFDh8gA3bj8aAoJ+yX85uyYY8mj6TbjvZQRAqxhYK41/Dfq+NFy+eWX24Kxhx5+WNatW2fW0OU6AFy6dKkZW5hWNqymRgboF6MwqnREKBvlE+HdS/cU4+YxE8+bN0+WPLTEtHHf5iRNwBOXqXSUmED2tJeCkclSulLiM6vNP9HGORL6+cSmJyl1kKkxlabFGsVk0Gigk0EtJTolKl9V2jNK6lDFPp8rOUmalHt+qUQ1MjW+gFDuMjOrVkRaYf1OJRGSyqi6kTKrAmHaPfodYTZOrlGGZIusF1VgrlSrzXPPPydLljwkE8aPkymqgM6ZM0dmzpxp/Tbr3r2eDj9yw8FNI+x52WBhqtRPviZbg+X3ZmjUvGJYNsp4BBeZdRSh2VkYd1a9mVAUAa/IGzGTXFaC82hWelq8dTvdDov9INkQnIHc4CGDZdapp9q+qKtWrZJnbSC3TG64/npZpvOsp02bLhMnTtA5aTOMn4YfN7zT3IFp93QkcTwPFn0g1xi89tX3SqVuXYRBxT6KUArxjOfets88o5JS2tnWeTOa1Gb3nZMRbd3sI6XXmvcOwxxkGh/DQKbxUY5Raig595xzdGBXpe73p2XlqpVqWFkma1QmLFmyRGaffrrMmHGyTNIpZvX1dTJELaXtrYSWjfLJxuwI+qlTpsrKFSvknnvvscnoaorKWzyt/yVvw/wzzeiTSXpaYiCM80SaOUmrN1+koD35+CInhc3yJhXGFyGhSZq7tALNZE8hlhJVvE3FLGkpxHJRKSlJNYqtY1O83lz2jExGP+M5uaXbLIGBVRALIYG/CE+YGaVtt1rllz25TFasXKHzZx4xRXXUqFE2V7SzVw9agwv+cF9V+sJh79nrVdDfvfBuy5Ef0Ok9pYViz6Sk/GmZidPnkVlHRpnMF3EGocz8VF9i7exr2CTQR4rdR0q7rN6Mvgj9lCIZkZm5jUbmvadWUKwKWpxRqAkgwQ0oNIdUAT2sU1oY0OFZ4POIKKR8ovGwehv4Qs4OXeT3hApB5lbjRRhbX6+u+Evl6quvlpEjRqbV0GXieHfAZ3yW9anlT8nfr/+7LLhzge2Nydd5euqgNlX5zIQ7M0HppKSlRAFeRnQOV33aabRyqU0ORYgldJpmsJim0cVblpI/iUp6J1h7SJqfUsAzpBxpa2klckSysNL4wjdGSbgGbSy1HFiYAnpQ/2IBNf7bb274HTu2G0/20y0EcbXDi/fdf7/NB52/YIFMVuXzkosvlgvVGwE/tmcoD+VTHxTfaWV0PGPGSbJ58wu2QovOYMDTMbIecgo6YUdslIywyCkVCI180DgvU1iPKyf5vG1yQm1J/Ubf2xTQ9vYEUY1Pi2YomtiYTsZVFoWs+ATA9NQE3QBv6ky557SmpFNMy1ksTqkEhILThkL0Af0xTw2GZdTI9I8dO3fIHrVaYA0lHQWUr+ywKGnkyJFq8aymk7b0dhrqa9cz7jC5S76DfPKMGbLwrrvkIbXYJoFnkaQzzSBkBdKTPl/wvJKCyYbquXPHkWN67lzG1IOWSCuU1S8se1oBKs+KT68iaU56mfTYYnWUJrQK3y+p0ISR2qD0NqXHelHqIYc/I49PI5ZJyR5s+rs3s4wn5CrmAP8zxZgjjxceItDP7JOo+u4nbNy4UTZt2mQL+i64YK4pn+TPerxWqOz+KAA0WH+HDh+UKvXkjR8/Xh5Tj8PiBxdz03bPNDurL2Tfr4Pb9KaNFgUBLAwpRVKikhIUzbU9K09qfGokJNP7jlVWpIylt/CPkWlCqzSeTNrTijIUzHhYNKnw+RLH/t4e7Nov0o65zt9QojBTRopHW1dI5Fpyahyo7VL+U9oh/23TdQ2P6XxQXPKDdD3DKboq/qhXPnnkjNrMFahCne1sWAW5Y/sOc3cyMrTPRRpTFIKffV3Ig/mcnuAPiAR9MjwWgnXBgjTLYKkNf5xMQ0zpZ0mNWrNaCNJCemxaziDOCjWU5FYaroJ8zZxSJlFCmsnoyVrA8ofY5dIcW8/KMcHPW1ZQqC3ADSsrQMBqzVXNwTDSOs39rhaZfbo1DPPScA+ueXaNuS62b99ufbRahUndmDHqIpwoM085Rc7S+Z81NckI0Zg5eLk0akJHXugNeTP2H9inbTxLlj/1pL5clto0Flc4TUEpUD7BA2tVgkpao3PAeZJeFsR4SsnHhE4xagX9pOQaOrdAq1pfaqEM+DKiiwMCH3pHyudEaGX3jny23An1MpiDtxjY4QbkQw7b1eKyQRfz2VfgNA+LHfhOOO4+toEhWFn920q1wGh09B8eF+3lyH2zkOpUXdm/Wd8nK1asSDwoiql/7c7ax42GIfOZZyY0lA7enYVkGzKVepY8c0q1oAWNiRcUyOo7bddWrT7AoHFjilw16eetoxPKzLzyaTeX3GHafabFFWlpy5OUMLKXNpkFVPsjH3tgCsi2rVvtHP6jnbjYkW148aoHDrQy7u1reYWl5ex0yyc3jmuCmzeL0tCh9hUM3DT0W1NMNZ1PfZUaSnqoZC69itKaZExRWAndI+GXtP5fWgUQKq0EtSctatyupFXFaDXOX4zhs2g5ozYVLiXeRLFmtgQSrY62wGy7da7n2mfX2ghw9ZrVujp3tbzEQEgfzvHKmNOmTrU5aRN0ftoYVUJrNa6ykgnaepc5Rm6mOe2eTFv5MaAD22PVfXLZZZfrFhtnGz8xxSUZ0OkIGL5q9CgBo7QmZj3f4lS00rR6bBV+8ZJNUm3D/CaxHRDhN9AIwA6p126Z6sOqufZfSitKf05KLPlfQI1Kigd71ekfF3xMXdmqAo8pVWvVurJ2/Xp5XpVPAkKvdmStjFJPwgknniBz1eU3QjfDZiFg4k4Ob7J4veWQSmsTHlQviX4SFldmf51iwK4ZpOFyx+JrCmijB9hc68G9OBb2Ts09ntKftz5ue3CF7YAgzzKpuyVyKqTj+UPS4V2E8YU1J/UmsWDaENL7ILTCuhvyFz9LpVa8YakEm9SdI6zSRfOH7ad4M08obBRFw2uKFwm0I8FCB3266Gjf/n3qUd5sBhX4b5XKuq30R8V0kCqbo9XoN1733p2u2y/NmnW6DNUpkAwW83u7FqmrtUlloHwyL0Y/oafK5+HDfa3joIzi9rQHqaAnjFz44Fp7y0dvOUeohD6agJHGZE4sFa5iiSXUblmVVmsUjtR2tS6S2/dFRrgdFqiLev78+YlwVOasVjdEne7vyQa9J+mqwDF1Y3TriiE2Z4ZvG9s7RfM1fjm2ri1HXEpvhnYgtOGjSl3ExyfV+LJMnbabcMwxyXeYNSPM1eSVWNJb7oganNaPSug/+brT6OQT2/HE29oZ9TcILh5jPniT8hHJST46fxJkKMZ/afmtaGZCkkqy9kW8OvDWM7ptGQO5pbq46PkNG+RFVUTpl+ybyz66p5wyUxXQkcZbEydNtHnKtlK+oqeJ6LReGtxBmZ0y8OupC4p0+zaVa3ymt1/fPjq4TQb6pnSifNqDCx9ec7fhmBcr43kKuLghOqkk65kX5ss3Kehv9sbIzKglmKvfkB621mPDOLJ6fL66IzhJE2etI9eKVmUUCfEobEtGkSRb0cRCSo2vsXaiQ+FpYNCH5Z3fGt3iDMsnWzDBf2ZQUdmGjBilSigDwX79+sO+7Ro6XflE+OFy6YEM71GpTCumiKJ8onl76FovH291y47JMy71SSfs24iJc9UV6+gta1E3yGVwJ0ghIFkRuFuZdN36dbbLwsaNm9S9XicobDAo87Zwt7MojonaMG5f/fXWVeMoeW6Yh9k7UwllThF9gjbAV730M2qsrsXVvn/fXnNzNuo5ufzhE3dbeBjX/DmApvXG5ks2zlE6DRukNibS7FXqM9JbKI13Sm9rsw1rcQaecwrmGU2y6JTsVp32gcxQJCmzDAnKB/DV4R6HZI/2u7/rYrf5d86X9c89Z54tdjU5TVe/s9n1VLV2DlfFs0q3WOo/oIrOa6S5w9ZWX7Rt7ZxI823PRFOc9Xvoh/oaPzL/OpnSog2wGyv17jR/s0UaMjScpdxw1jMvUqhIUpMKsvJ6PF0xDB4fxrX2vC1ptbYNbVLOQcri22KVKP/hyePduEEHe/+88UYzqmxRpZO+iRyboDJthlo6T9Av+NXWjpJButUZiwCxzBOsi7QjmJ2ufHJvhq1KbxXhesN8c7RXAlxOFLTj/RvI5fCnNKGXtDj91dwaSuWAQAe3QTud8qX1MFM+1S24v2qfzTmrVZffoOqBcuYZZ0p9fb0MHFhtrgnmpPVV5uQrSCifvXWOMt/IrVBmRZmxfpr1Uu+g20t4JXlbMVWF7ZT6quuPNh7Q9vJCynFcB7Wo/avhBcsdlxISd25BCSWir+uCyHhZKgIgiJKFuw+rJ3PMFi9ZbAuKcPExXYU502fOnm1bwDDPs1L7aO/eDOj6Sp/KPmYVdZc7nMUTTn/fldq6jslvgz/16FX26GXvhYqKXrbq3xSC2McMgchp2X3RDdOtw0i5Rd/z8B8GPOYbs5iIY41OaxyjxpSpOn0MiyfTxgYNTJTORKYlcg2vBOtt2pPnOl35dPi5SZujpsIb62coUFxB9bxH4zGx3rSuqx2NeHTUPWFcd4WMLYnGquuBvTv37Nkr48eNty9DMC0ERbNPTvFkdIg7rZfO9UyYNBkpdlSbm6unYW5WwlO0EVdfhc71tAUeaN0+okvrcp7WXEVlkp4MIkprjL5iGjDwoopFg6/FI+OxNQjAU4d0j0+UTzwE9apw8n7Hxc78stF6PW7CeOmrnoPeuu0Lbr7eeW9CMqBj8ORdseGsNa3p+DLJGFQXy9LR9F3BvcOHybsmGf51fKtijV0KAV5sNuyi1c4JLbkDrJ7JdBf4j2ljI2tH2nZ7k3RKy7ix46S+rs4+koIs66OeMTOsKB8yR5k1DPlF3jShlKpb0rxcnvJQPnM3l5/cqtdpMrGE++pyWaPy2TmP7LAKh0MHdVuUQxW2qfXw4SNktlo8d+/eZcoaFgush31MQPZTFzYWGjZorzBrYjJgou1unemc+2haa8JBZj1SqyeC/JCN6prm7OoxrXlXZL1PW0Orq+PXHu1HyTpwoKcuGjpgnoKLL7nYNlmfPGmyfZABZbNflQo+FXZV6klACPKRETwJlcpfTGXxqRG8G/28PdraXjRRQG1bGz0mc7C1dyX/26vKSPeoQ6B0rw4uPZRP9tRldTuehrlzL5StW7ZIfX2dWj9rjN/w4vEhlX79kWvwYh+b8ohRxfjPsOSNmPW2tAyt/lMWymd+VBvcI6fdSRAktx4A0OpHGgsWRUD33tu7R7d6eWmPHKNWl+pB1cpoh6WnMun+3Ttk1849auGstu0m1HehlgtVMnVREQonFhwWxuHCdit9ni/LSEAi9Bg0I7AR3KaAsmUZymcMEYECBNriPcum8Yf36/ZJL+yTQUMHqetc3c10xH0av3e7jB0/VeeWTVEB19vmlPVSK3xvPe/TT62euNyZO62DPNuJwRbEJY30PlzQ5LK+DBVlVAfbSF6hKCf/SFs887J+CN2qcfo0Dx+Q3Tt3677U+6VK525W9kKr0nhdy9BPeXHatFOkV281olRWSC8zqFTo7kI6zcUsn8naBQwqWDyRE/k+DA+3UygL5TPr3trvtrNq7MT4dnzInXhXZVf1IbXE7Nysn7l78EF57uAQmTjrfJk8+KBsePwB/fTkctnUV+ejTT1RJg7TzeNVcUPRZBQIY8K0bunMM6ffYZl11rB9SdcqswY6bvHY6QjQM45EGaG8zu7UPy/J3dfNk+rT58pZJ9dJpegg74U1cscN/5IDY8+Ts6cfr5/XxIrJ3s0q/FA+9ceAzgUe/JVYWhpaFPblTgerxAakGVZKJNGm2UE1vgnaFNJOJZY8y8Q6un3DSrnn/qXSf9LZcu70UbJ/5xZZ/8i9suSZLXK4dqrMqhshFTqZlG2+kGcon731M6/Gf25QCfqHL15trxssa+WzvW460u3OCCjjYYLYt0GeeGiZbNxXJQNmDpZ7b79T7nv0BTl+zmg5bcggqe6vW6Pom9otnLit8xOwu9DbuysL7u7cSzv63o+0S9uXinr3l2O2LJe//HWf7tN5hQzctkhWLH1Ubrrnabns5EtlQPUA6cU8TpTPCl2MgxdBhaDxWHDDDJbcch9Ex9M2ROBIn3cbNiWSOkIEmOPfQ7cLqqw4LC+sfkTuW3VAjh/2cjm8/lG5Y94CeWaPLp498WwZqPzXU5kLfsPL0Et5jylliYxjcVHjUHjdOPXIr6LyeeQYRgpdCIEe6kbvP7RWxk4/XZ5eeZssXXSr3LanTlatV3f80Bly4vixUlfTX5kSp4WynzJrD5WEeSWuvTmyC2EZmxoRcATYq0R6DpTTX3mOXPs13VbprhHSe91CeXHTC9Jv+kUyY4J+ilZd7MY+CMCeLIBjXmfi4nO2Sua+J1NGnHY8th0CjnPbUYyUOhsBl03Vw8fIpPH18uRtD8gtt4tUvbRGHnuxn9RMmCozxg+X/n17W1PJ7+51jCrYwjujX0Tls7N7Tqy/QxEwxqscIDWjJssJU9RN8dAN8pcn18j06efIbP1U5uQJtdK/Uje2znn9nLE7tJGxsohAl0MA8VUhI6acIXNOul3mXfcH2bG/n1TXjJY3vnq21A6tVktnMufYBJ3+8a2UYDZ38UV+63IPPja40xFIJlNU9Bkok6bNkNrFD8k//vx3Gdr/WBl1wlly2rkzZeTg/tJLB3wE/sJn9tPznKgjqUNDXIHQoXDHyjoXARVyymk9euiXf/oNllHjJ0lN/77y3MptUj16vJw1q06GD+uvTWxgUmuvM6oeY4gIRARSEFDeQIj1VIF30QUny+qnlsravYN1rtlpcvrEEdKvd8NiBtx8tgjH+Mz8CykEY1REICLQMgQSuXT4cE+pGTNOt1IaLS8tf1ZWbauS2onjZMbUWundK3GvM7c6cbPnZFlOtrWsnrbNFZXPtsUzUitrBBjtJQ08uH+P7Nq+SXr166lfMBokB3Y/L6s2bZcde3ThhIZwZBhVzgSz+DciUAwB45Mee2Tlgyt00d4MGXPMFhm0frFs2LZHDhzCtac5csIuz18wJHHFCMe0iEBEoFkEYKVdL23SL4rtUMPKGDl+0HbZuXOTPLdll5WF5wr5r1mi7ZghKp/tCG4kXX4IMKfs0N6tsnnNw/LAokelx9CJcsWVs2X76jvlt7+9RhYtWy67407j5ffgYou6BAJrl1wr/3ffVnndle+Wq88ZLlMrVsi1v7tFNmzdaZbRqGR2iccYG9kFETi0Z7M8dv9CWbr2sFz29tfJJWcOlmcW3yw3zLtJNuw8YAO8cuK/qHx2wU4Wm9xaBFTxPLBLNqxcKvfc/G95atUemXLGq+WiOefJ1NFVsn/VfXLPwkdk+Zqtra0glosIdEsEDh3YK/tfWinX/+2/0nfGefZp2kvf9Bo5/5Vny66H58mti1fKLt3zM4aIQESgjRHQvavl0G5Zt1xXui98QqqOny0XX3ihnDfnApl23CF5fukiWfjgGtmvn9sspxAXHLXiaWA9e+CBB2ThwoXywQ9+0PaBhAzfMP7rX/9q24e8+c1vLokyXyJYtmyZ3HXXXTJp0iR5+ctfXlJ5Mi9fvlxuvfVWWbVqlX3Z4GxdQHPxxRfb1wyaI8Y9bdEvIKxZs0ZG6fdea2pqmivSBdNV+Ty4T7a9sEnWPL1Rqo6bIlNOniyD+myXM2edKnv3VsjqbXtl44btInWDuuD9xSZnIbBnzx755z//ad84Zt/WWbNmyTnnnCN8UrVYeO655+T3v/+98cPVV19te+IVy9+eaXwqb/HixXL33XfLq1/9aqmvr2/P6kqiffjQPjmwc508vv44uWDuFKkZ1F/6VE+T0Qcr5MwJ8+XJtVtk7/5DtpivJMIx81GDwOOPP27yETl5xhlnyKWXXmrzD9vjBh9++GGZN2+ebNy40T4Q8rKXvUzOOuss+7pWS+q79tpr5bzzzpPjjjuu3drYkna0LM8h9Srskc0bNsmu3T3klNOmyeCBQ6X/4UnyyvNmycGFz8va1Zvk4Jl1uX12y8P+2fNzn/vc/zNXJN/iLfjxsjtw4ID9UI5IZ0PSQYMG2a9lwBydua677jr59re/LR/4wAdM2eQut2/fLp/61KdMiXzLW95S0o3v3bvXFFoEHZ+5glFKDf/73//kP//5jymPI0eOlLq6Ojlev6PMXnoP6qbqjz76qAnb/vo5O+Z/kH/nzp1y7LHH2rP929/+Jr/73e9MqI0ePbrU6rtEfttjsLKfDBk+WiZMn6afHhshfXSvs6rqITJ8lG6zVD9W6kfXyMCqZFuKLnFTsZFFEeD9tmHDBvniF79ogoT+f/9998l999+vuxxML6qAMpD7whe+IC+88IK85jWv6XTlE56FR2fPnq1zlcuJR9k+qVKqh47WBQ7jZPCAPnZd2bdKaoaPlFH1k2T0sdW6vVJ5CL6iHSYmtikC8NBvfvMbuemmm2THjh2mTyCPnnrqKfv06ogRI9q0vscee0x+8YtfmCFl3LhxgixkoDZ8+HDj35tvvtn4eejQoXbNu+GXv/ylfTqZOAann/zkJ+XUU0+1MizQKe+gPKVbllWoXDvu+HqZMHm8VPdl8/hKGTB4mBxbO1blXK0Mr6myHSZs7mcb39C2bdtkq/7QE8ELPdF/vpcvuPqPPNHy2ZqHoMIMRXPTpk26erphowLOGWlVV+vXcVoRKI/Cj5Jfali5cqXccccdZuVE8eV7rgTvaFhUV6xYYcooyibxWEmnTp1qP67Hjx9v8Vg+j8rASvdjesvgEfUyeHgd4Oht8vwqpd+Q42Wc/saSR6N5Fo7dUYlFN7spBlkIGQaLM2bMkHvvvVc++9nPykknnSSvfe1ri3oHGIDDl+UQ/B3BsVyC8coxumF8/5Fy7vkjcnyDQOwpvauGSN3MOTJGmQpui6F7IQDvPPLII3LbbbfJG9/4RjnttNPMEkncv//9b/NGIIMqKyvbDJgnn3xStm7Veceve51cdNFFplRC3N/n8+fPt4HbxIkTje+xyKJ8IvcmaRxK0zvf+U679jJt1rh2IJTsF9FHtw8cLzW14/JyrUevvtK/ZpxMyTkxTdy1Q/2tJdli5ZOH0BUeRGuBaItyoUCA6R566CFzM1xwwQWCVbGffkcVi+brX/96U25wc8OUt99+u40IUDr5hrgHhOW//vUvuV8tNIMHDzY3AK7CZ5991tyHKLkwMQG34n//+18Tkrt27cpbc17xilcYMzEdAGV5/fr18u53v1s2b94sN954o00duPPOO+Xtb3+7CWdc/whkRjJYWBg54sJg9FpXVydXXXWVKbDc69KlS+VPf/qTjSKnTZsmY8eOtTouu+yy8rSM04cdXD1PCxnRaVljXBdEYMiQIVJbWyu44fr21ZezWkEZhT/99NNmLUFoEcd0lXPPPbfJHS5ZskR+/etfy759+ywNgTpnzhzjO/gFnsRVj5cBfkfZZVBHeOmll+RXv/qVeUa4xhLz8Y9/3HgXyxCDQ39HoBDTrrVr19o7BL4cMGCA8S3Wg3IKoVxINq0OW6c8x1eNwqh43m0QoN/iwsYDhzIIbxEwjiCL4BmmwKDwwXtveMMbLB3X/C233GI8ivv7nnvuMVmJB6JO5dDll18uJ5xwgvEtRpcXX3xRhg0bZvWg1CKznAYE4VFc/eRFTmKNg5fx4j7xxBNmJf3pT39qR2QhCuwpp5xibfn85z9v5THgwI/Ivo9+9KOC8gqPYu378Y9/LCixyO/TTz/d6v/0pz8tvG/aOzTwn3JZigDrSN5zPdGPxe69qPLZcFPFSMS0NASwlKAk/uxnPzMmOPnkk62T/+AHP5D6+nqZPHmyLFiwwEZ+MAUdGlfEunXrjDFQPP/xj3+YoIIJYC6YhjlqKKl//OMfjWEZNZ544ok2XxPGxmVPfpgU5RLmQhlE0FEHiiVuCAQZFlBeCjALTEJ9KKm0h/y4SWAsRo+8LEinT7zrXe8yQQrDUR+WJCzB3/nOd4zmhTrZmXpjiAiUEwL0fwZaKJr3qdsdYQX/IDDgKwZQTH+Bb1EGZ86c2aT58NiUKVOM9/AcfOUrX5GBAwcaDzAHnAEniiPufBRNAkKIOr761a/aOwBBCB2UX/j0e9/7ngniuXPnmuL685//3GjC1z/5yU+MJoIbYUrbYogIdBUEWEOwevVq+chHPmI84DoFyh9KJPIFOYjrHXmDPMI6itLK1DZ4EkMO8o48yE3mPMMH73//+40nbrjhBjOWvOMd7zC5RT5+8Db0mIqGoomcwkAC3zvPIvdoA54QlEl+WGGhyboL5B7tYLoL86xxxaMw45b/61/+IhWqNKOcMp+cgSS0fvvb3xqff+xjH+sqj+nI26l6gT/bkFhanKc3UT7J7D8yFRYuvHZC8dgYAXCCwVDCEBwodFg4r7/+elMKSUcxZd7We97zHpt7SRwKKMolVhBGewhALJWM5H74wx/ayM2VUQQaih55Fi1aJMxXQbG84oorBDe800JY8kPgMW8NoUZdMDIMiYsBZRnhTDyBI+2HNgstSGMuDZZarEaMShnpffnLXzblFaGLstuaKQONkYtXEYH2Q4A+zMI8+jECiH7Oj4EYVhcsGVg4GIQh5BA+zhO0qk4F5lvf+lZTHOHtD3/4w+Y9gI8QkvAWiw2ht0q9BQgx+JFzhBjzR3kfIODgOYQs9aHEnn/++SZUEax//vOf5W1ve5sNODnCo3gj8HAg0GOICHQFBJAHLF7FwIE8CQNubviJeaDwDconLnEMJAwSUeSQW8g2FMb3vve9plSiUOJJfOaZZ+zavYKvetWrjO/wyEETWedePKyq8ByeRxRM6n3Tm95kbcOAAp/Cf3gpuQ4D7wT4F+WTslhcMchsUZrUzSCTAeSVV14p+9UjghVX19I0ud+Q5tF2nmgN6Xfl79jwPUrOxr0hvazFOoEiWbpVEh0yLYQKHOlYGHEbwEi41GBARoIIGJgEhqGzwhisrEOBxG2OMjdfXQQISlbW46LHYsNzwHKKcGNkh1uc8gTqTjtaZC6dPIVt9PTwSB7ce2eeeaaNJmFeGBYmxFrDSwJrERZS7on2oEh7G0Ja8TwiUA4IwDtYM9hNAuHxjW98Q772ta/Jl770JVMEucaCj4WR/o5wo8+HgQEdlklokRdXOoKOfo/yiZClDG55+BMlknT4BcURD4gLN5RPpsLwu+aaa+QPf/iDlWPgyXuAdpAXSyr0eX8gyCOPhU8knpczAvAJ8gwXO9Ndwikj9Hs8fBMmTDBvHbzBmgnykwYfYfnEw4BlEhlIYBBGHmih3DLVBSUTGUQo5I/C68I8pIc/IxL8IQ1LKoNN7gcFFpkHX/sRRZa0yt69TYnlXdDdAvfvv5bce1HlE0KFD64U4i1pQJfMo7jgViOEnQxhwlxKVqKmBcfOOzr53VIY4sw58VWquGJ5ZE4MgY7OqI86sHpi5UQgtSRQNyGsx68L4yxjwR+UbZRcV7q9jZ6N9vLzejw+HiMC5YQA1n68ECiCWD/v0AEeczSZQgI/MqeaxUlYPUO+oO8zJebrX/+6KYgs6mMqDPOxKefB+z9HFEcfGHq88zv5iYOf4GFc8bjhPZ5BHe8W2gB9L28Z4p+IQBdBwKeWYKlkMOZbm9GnMcLQx3Flo0Aiz5ja9aMf/ciUVeQovAGPwLd4+TygCKKsQuNIA7xVjL/gQefjsC7uAaMRZTl3xZqpO90xJBpGy+/8mCzg/WH00AfPj+BxLSd/dOYEBxRCGIO5IIzE+DGKo5N+6EMfaiS4HAU6MT86KdaX89XMz2RnGJDyWFoQhLjHca1jdYTpcB9g8r/kkkusXp/3Ca2WBpiEOqDvzMF9+OgTy2xLAkyGu5KFR5R//vnnzUJD27mXqIC2BMWYp7MQoO9jsURxZGoKbjP6NFNcWGCElRGhRj8O+QuehVewwNSpReZKdaUjLKHlA7Lwnrys8zt0mV8Gv2At5Ydlk/oRvHg94G/4nB/eEupEuOLWw8pCGZTm+B4OkY7n5YwACieL8phzifUfjwI8w1QTn9OJHISHWByLFZT51lj4UTaJR6bCt6TBR/AHZdzSWer9wz/Qg//gc+Q48pFr5KDzbkvoMsBEHjKnFZroACywSlNWW0Kvy+ZRTPXFlH83md6Yu057XxGXavn0zBzRZu2nnaCHPqi0F22XBayVDadzIkiY1/Gtb33LJiCDFR2Z+VwIL9xudEA6JsHAVssl1yiXzHfBBfj973/f5lSSziiRslg1WSHLPDLmVsKoWD0x/TOvhHNokI9yBOJw8RPPM/Jrt6ag7DKxGzcjzM8iJBiclYG8GNgsHyZEEPpoDiU3ZCIYzevgxcCKwG9+85vWDurFVUi9pTCvNT7+iQi0MwIocvRv+j9WEwZ8KKCf+MQnbD4ZvIDQwJLJlBiUQvo+vARPwGvM/0T4wY/v0nnY8Ds8CV/Ah86T3ArX8BFl4Qnch1hyvvvd71o7aAv8xb7A73vf+4SFiOwcQX7oMM8bwc3iPuJZPQ9NlFC8H9CMISJQ7ggwV5M50gT6/jU6vYR+jAsd6z5yB94jrl6nk7EgCCUQvqqrS6avwHNYQz/zmc9YHniXNJRa+ABeCuUUfEccPE+AP5HHrrsgu5lfygcbqJ/5pngy2cUCnmbut/Mt7UJmI/e8PDR5h0Cf+tlTlMVPKNbk4V1BfHfiUXDK/9AVFSO/Bq+00ENH0ocZ+fNA+aH5+zmaPCPt3frjeFDTUWZQnHgBdueAgkVnQ6FjDiRAw0RMRmYeJulYSlhQgEWFaxiOhUMoaUykZpTEfE6UQTpqnTIUggdmQdBhJaE89AkwJIxCp0dAQgfrC9fQZn4oZZkUDQOziS9MxIiRdGhRDkFI/eRn0RB5cUXCoMzNIQ3mYhsn5nEywqRPMBeNeyIdwYnliDooR//4i67+o40sqmjtqLQ796l47+2HAEob8zWx/LtSiVDxbV5QOuE3+jk8RBo8SD9GSCHM8Eas0jnP8CzvSd6B8DVz2RCa8AtKK+WIhx7eAOajwYfwG/O2UXp5j5IXCyfvWd4jtJF3MVZQBp68T5gD52m8G+A7BDqCGiEaQ0SgnBGAD/jBd/ARcggeo2/DMwywPKD4OY8gw3yLMvKzPgJZA9/Bv8gZZC3KHjILPoUvkMNcI5vhS/gOOeX8Ct9RB22hXcg9+Bi5DP8i21BEeR/QNt4DLH6iTqYHoNgSMArxBUF4kjrZEpE6kOPwMEot8pJr0o/2wJQkdAubi6v3zDu0r/44ooyjo4AhePjRlE8eOg8Y8PhxDoCufLoC6sonD7W7K5/emejA4EQHc4uhpxU7Us4DWHMddlSuocmR58ER+h7vZVt6pBwBWjCsj+K8bjqHxzVHE1oonCjPlKNzMf2A1ftsd8EebDBlDBGBckHA+Yb+7v3chUKYxvsPPvM8Yfudh6DBO5OXaCGNMH947nVQDt7xl7HHc4Qu9bu3wus7nHs/s60L9XmdIf14HhEodwToz/RvjsiMlgby0+ezeKeldMjnPEU7oInM9YAch6ed91vCZ9DDOAQ9yjFfHG8mW7kxRae7BJRPfiifx6hO4IonyifvU3B2xdOVzwbkcygBuIPu5xx1cqjoG9MA9vTuAmyx+wQLAC41hBiGDOB0PJ0jD8uDx/t1S49eLqRF2bS6m6MJLToaLkxGmNw/1hwWRzEapOPFEBEoJwS8/6P0FYYwLS3d83u+NJ7xNM9bePR0BFT4vvB4jtANaefTtM2VKe0urCNeRwTKGQH6M4pIqcH5IIt3SqHntNLaEfJlS2kyYOTrSExdwyuBZZe52Xx625XmltLqyvnANf/TG8mfh/F6HoYKfxhEFp47AR46P8DkGOYLicXz7oEA/QC3Cft/YhWnTyC0cTcyDYCRTwwRgYhARCAiEBE4WhFwfYiFUrjkMexgAUUJzdrx5mjFArXS9UTXEV1/zNIXzfLpmQDGz9OOTjyL2NEKbLyvxgjw/JlLw7Y0MUQEIgIRgYhARKC7IeA6EouEu3sAC9cP/ej4ZB0bud1DAsyvcCIcsWyR7sfuDna8/4hARCAiEBGICEQEIgLdHoGcboh+GOqNnLte6UqoY5VXPsMEz+xKJwSdKHOSSI8hIhARiAhEBCICEYGIQESgeyPguqLrh6HO6Aqo65iuP+bnfHoCGZnL4PMZnCjEiHMltHtDHe8+IhARiAhEBCICEYGIQEQA/dEVTj93pZOj/1zPBDFTPj2i2BHC7oonXwwRgYhARCAiEBGICEQEIgLdGwF0QlcwXen0uCy9Mr/gCOgKlUovjOLJlgJ+XZive8Me7z4iEBGICEQEIgIRgYhA90QAnTDL8hki4rojx0ZzPsmE1hq63d3iiS+feI7kiSEiEBGICEQEIgIRgYhARKB7I4BOiG6YNeeTdNcbXQFtZPkk0ed6AiXnuNpdGeVIQb4EsG3btiZpYT7OnUZ4tEj94+l+HY8RgYhARCAiEBGICEQEIgIdi4ArhF6rX3MsPPc4P6I3st83wZVPjm4J5Uge8ocKaOqCI28AhUIlEUWUHxupsos/R//UHEf/kYdzV0a9HHRDeuG51xmPEYGIQEQgIhARiAhEBCIC7Y+AK5fU5Oehssi5/woVSq7ZXN91PJRO8hbmc3qusHJs5Hb3BDISUA4hAmGOpPNtcL5NzJFfqHyG194YaBzSH98ndmXTj1ZJ7k9aXJgezyMCEYGIQEQgIhARiAhEBI4MAXS5wuBxpgeicGoezl3xdKXSrZrhtcehJ3q8nxu9HB0/p+5U5RNF0DN55a4cujLq6VREIJ00QpiG4nmM/g6pJdSD0/JrjmlxYXo8jwhEBCICEYGIQEQgIhARODIE0NEKQxjHJ7K5TlNA0fn857oeR1c2PY1jmB6eU3fe7c5FYSKF05RKz0u6u9dDlztWT8r5L7ymbBii0hmiEc8jAhGBiEBEICIQEYgItD8C6HyFwfXAQuWRa34omfzI5+dYPt3l7nk8P0enGR7zyidKoCeQGYWRowfSyIOSyTlp7nJ3F7sfXenk6IondDzeacZjRCAiEBGICEQEIgIRgYhA5yPgOiAtcT3P4/wa3S/8ucXTXe+ez+P92uk47UZudyIh6oonyqIHCnLthMgHcVcuXfH061DRLDx3mvEYEYgIRAQiAhGBiEBEICLQ+Qig3xEKFUW/DpXOUBd0fZBjYXxY1s+po9FWS0QQIBAqjMRRyJVPJ4DlEwXU87oC6tccPXicX3MM08P4eB4RiAhEBCICEYGIQEQgItC+CKDPhcH1O+IKz0Pl0suFiqenk8Z5eO20/Ghu90Il0ImmVV7YSFcqUTy9Qo8L6XpcWD5MD+PjeUQgIhARiAhEBCICEYGIQPsiEOp71OTKodfq1+GxUKl0RZNjSCMs4/T82MTtTgJKIYUITsyVx7BSj+NIPEeUUIKn2UXu2s85kh5DRCAiEBGICEQEIgIRgYhA5yHg+p63ILx2BZK0UP/zeD8WpoXXlPV8HAkVKIFcuDLoCZaa++OKpSuUnpfkwri065CWn4c0PC4ehljBmgAAAK9JREFUIwIRgYhARCAiEBGICEQEOg6BNL2P2tH9PJDH8/m5X4eKZpjm59DwvH6et3x6BEphmCmMDxVLz+Nx5COkXXs8R8qRJ4aIQEQgIhARiAhEBCICEYHORyDUzVy/4+jntLDw3K89X3j0/J7HrzkSTPlEGSSDH5Okpn+dSKhghueU4DoMhddhWjyPCEQEIgIRgYhARCAiEBEoPwRc5/OWhdec+3V4Tt6seE9DL/z/jbVc/ZxblKwAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7b533d39-a950-40cc-b529-05216c6872d8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Q7 Student Answers:\n",
    "> __a)__ B. 1000 most frequent words would underfit, while 1000 least frequent words would overfit.   \n",
    "\n",
    "> __a-bonus)__ The 1,000 most frequent words would most likely reduce the quality of synonyms, while the 1,000 least frequent words would most like increase the quality.  As a side note and expanding on the results calculated in Question 6, the 1,000 most frequent words should produce more neighbors compared to the 1,000 least frequent words.  The choice between word frequencies relates to overfitting and underfitting because the 1,000 most frequent words may be unable to capture the relationship between the input examples and the target values, therefore, performing poorly by establishing relationships based on word frequency rather than semantics.  Moreover, the 1,000 least frequent words could overfit the training data resulting in good synonym detection performance among the training documents but poor performance on new documents.  Similar to other feature selection decisions I've encountered in the past, there is always a balance.  \n",
    "\n",
    "\n",
    "> ![Screen Shot 2021-10-03 at 2.20.44 PM.png](attachment:9777b34a-cad2-4fa4-bb34-90ff6d67bf7c.png)\n",
    "\n",
    "  \n",
    "> __b)__ Tallying up word counts from a randomly sampled subset of documents/data is an alternative strategy for generating a basis vocab compared to computing the full ordered list among all the data.  \n",
    "  \n",
    "> __c)__ The basis vocabulary can also be described as features because each word is a measurable characteristic contributing to the calculation of similarity metrics.  Two distinct feature sets/basis vocabulary will most likely result in two different similarity metric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b853bc36-399b-4f21-af49-697c2019f6a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part c - provided stopwords (RUN THIS CELL AS IS)\n",
    "STOPWORDS =  ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', \n",
    "              'ourselves', 'you', 'your', 'yours', 'yourself', \n",
    "              'yourselves', 'he', 'him', 'his', 'himself', 'she', \n",
    "              'her', 'hers', 'herself', 'it', 'its', 'itself', \n",
    "              'they', 'them', 'their', 'theirs', 'themselves', \n",
    "              'what', 'which', 'who', 'whom', 'this', 'that', \n",
    "              'these', 'those', 'am', 'is', 'are', 'was', 'were', \n",
    "              'be', 'been', 'being', 'have', 'has', 'had', 'having', \n",
    "              'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', \n",
    "              'but', 'if', 'or', 'because', 'as', 'until', 'while', \n",
    "              'of', 'at', 'by', 'for', 'with', 'about', 'against', \n",
    "              'between', 'into', 'through', 'during', 'before', \n",
    "              'after', 'above', 'below', 'to', 'from', 'up', 'down', \n",
    "              'in', 'out', 'on', 'off', 'over', 'under', 'again', \n",
    "              'further', 'then', 'once', 'here', 'there', 'when', \n",
    "              'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "              'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "              'nor', 'not', 'only', 'own', 'same', 'so', 'than', \n",
    "              'too', 'very', 'should', 'can', 'now', 'will', 'just', \n",
    "              'would', 'could', 'may', 'must', 'one', 'much', \"it's\",\n",
    "              \"can't\", \"won't\", \"don't\", \"shouldn't\", \"hasn't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f3bad8f-3d76-401d-8687-e16db841de68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part c - get the vocabulary and basis (RUN THIS CELL AS IS)\n",
    "# \n",
    "def get_vocab(rdd, n_total, n_basis):\n",
    "    vocab, basis = None, None\n",
    "    ############# YOUR CODE HERE ###############\n",
    "    sw = sc.broadcast(set(STOPWORDS))\n",
    "    top_10k = rdd.map(lambda line: line.split('\\t')[0:2])\\\n",
    "                 .flatMap(lambda x: [(w, int(x[1])) for w in x[0].lower().split() \n",
    "                                     if w not in sw.value])\\\n",
    "                 .reduceByKey(lambda x,y: x+y)\\\n",
    "                 .takeOrdered(n_total, key=lambda x: -x[1])\n",
    "    vocab = [pair[0] for pair in top_10k]\n",
    "    basis = vocab[n_total - n_basis:]\n",
    "    ############# (END) YOUR CODE ##############\n",
    "    return vocab, basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "817d0400-d9a5-4f5f-9fc8-106fc2614c75",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 205.97088837623596 seconds\n"
     ]
    }
   ],
   "source": [
    "# part c - run your job (RUN THIS CELL AS IS)\n",
    "start = time.time()\n",
    "VOCAB, BASIS = get_vocab(dataRDD, 10000, 1000)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 268.0176115036011 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "320fa840-3dd9-40ce-9584-4e7861d5b8f2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part c - save to file (RUN THIS CELL AS IS)\n",
    "with open(\"vocabulary.txt\", \"w\") as file:\n",
    "    file.write(str(VOCAB))\n",
    "with open(\"basis.txt\", \"w\") as file:\n",
    "    file.write(str(BASIS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e26c9657-5646-4835-b065-489c874ad30b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part d - spark job\n",
    "def buildStripes(rdd, vocab, basis):\n",
    "    stripesRDD = None\n",
    "    ############# YOUR CODE HERE ###############\n",
    "    \"\"\"\n",
    "    1. split ngram in grams\n",
    "    2. generate co-word permutations\n",
    "    3. drop pairs with same word and co-word\n",
    "    4. filter pair for co-word in basis\n",
    "    5. filter pair for word in vocab\n",
    "    6. place co-word in a list\n",
    "    7. reduce co-words into a list by key\n",
    "    8. produce set from list of values \n",
    "    \"\"\"\n",
    "    \n",
    "    # create set from basis and vocab vocabularies\n",
    "    basis, vocab = sc.broadcast(set(basis)), sc.broadcast(set(vocab))\n",
    "    \n",
    "    # spark job\n",
    "    # added != operation after f1RDD returned unexpected results\n",
    "    stripesRDD = rdd.map(lambda line: line.split('\\t')[0].lower().strip().split()) \\\n",
    "                    .flatMap(lambda gram: itertools.permutations(gram,2)) \\\n",
    "                    .filter(lambda pair: pair[0] != pair[1]) \\\n",
    "                    .filter(lambda pair: pair[1] in basis.value) \\\n",
    "                    .filter(lambda pair: pair[0] in vocab.value) \\\n",
    "                    .map(lambda pair: (pair[0], [pair[1]])) \\\n",
    "                    .reduceByKey(lambda a,b: a + b) \\\n",
    "                    .map(lambda pairs: (pairs[0], set(pairs[1])))\n",
    "\n",
    "    ############# (END) YOUR CODE ##############\n",
    "    return stripesRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2a70b273-fb86-4f86-8111-a3480ecf18a7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('best', {'times'}), ('worst', {'times'}), ('foolishness', {'age'}), ('age', {'foolishness', 'wisdom', 'times'}), ('wisdom', {'age'}), ('times', {'age', 'best', 'worst'})]\n",
      "Wall time: 0.13530802726745605 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n[('worst', {'times'}), ('best', {'times'}), ('foolishness', {'age'}), ('age', {'wisdom', 'foolishness', 'times'}), ('wisdom', {'age'}), ('times', {'age', 'best', 'worst'})]\\n\""
      ]
     },
     "execution_count": 1119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part d - run your systems test (RUN THIS CELL AS IS)\n",
    "VOCAB, BASIS = get_vocab(testRDD, 10, 10)\n",
    "testStripesRDD = buildStripes(testRDD, VOCAB, BASIS)\n",
    "start = time.time()\n",
    "print(testStripesRDD.collect())\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 0.1581110954284668 seconds\n",
    "# Expected results\n",
    "'''\n",
    "[('worst', {'times'}), ('best', {'times'}), ('foolishness', {'age'}), ('age', {'wisdom', 'foolishness', 'times'}), ('wisdom', {'age'}), ('times', {'age', 'best', 'worst'})]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2d6a2071-70d0-482b-9290-4e91d9f543d9",
     "showTitle": false,
     "title": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2132:============================>                           (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('zippor', {'balak'}), ('zedong', {'mao'}), ('zeal', {'infallibility'}), ('youth', {'constrained', 'mould'}), ('younger', {'careers'})]\n",
      "Wall time: 4.377715587615967 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n[('zippor', {'balak'}), ('zedong', {'mao'}), ('zeal', {'infallibility'}), ('youth', {'mould', 'constrained'}), ('younger', {'careers'})]\\n\""
      ]
     },
     "execution_count": 1121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part d - run your single file test (RUN THIS CELL AS IS)\n",
    "VOCAB, BASIS = get_vocab(f1RDD, 10000, 1000)\n",
    "f1StripesRDD= buildStripes(f1RDD, VOCAB, BASIS).cache()\n",
    "start = time.time()\n",
    "print(f1StripesRDD.top(5))\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 1.55739426612854 seconds\n",
    "# Expected results\n",
    "'''\n",
    "[('zippor', {'balak'}), ('zedong', {'mao'}), ('zeal', {'infallibility'}), ('youth', {'mould', 'constrained'}), ('younger', {'careers'})]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "470096b5-c854-4a3a-b8b7-50e45cd23c72",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1856:=================================================>  (182 + 4) / 190]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zones\n",
      "['parks', 'warmer', 'saturation', 'gaza', 'environments', 'buffer', 'localities', 'remotest', 'adhesion', 'residential', 'subdivided', 'uppermost']\n",
      "-------\n",
      "zone\n",
      "['penis', 'articular', 'avoidance', 'ie', 'cracks', 'poorly', 'southeastern', 'accumulate', 'trigger', 'tribal', 'atlas', 'transitional', 'sandy', 'masculine', 'flexor', 'excitation', 'assisting', 'parked', 'uppermost', 'auxiliary', 'saturation', 'vomiting', 'cartilage', 'defines', 'traversed', 'intervening', 'illuminated', 'glowing', 'originate', 'guides', 'contamination', 'au', 'fibrous', 'alaska', 'diffuse', 'persia', 'buffer', 'officially', 'unusually', 'penetrating', 'turbulent', 'residential', 'narrower', 'subdivided', 'inorganic', 'americas']\n",
      "-------\n",
      "zinc\n",
      "['phosphorus', \"alzheimer's\", 'metallic', 'transcription', 'radioactive', 'wasting', 'ammonium', 'pancreas', 'coating', 'hydroxide', 'dipped', 'leukemia', 'dietary', 'insoluble', 'dysfunction', 'burns', 'diamond', 'weighing']\n",
      "-------\n",
      "Wall time: 364.4752621650696 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nzones\\n[\\'remotest\\', \\'adhesion\\', \\'residential\\', \\'subdivided\\', \\'environments\\', \\'gaza\\', \\'saturation\\', \\'localities\\', \\'uppermost\\', \\'warmer\\', \\'buffer\\', \\'parks\\']\\n-------\\nzone\\n[\\'tribal\\', \\'narrower\\', \\'fibrous\\', \\'saturation\\', \\'originate\\', \\'auxiliary\\', \\'ie\\', \\'buffer\\', \\'transitional\\', \\'turbulent\\', \\'vomiting\\', \\'americas\\', \\'articular\\', \\'poorly\\', \\'intervening\\', \\'officially\\', \\'accumulate\\', \\'assisting\\', \\'flexor\\', \\'traversed\\', \\'unusually\\', \\'uppermost\\', \\'cartilage\\', \\'inorganic\\', \\'illuminated\\', \\'glowing\\', \\'contamination\\', \\'trigger\\', \\'masculine\\', \\'defines\\', \\'avoidance\\', \\'residential\\', \\'southeastern\\', \\'penis\\', \\'cracks\\', \\'atlas\\', \\'excitation\\', \\'persia\\', \\'diffuse\\', \\'subdivided\\', \\'alaska\\', \\'guides\\', \\'au\\', \\'sandy\\', \\'penetrating\\', \\'parked\\']\\n-------\\nzinc\\n[\\'ammonium\\', \\'coating\\', \\'pancreas\\', \\'insoluble\\', \"alzheimer\\'s\", \\'diamond\\', \\'radioactive\\', \\'metallic\\', \\'weighing\\', \\'dysfunction\\', \\'wasting\\', \\'phosphorus\\', \\'transcription\\', \\'dipped\\', \\'hydroxide\\', \\'burns\\', \\'leukemia\\', \\'dietary\\']\\n-------\\n'"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part d - run the full analysis and take a look at a few stripes (RUN THIS CELL AS IS)\n",
    "VOCAB = ast.literal_eval(open(\"vocabulary.txt\", \"r\").read())\n",
    "BASIS = ast.literal_eval(open(\"basis.txt\", \"r\").read())\n",
    "stripesRDD = buildStripes(dataRDD, VOCAB, BASIS).cache()\n",
    "\n",
    "start = time.time()\n",
    "for wrd, stripe in stripesRDD.top(3):\n",
    "    print(wrd)\n",
    "    print(list(stripe))\n",
    "    print('-------')\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 214.13801431655884 seconds\n",
    "# Expected results:\n",
    "'''\n",
    "zones\n",
    "['remotest', 'adhesion', 'residential', 'subdivided', 'environments', 'gaza', 'saturation', 'localities', 'uppermost', 'warmer', 'buffer', 'parks']\n",
    "-------\n",
    "zone\n",
    "['tribal', 'narrower', 'fibrous', 'saturation', 'originate', 'auxiliary', 'ie', 'buffer', 'transitional', 'turbulent', 'vomiting', 'americas', 'articular', 'poorly', 'intervening', 'officially', 'accumulate', 'assisting', 'flexor', 'traversed', 'unusually', 'uppermost', 'cartilage', 'inorganic', 'illuminated', 'glowing', 'contamination', 'trigger', 'masculine', 'defines', 'avoidance', 'residential', 'southeastern', 'penis', 'cracks', 'atlas', 'excitation', 'persia', 'diffuse', 'subdivided', 'alaska', 'guides', 'au', 'sandy', 'penetrating', 'parked']\n",
    "-------\n",
    "zinc\n",
    "['ammonium', 'coating', 'pancreas', 'insoluble', \"alzheimer's\", 'diamond', 'radioactive', 'metallic', 'weighing', 'dysfunction', 'wasting', 'phosphorus', 'transcription', 'dipped', 'hydroxide', 'burns', 'leukemia', 'dietary']\n",
    "-------\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4c83537a-cc0c-4629-9aa1-eaefeb9bfa46",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# part d - save your full stripes to file for ease of retrival later... (OPTIONAL)\n",
    "stripesRDD.saveAsTextFile(PWD + '/stripes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9993"
      ]
     },
     "execution_count": 1128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stripesRDD.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "755130f1-1af3-472e-bd74-3435b7e2939f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Question 8: Synonym Detection\n",
    "\n",
    "We're now ready to perform the main synonym detection analysis. In the tasks below you will compute cosine, jaccard, dice and overlap similarity measurements for each pair of words in our vocabulary and then sort your results to find the most similar pairs of words in this dataset. __`IMPORTANT:`__ When you get to the sorting step please __sort on cosine similarity__ only, so that we can ensure consistent results from student to student. \n",
    "\n",
    "Remember to test each step of your work with the small files before running your code on the full dataset. This is a computationally intense task: well designed code can be the difference between a 20min job and a 2hr job. __`NOTE:`__ _as you are designing your code you may want to review questions 3 and 4 where we modeled some of the key pieces of this analysis._\n",
    "\n",
    "### Q8 Tasks:\n",
    "* __a) short response:__ In question 7 you wrote a function that would create word stripes for each `term` in our vocabulary. These word stripes are essentially an 'embedded representation' of the `term`'s meaning. What is the 'feature space' for this representation? (i.e. what are the features of our 1-hot encoded vectors?). What is the maximum length of a stripe?\n",
    "\n",
    "* __b) short response:__ Remember that we are going to treat these stripes as 'documents' and perform similarity analysis on them. The first step is to emit postings which then get collected to form an 'inverted index.' How many rows will there be in our inverted index? Explain.\n",
    "\n",
    "* __c) short response:__ In the demo from question 2, we were able to compute the cosine similarity directly from the stripes (we did this using their vector form, but could have used the list instead). So why do we need the inverted index?\n",
    "\n",
    "* __d) code:__ Write a spark job that does the following:\n",
    "  * loops over the stripes from Q7 and emits postings for the `term` _(key:term, value:posting)_   \n",
    "  * aggregates the postings to create an inverted index _(key:term, value:list of postings)_\n",
    "  * loops over all pairs of `term`s that appear in the same postings list and emits co-occurrence counts\n",
    "  * aggregates co-occurrences _(key:word pair, value:count + other payload)_\n",
    "  * uses the counts (along with the accompanying information) to compute the cosine, jacard, dice and overlap similarity metrics for each pair of words in the vocabulary \n",
    "  * retrieve the top 20 and bottom 20 most/least similar pairs of words\n",
    "  * also return the cached sorted RDD for use in the next question  \n",
    "  __`NOTE 1`:__ _Don't forget to include the stripe length when you are creating the postings & co-occurrence pairs. A composite key is the way to go here._  \n",
    "  __`NOTE 2`:__ _Please make sure that your final results are sorted according to cosine similarity otherwise your results may not match the expected result & you will be marked wrong._\n",
    "  \n",
    "* __e) code:__ Comment on the quality of the \"synonyms\" your analysis comes up with. Do you notice anything odd about these pairs of words? Discuss at least one idea for how you might go about improving on the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c04f1c10-c494-46fa-9c84-7eefb4036894",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Q8 Student Answers:\n",
    "> __a)__ The stripes' feature space consists of the vocab vocabulary keys and the basis vocabulary values.  The maximum length of the stripe is determined by the number of features in the basis vocabulary plus the key term.\n",
    "\n",
    "> __b)__ The number of rows in the inverted index are constrained to the number of terms in the vocab vocabulary.  If the vocab vocabulary contains 10,000 words, then the max number of rows in the inverted index is 10,000.  The inverted index output from Question 7, which used a 10,000 term vocabulary, contains 9,993 rows.  Recall an inverted index is a table of terms paired with postings.  In this case, the terms from the vocab vocabulary are paired with words from the basis vocabulary.\n",
    "\n",
    "> __c)__ Creating an inverted index within the Spark framework allows similarity metrics to be processed efficiently using the stripe method and in parallel across a cluster.  As we looked at previously, the list approach is synonymous with one-hot encoding, the use of an inverted index generated by stripes is a favorable approach. \n",
    "\n",
    "> __e)__ The quality of the synonyms is quite poor considering the top 50 highest similarity rankings are not synonyms.  The word pair closest to being synonyms in the top 50 list is \"first-two\".  One thing I notice is the words from the word pairs seem likely to appear in the same sentence; examples are \"hong - kong\", \"states - united\", and \"new - part\".  My intuition for improving the analysis is as follows: I typically write two synonyms in a sentence that is composed of many words in which the synonyms are not next to one another.  For this reason, I think increasing the number of n-grams/window across words will improve the analysis.  Another tactic to improve the analysis is adding more stop words.  This could lead to the biggest elimination of word pairs that typically appear in the same sentence but are not synonyms.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b56bac93-522f-4c29-8895-3b4844720edb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# helper function for pretty printing (RUN THIS CELL AS IS)\n",
    "def displayOutput(lines):\n",
    "    template = \"{:25}|{:6}, {:7}, {:7}, {:5}\"\n",
    "    print(template.format(\"Pair\", \"Cosine\", \"Jaccard\", \"Overlap\", \"Dice\"))\n",
    "    for pair, scores in lines:\n",
    "        scores = [round(s,4) for s in scores]\n",
    "        print(template.format(pair, *scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "97a29461-b203-49cb-8bc1-16127644446c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__`TIP:`__ Feel free to define helper functions within the main function to help you organize your code. Readability is important! Eg:\n",
    "```\n",
    "def similarityAnlysis(stripesRDD):\n",
    "    \"\"\"main docstring\"\"\"\n",
    "    \n",
    "    simScoresRDD, top_n, bottom_n = None, None, None\n",
    "    \n",
    "    ############ YOUR CODE HERE ###########\n",
    "    def helper1():\n",
    "        \"\"\"helper docstring\"\"\"\n",
    "        return x\n",
    "        \n",
    "    def helper2():\n",
    "        \"\"\"helper docstring\"\"\"\n",
    "        return x\n",
    "        \n",
    "    # main spark job starts here\n",
    "    \n",
    "        ...etc\n",
    "    ############ (END) YOUR CODE ###########\n",
    "    return simScoresRDD, top_n, bottom_n\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c654dc13-824b-4905-920f-d11443f3d074",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# part d - write your spark job in the space provided\n",
    "def similarityAnalysis(stripesRDD, n):\n",
    "    \"\"\"\n",
    "    This function defines a Spark DAG to compute cosine, jaccard, \n",
    "    overlap and dice scores for each pair of words in the stripes\n",
    "    provided. \n",
    "    \n",
    "    Output: an RDD, a list of top n, a list of bottom n\n",
    "    \"\"\"\n",
    "    simScoresRDD, top_n, bottom_n = None, None, None\n",
    "    \n",
    "    ############### YOUR CODE HERE ################\n",
    "   \n",
    "    def splitWords(pair):\n",
    "        \"\"\"Mapper 2: tokenize each document and emit postings.\"\"\"\n",
    "        doc, text = pair\n",
    "        words = text.split(\" \")\n",
    "        for w in words:\n",
    "            yield (w, [(doc,len(words))])\n",
    "            \n",
    "    def makeCompositeKey(inverted_index):\n",
    "        \"\"\"Mapper 3: loop over postings and yield pairs.\"\"\"\n",
    "        word, postings = inverted_index\n",
    "        # taking advantage of symmetry, output only (a,b), but not (b,a)\n",
    "        for subset in itertools.combinations(sorted(postings), 2):\n",
    "            yield (str(subset), 1)\n",
    "            \n",
    "    def similarity(line):\n",
    "        \"\"\"Mapper 4: compute similarity scores\"\"\"\n",
    "        (doc1, n1), (doc2, n2) = ast.literal_eval(line[0])\n",
    "        # a instersect b, set a, set b\n",
    "        total, n1, n2 = int(line[1]), int(n1), int(n2)\n",
    "        \n",
    "        \n",
    "        cosine = total / float(((n1)**0.5) * (n2)**0.5)\n",
    "        \n",
    "        # a intersect b / a union b (a + b - a intersect b)\n",
    "        jaccard = total / float(n1 + n2 - total)\n",
    "        \n",
    "        # 2 * (a intersect b) / (set size a + set size b)\n",
    "        dice = (2 * total) / float(n1 + n2)\n",
    "        \n",
    "        # a intersect b / min size between a and b\n",
    "        overlap = total / float(min(n1, n2))  \n",
    "        \n",
    "        similarities = [cosine, jaccard, overlap, dice]\n",
    "        yield doc1+\" - \"+doc2, similarities\n",
    "    \n",
    "    # spark Job\n",
    "    result = stripesRDD.map(lambda pair: (pair[0], ' '.join(pair[1]))) \\\n",
    "                 .flatMap(splitWords) \\\n",
    "                 .reduceByKey(lambda a,b : a + b) \\\n",
    "                 .flatMap(makeCompositeKey) \\\n",
    "                 .reduceByKey(lambda a,b : a + b) \\\n",
    "                 .flatMap(similarity)\n",
    "    \n",
    "    result = result.sortBy(lambda x: -x[1][0]).cache()\n",
    "\n",
    "    top_n = result.takeOrdered(n, key=lambda x: -x[1][0])\n",
    "    \n",
    "    bottom_n = result.takeOrdered(n, key=lambda x: x[1][0])\n",
    "\n",
    "    ############### (END) YOUR CODE ##############\n",
    "    return result, top_n, bottom_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d0eb2822-463a-462a-b71f-f5f84b340b45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0.6770732402801514 seconds\n"
     ]
    }
   ],
   "source": [
    "# part d - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\n",
    "start = time.time()\n",
    "testResult, top_n, bottom_n= similarityAnalysis(testStripesRDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 1.4768586158752441 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "89790631-03c5-4fad-a582-ae8102ef6f9b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.1683499813079834 seconds\n"
     ]
    }
   ],
   "source": [
    "# part d - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\n",
    "start = time.time()\n",
    "f1Result, top_n, bottom_n = similarityAnalysis(f1StripesRDD, 10)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 1.9845571517944336 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a770823e-2656-4db3-acf3-cdfc5901de42",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38972\n",
      "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
      "commentary - lady        |   1.0,     1.0,     1.0,   1.0\n",
      "commentary - learn       |   1.0,     1.0,     1.0,   1.0\n",
      "commentary - owe         |   1.0,     1.0,     1.0,   1.0\n",
      "commentary - really      |   1.0,     1.0,     1.0,   1.0\n",
      "commentary - tone        |   1.0,     1.0,     1.0,   1.0\n",
      "curious - lady           |   1.0,     1.0,     1.0,   1.0\n",
      "curious - owe            |   1.0,     1.0,     1.0,   1.0\n",
      "curious - reply          |   1.0,     1.0,     1.0,   1.0\n",
      "curious - tone           |   1.0,     1.0,     1.0,   1.0\n",
      "lady - owe               |   1.0,     1.0,     1.0,   1.0\n"
     ]
    }
   ],
   "source": [
    "print(count)\n",
    "displayOutput(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d7c73eab-154b-49db-9e52-83c6c6a8a8ae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
      "part - time              |0.0294,  0.0149,  0.0303, 0.0294\n",
      "time - upon              |0.0314,  0.0159,  0.0345, 0.0312\n",
      "time - two               |0.0314,  0.0159,  0.0345, 0.0312\n",
      "made - time              |0.0325,  0.0164,   0.037, 0.0323\n",
      "first - time             |0.0338,  0.0169,    0.04, 0.0333\n",
      "new - time               |0.0352,  0.0175,  0.0435, 0.0345\n",
      "part - us                |0.0355,  0.0179,  0.0417, 0.0351\n",
      "little - part            |0.0355,  0.0179,  0.0417, 0.0351\n",
      "made - upon              |0.0357,  0.0182,   0.037, 0.0357\n",
      "made - two               |0.0357,  0.0182,   0.037, 0.0357\n"
     ]
    }
   ],
   "source": [
    "displayOutput(bottom_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "98d0be65-e606-44ab-ac0b-2df0cd9dce3b",
     "showTitle": false,
     "title": ""
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/03 19:01:41 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_177 in memory.\n",
      "21/10/03 19:01:41 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_179 in memory.\n",
      "21/10/03 19:01:42 WARN MemoryStore: Not enough space to cache rdd_3182_177 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:42 WARN BlockManager: Block rdd_3182_177 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:42 WARN BlockManager: Putting block rdd_3182_177 failed\n",
      "21/10/03 19:01:42 WARN MemoryStore: Not enough space to cache rdd_3182_179 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:42 WARN BlockManager: Block rdd_3182_179 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:42 WARN BlockManager: Putting block rdd_3182_179 failed\n",
      "21/10/03 19:01:42 WARN MemoryStore: Not enough space to cache rdd_3182_178 in memory! (computed 1126.7 KiB so far)\n",
      "21/10/03 19:01:42 WARN BlockManager: Block rdd_3182_178 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:42 WARN BlockManager: Putting block rdd_3182_178 failed\n",
      "21/10/03 19:01:42 WARN MemoryStore: Not enough space to cache rdd_3182_176 in memory! (computed 2047.7 KiB so far)\n",
      "21/10/03 19:01:42 WARN BlockManager: Block rdd_3182_176 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:42 WARN BlockManager: Putting block rdd_3182_176 failed\n",
      "21/10/03 19:01:43 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_182 in memory.\n",
      "21/10/03 19:01:43 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_183 in memory.\n",
      "21/10/03 19:01:43 WARN MemoryStore: Not enough space to cache rdd_3182_182 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:43 WARN BlockManager: Block rdd_3182_182 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:43 WARN BlockManager: Putting block rdd_3182_182 failed\n",
      "21/10/03 19:01:43 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_184 in memory.\n",
      "21/10/03 19:01:44 WARN MemoryStore: Not enough space to cache rdd_3182_183 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:44 WARN BlockManager: Block rdd_3182_183 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:44 WARN BlockManager: Putting block rdd_3182_183 failed\n",
      "21/10/03 19:01:44 WARN MemoryStore: Not enough space to cache rdd_3182_180 in memory! (computed 2030.8 KiB so far)\n",
      "21/10/03 19:01:44 WARN BlockManager: Block rdd_3182_180 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:44 WARN BlockManager: Putting block rdd_3182_180 failed\n",
      "21/10/03 19:01:44 WARN MemoryStore: Not enough space to cache rdd_3182_181 in memory! (computed 1101.9 KiB so far)\n",
      "21/10/03 19:01:44 WARN BlockManager: Block rdd_3182_181 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:44 WARN BlockManager: Putting block rdd_3182_181 failed\n",
      "21/10/03 19:01:44 WARN MemoryStore: Not enough space to cache rdd_3182_184 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:44 WARN BlockManager: Block rdd_3182_184 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:44 WARN BlockManager: Putting block rdd_3182_184 failed\n",
      "21/10/03 19:01:44 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_187 in memory.\n",
      "21/10/03 19:01:45 WARN MemoryStore: Not enough space to cache rdd_3182_187 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:45 WARN BlockManager: Block rdd_3182_187 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:45 WARN BlockManager: Putting block rdd_3182_187 failed\n",
      "21/10/03 19:01:45 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_188 in memory.\n",
      "21/10/03 19:01:45 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_189 in memory.\n",
      "21/10/03 19:01:46 WARN MemoryStore: Not enough space to cache rdd_3182_188 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:46 WARN BlockManager: Block rdd_3182_188 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:46 WARN BlockManager: Putting block rdd_3182_188 failed\n",
      "21/10/03 19:01:46 WARN MemoryStore: Not enough space to cache rdd_3182_186 in memory! (computed 1118.3 KiB so far)\n",
      "21/10/03 19:01:46 WARN BlockManager: Block rdd_3182_186 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:46 WARN BlockManager: Putting block rdd_3182_186 failed\n",
      "21/10/03 19:01:46 WARN MemoryStore: Not enough space to cache rdd_3182_189 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:46 WARN BlockManager: Block rdd_3182_189 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:46 WARN BlockManager: Putting block rdd_3182_189 failed\n",
      "21/10/03 19:01:58 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_177 in memory.\n",
      "21/10/03 19:01:58 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_178 in memory.\n",
      "21/10/03 19:01:58 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_179 in memory.\n",
      "21/10/03 19:01:59 WARN MemoryStore: Not enough space to cache rdd_3182_179 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:59 WARN BlockManager: Block rdd_3182_179 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:59 WARN BlockManager: Putting block rdd_3182_179 failed\n",
      "21/10/03 19:01:59 WARN MemoryStore: Not enough space to cache rdd_3182_178 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:01:59 WARN BlockManager: Block rdd_3182_178 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:01:59 WARN BlockManager: Putting block rdd_3182_178 failed\n",
      "21/10/03 19:01:59 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_180 in memory.\n",
      "21/10/03 19:02:00 WARN MemoryStore: Not enough space to cache rdd_3182_176 in memory! (computed 1135.4 KiB so far)\n",
      "21/10/03 19:02:00 WARN BlockManager: Block rdd_3182_176 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:00 WARN BlockManager: Putting block rdd_3182_176 failed\n",
      "21/10/03 19:02:00 WARN MemoryStore: Not enough space to cache rdd_3182_177 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:00 WARN BlockManager: Block rdd_3182_177 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:00 WARN BlockManager: Putting block rdd_3182_177 failed\n",
      "21/10/03 19:02:00 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_182 in memory.\n",
      "21/10/03 19:02:00 WARN MemoryStore: Not enough space to cache rdd_3182_182 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:00 WARN BlockManager: Block rdd_3182_182 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:00 WARN BlockManager: Putting block rdd_3182_182 failed\n",
      "21/10/03 19:02:00 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_183 in memory.\n",
      "21/10/03 19:02:01 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_184 in memory.\n",
      "21/10/03 19:02:01 WARN MemoryStore: Not enough space to cache rdd_3182_180 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:01 WARN BlockManager: Block rdd_3182_180 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:01 WARN BlockManager: Putting block rdd_3182_180 failed\n",
      "21/10/03 19:02:01 WARN MemoryStore: Not enough space to cache rdd_3182_181 in memory! (computed 1101.9 KiB so far)\n",
      "21/10/03 19:02:01 WARN BlockManager: Block rdd_3182_181 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:01 WARN BlockManager: Putting block rdd_3182_181 failed\n",
      "21/10/03 19:02:01 WARN MemoryStore: Not enough space to cache rdd_3182_183 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:01 WARN MemoryStore: Not enough space to cache rdd_3182_184 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:02 WARN BlockManager: Block rdd_3182_184 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:02 WARN BlockManager: Putting block rdd_3182_184 failed\n",
      "21/10/03 19:02:02 WARN BlockManager: Block rdd_3182_183 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:02 WARN BlockManager: Putting block rdd_3182_183 failed\n",
      "21/10/03 19:02:02 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_187 in memory.\n",
      "21/10/03 19:02:02 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_188 in memory.\n",
      "21/10/03 19:02:02 WARN MemoryStore: Not enough space to cache rdd_3182_187 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:02 WARN BlockManager: Block rdd_3182_187 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:02 WARN BlockManager: Putting block rdd_3182_187 failed\n",
      "21/10/03 19:02:02 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_189 in memory.\n",
      "21/10/03 19:02:03 WARN MemoryStore: Not enough space to cache rdd_3182_188 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:03 WARN BlockManager: Block rdd_3182_188 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:03 WARN BlockManager: Putting block rdd_3182_188 failed\n",
      "21/10/03 19:02:03 WARN MemoryStore: Not enough space to cache rdd_3182_189 in memory! (computed 0.0 B so far)\n",
      "21/10/03 19:02:03 WARN BlockManager: Block rdd_3182_189 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:03 WARN BlockManager: Putting block rdd_3182_189 failed\n",
      "21/10/03 19:02:03 WARN MemoryStore: Not enough space to cache rdd_3182_186 in memory! (computed 1118.3 KiB so far)\n",
      "21/10/03 19:02:03 WARN BlockManager: Block rdd_3182_186 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 19:02:03 WARN BlockManager: Putting block rdd_3182_186 failed\n",
      "[Stage 1949:===================================================>(189 + 1) / 190]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1413.3118302822113 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# part d - run the system test (RUN THIS CELL AS IS... use display cell below to see results)\n",
    "start = time.time()\n",
    "result, top_n, bottom_n = similarityAnalysis(stripesRDD, 20)\n",
    "print(\"Wall time: {} seconds\".format(time.time() - start))\n",
    "# Wall time: 1851.9786894321442 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1e276d49-96f1-4f6a-8858-00d804989777",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
      "first - time             |  0.89,  0.8012,  0.9149, 0.8897\n",
      "time - well              |0.8895,   0.801,   0.892, 0.8895\n",
      "great - time             | 0.875,  0.7757,   0.925, 0.8737\n",
      "part - well              | 0.874,  0.7755,  0.9018, 0.8735\n",
      "first - well             |0.8717,  0.7722,  0.8936, 0.8715\n",
      "part - time              |0.8715,  0.7715,  0.9018, 0.871\n",
      "time - upon              |0.8668,   0.763,  0.9152, 0.8656\n",
      "made - time              | 0.866,  0.7619,  0.9109, 0.8649\n",
      "made - well              |0.8601,  0.7531,  0.9022, 0.8592\n",
      "time - way               |0.8587,  0.7487,  0.9259, 0.8563\n",
      "great - well             |0.8526,  0.7412,  0.8988, 0.8514\n",
      "time - two               |0.8517,  0.7389,  0.9094, 0.8498\n",
      "first - great            |0.8497,  0.7381,  0.8738, 0.8493\n",
      "first - part             |0.8471,  0.7348,  0.8527, 0.8471\n",
      "great - upon             |0.8464,  0.7338,  0.8475, 0.8464\n",
      "upon - well              |0.8444,   0.729,   0.889, 0.8433\n",
      "new - time               |0.8426,   0.724,  0.9133, 0.8399\n",
      "first - two              |0.8411,  0.7249,  0.8737, 0.8405\n",
      "way - well               |0.8357,  0.7146,  0.8986, 0.8335\n",
      "time - us                |0.8357,  0.7105,  0.9318, 0.8308\n"
     ]
    }
   ],
   "source": [
    "displayOutput(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c0d9efbd-b518-4bda-98a2-5bb5f1117f2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
      "region - write           |0.0067,  0.0032,  0.0085, 0.0065\n",
      "relation - snow          |0.0067,  0.0026,  0.0141, 0.0052\n",
      "cardiac - took           |0.0074,  0.0023,  0.0217, 0.0045\n",
      "ever - tumor             |0.0076,   0.002,  0.0263, 0.004\n",
      "came - tumor             |0.0076,   0.002,  0.0263, 0.004\n",
      "let - therapy            |0.0076,   0.003,  0.0161, 0.0059\n",
      "related - stay           |0.0078,  0.0036,  0.0116, 0.0072\n",
      "factors - hear           |0.0078,  0.0039,  0.0094, 0.0077\n",
      "implications - round     |0.0078,  0.0033,  0.0145, 0.0066\n",
      "came - proteins          |0.0079,   0.002,  0.0286, 0.0041\n",
      "population - window      |0.0079,  0.0039,    0.01, 0.0077\n",
      "love - proportional      | 0.008,  0.0029,  0.0185, 0.0058\n",
      "got - multiple           | 0.008,  0.0034,  0.0149, 0.0067\n",
      "changes - fort           |0.0081,  0.0032,  0.0161, 0.0065\n",
      "layer - wife             |0.0081,  0.0038,  0.0119, 0.0075\n",
      "five - sympathy          |0.0081,  0.0034,  0.0149, 0.0068\n",
      "arrival - essential      |0.0081,   0.004,  0.0093, 0.008\n",
      "desert - function        |0.0081,  0.0031,  0.0175, 0.0062\n",
      "fundamental - stood      |0.0081,  0.0038,  0.0115, 0.0077\n",
      "patients - plain         |0.0081,   0.004,  0.0103, 0.0079\n"
     ]
    }
   ],
   "source": [
    "displayOutput(bottom_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "09c78c64-6d5e-4ae0-b098-b7ac7d02830a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "__Expected output f1RDD:__  \n",
    "<table>\n",
    "<th>MOST SIMILAR:</th>\n",
    "<th>LEAST SIMILAR:</th>\n",
    "<tr><td><pre>\n",
    "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
    "commentary - lady        |   1.0,     1.0,     1.0,   1.0\n",
    "commentary - toes        |   1.0,     1.0,     1.0,   1.0\n",
    "commentary - reply       |   1.0,     1.0,     1.0,   1.0\n",
    "curious - tone           |   1.0,     1.0,     1.0,   1.0\n",
    "curious - lady           |   1.0,     1.0,     1.0,   1.0\n",
    "curious - owe            |   1.0,     1.0,     1.0,   1.0\n",
    "lady - tone              |   1.0,     1.0,     1.0,   1.0\n",
    "reply - tone             |   1.0,     1.0,     1.0,   1.0\n",
    "lady - toes              |   1.0,     1.0,     1.0,   1.0\n",
    "lady - reply             |   1.0,     1.0,     1.0,   1.0\n",
    "</pre></td>\n",
    "<td><pre>\n",
    "\n",
    "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
    "part - time              |0.0294,  0.0149,  0.0303, 0.0294\n",
    "time - upon              |0.0314,  0.0159,  0.0345, 0.0312\n",
    "time - two               |0.0314,  0.0159,  0.0345, 0.0312\n",
    "made - time              |0.0325,  0.0164,   0.037, 0.0323\n",
    "first - time             |0.0338,  0.0169,    0.04, 0.0333\n",
    "new - time               |0.0352,  0.0175,  0.0435, 0.0345\n",
    "part - us                |0.0355,  0.0179,  0.0417, 0.0351\n",
    "little - part            |0.0355,  0.0179,  0.0417, 0.0351\n",
    "made - two               |0.0357,  0.0182,   0.037, 0.0357\n",
    "made - upon              |0.0357,  0.0182,   0.037, 0.0357\n",
    "</pre></td></tr>\n",
    "</table>\n",
    "\n",
    "__Expected output dataRDD:__  \n",
    "<table>\n",
    "<th>Most Similar</th>\n",
    "<th>Least Similar</th>\n",
    "<tr><td><pre>\n",
    "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
    "first - time             |  0.89,  0.8012,  0.9149, 0.8897\n",
    "time - well              |0.8895,   0.801,   0.892, 0.8895\n",
    "great - time             | 0.875,  0.7757,   0.925, 0.8737\n",
    "part - well              | 0.874,  0.7755,  0.9018, 0.8735\n",
    "first - well             |0.8717,  0.7722,  0.8936, 0.8715\n",
    "part - time              |0.8715,  0.7715,  0.9018, 0.871\n",
    "time - upon              |0.8668,   0.763,  0.9152, 0.8656\n",
    "made - time              | 0.866,  0.7619,  0.9109, 0.8649\n",
    "made - well              |0.8601,  0.7531,  0.9022, 0.8592\n",
    "time - way               |0.8587,  0.7487,  0.9259, 0.8563\n",
    "great - well             |0.8526,  0.7412,  0.8988, 0.8514\n",
    "time - two               |0.8517,  0.7389,  0.9094, 0.8498\n",
    "first - great            |0.8497,  0.7381,  0.8738, 0.8493\n",
    "first - part             |0.8471,  0.7348,  0.8527, 0.8471\n",
    "great - upon             |0.8464,  0.7338,  0.8475, 0.8464\n",
    "upon - well              |0.8444,   0.729,   0.889, 0.8433\n",
    "new - time               |0.8426,   0.724,  0.9133, 0.8399\n",
    "first - two              |0.8411,  0.7249,  0.8737, 0.8405\n",
    "way - well               |0.8357,  0.7146,  0.8986, 0.8335\n",
    "time - us                |0.8357,  0.7105,  0.9318, 0.8308\n",
    "\n",
    "</pre></td>\n",
    "<td><pre>\n",
    "Pair                     |Cosine, Jaccard, Overlap, Dice \n",
    "region - write           |0.0067,  0.0032,  0.0085, 0.0065\n",
    "relation - snow          |0.0067,  0.0026,  0.0141, 0.0052\n",
    "cardiac - took           |0.0074,  0.0023,  0.0217, 0.0045\n",
    "ever - tumor             |0.0076,   0.002,  0.0263, 0.004\n",
    "came - tumor             |0.0076,   0.002,  0.0263, 0.004\n",
    "let - therapy            |0.0076,   0.003,  0.0161, 0.0059\n",
    "related - stay           |0.0078,  0.0036,  0.0116, 0.0072\n",
    "factors - hear           |0.0078,  0.0039,  0.0094, 0.0077\n",
    "implications - round     |0.0078,  0.0033,  0.0145, 0.0066\n",
    "came - proteins          |0.0079,   0.002,  0.0286, 0.0041\n",
    "population - window      |0.0079,  0.0039,    0.01, 0.0077\n",
    "love - proportional      | 0.008,  0.0029,  0.0185, 0.0058\n",
    "got - multiple           | 0.008,  0.0034,  0.0149, 0.0067\n",
    "changes - fort           |0.0081,  0.0032,  0.0161, 0.0065\n",
    "layer - wife             |0.0081,  0.0038,  0.0119, 0.0075\n",
    "five - sympathy          |0.0081,  0.0034,  0.0149, 0.0068\n",
    "arrival - essential      |0.0081,   0.004,  0.0093, 0.008\n",
    "desert - function        |0.0081,  0.0031,  0.0175, 0.0062\n",
    "fundamental - stood      |0.0081,  0.0038,  0.0115, 0.0077\n",
    "patients - plain         |0.0081,   0.004,  0.0103, 0.0079\n",
    "</pre></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "63c40693-e756-4efd-985a-7db35c58af83",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Congratulations, you have completed HW3! Please refer to the readme for submission instructions.\n",
    "\n",
    "If you would like to provide feedback regarding this homework, please use the survey at: https://docs.google.com/forms/d/e/1FAIpQLSce9feiQeSkdP43A0ZYui1tMGIBfLfzb0rmgToQeZD9bXXX8Q/viewform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/03 23:30:57 WARN MemoryStore: Not enough space to cache rdd_3182_4 in memory! (computed 3.9 MiB so far)\n",
      "21/10/03 23:30:57 WARN BlockManager: Block rdd_3182_4 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:30:57 WARN BlockManager: Putting block rdd_3182_4 failed\n",
      "21/10/03 23:31:06 WARN MemoryStore: Not enough space to cache rdd_3182_1 in memory! (computed 1819.5 KiB so far)\n",
      "21/10/03 23:31:06 WARN BlockManager: Block rdd_3182_1 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:31:06 WARN BlockManager: Putting block rdd_3182_1 failed\n",
      "21/10/03 23:31:07 WARN MemoryStore: Not enough space to cache rdd_3182_177 in memory! (computed 1100.1 KiB so far)\n",
      "21/10/03 23:31:07 WARN BlockManager: Block rdd_3182_177 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:31:07 WARN BlockManager: Putting block rdd_3182_177 failed\n",
      "21/10/03 23:31:07 WARN MemoryStore: Not enough space to cache rdd_3182_3 in memory! (computed 2.4 MiB so far)\n",
      "21/10/03 23:31:07 WARN BlockManager: Block rdd_3182_3 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:31:07 WARN BlockManager: Putting block rdd_3182_3 failed\n",
      "21/10/03 23:31:07 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_187 in memory.\n",
      "21/10/03 23:31:08 WARN MemoryStore: Not enough space to cache rdd_3182_187 in memory! (computed 0.0 B so far)\n",
      "21/10/03 23:31:08 WARN BlockManager: Block rdd_3182_187 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:31:08 WARN BlockManager: Putting block rdd_3182_187 failed\n",
      "21/10/03 23:31:08 WARN MemoryStore: Not enough space to cache rdd_3182_180 in memory! (computed 1117.9 KiB so far)\n",
      "21/10/03 23:31:08 WARN BlockManager: Block rdd_3182_180 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:31:08 WARN BlockManager: Putting block rdd_3182_180 failed\n",
      "21/10/03 23:31:08 WARN MemoryStore: Not enough space to cache rdd_3182_183 in memory! (computed 1095.5 KiB so far)\n",
      "21/10/03 23:31:08 WARN BlockManager: Block rdd_3182_183 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:31:08 WARN BlockManager: Putting block rdd_3182_183 failed\n",
      "21/10/03 23:31:09 WARN MemoryStore: Not enough space to cache rdd_3182_186 in memory! (computed 1118.3 KiB so far)\n",
      "21/10/03 23:31:09 WARN BlockManager: Block rdd_3182_186 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:31:09 WARN BlockManager: Putting block rdd_3182_186 failed\n",
      "[Stage 2196:===================================================>(189 + 1) / 190]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of pairs from the corpus is: 28757658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pairsCount = result.count()\n",
    "print(\"The number of pairs from the corpus is:\", pairsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/10/03 23:38:22 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_3 in memory.\n",
      "21/10/03 23:38:22 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_4 in memory.\n",
      "21/10/03 23:38:22 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_177 in memory.\n",
      "21/10/03 23:38:23 WARN MemoryStore: Not enough space to cache rdd_3182_177 in memory! (computed 0.0 B so far)\n",
      "21/10/03 23:38:23 WARN MemoryStore: Not enough space to cache rdd_3182_3 in memory! (computed 0.0 B so far)\n",
      "21/10/03 23:38:23 WARN BlockManager: Block rdd_3182_3 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:23 WARN BlockManager: Putting block rdd_3182_3 failed\n",
      "21/10/03 23:38:23 WARN BlockManager: Block rdd_3182_177 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:23 WARN BlockManager: Putting block rdd_3182_177 failed\n",
      "21/10/03 23:38:23 WARN MemoryStore: Not enough space to cache rdd_3182_4 in memory! (computed 0.0 B so far)\n",
      "21/10/03 23:38:23 WARN BlockManager: Block rdd_3182_4 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:23 WARN BlockManager: Putting block rdd_3182_4 failed\n",
      "21/10/03 23:38:24 WARN MemoryStore: Not enough space to cache rdd_3182_1 in memory! (computed 1819.5 KiB so far)\n",
      "21/10/03 23:38:24 WARN BlockManager: Block rdd_3182_1 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:24 WARN BlockManager: Putting block rdd_3182_1 failed\n",
      "21/10/03 23:38:24 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_183 in memory.\n",
      "21/10/03 23:38:24 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_186 in memory.\n",
      "21/10/03 23:38:24 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_3182_187 in memory.\n",
      "21/10/03 23:38:25 WARN MemoryStore: Not enough space to cache rdd_3182_183 in memory! (computed 0.0 B so far)\n",
      "21/10/03 23:38:25 WARN BlockManager: Block rdd_3182_183 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:25 WARN BlockManager: Putting block rdd_3182_183 failed\n",
      "21/10/03 23:38:25 WARN MemoryStore: Not enough space to cache rdd_3182_187 in memory! (computed 0.0 B so far)\n",
      "21/10/03 23:38:25 WARN BlockManager: Block rdd_3182_187 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:25 WARN BlockManager: Putting block rdd_3182_187 failed\n",
      "21/10/03 23:38:25 WARN MemoryStore: Not enough space to cache rdd_3182_186 in memory! (computed 0.0 B so far)\n",
      "21/10/03 23:38:25 WARN BlockManager: Block rdd_3182_186 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:25 WARN BlockManager: Putting block rdd_3182_186 failed\n",
      "21/10/03 23:38:25 WARN MemoryStore: Not enough space to cache rdd_3182_180 in memory! (computed 1117.9 KiB so far)\n",
      "21/10/03 23:38:25 WARN BlockManager: Block rdd_3182_180 could not be removed as it was not found on disk or in memory\n",
      "21/10/03 23:38:25 WARN BlockManager: Putting block rdd_3182_180 failed\n",
      "                                                                                \r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'top'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_181/1145240445.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtop_50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtakeOrdered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop_50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'top'"
     ]
    }
   ],
   "source": [
    "top_50 = result.takeOrdered(50, key=lambda x: -x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('first - time', [0.8899938790067196, 0.8012422360248447, 0.9148936170212766, 0.8896551724137931])\n",
      "('time - well', [0.889515555860911, 0.8010101010101011, 0.8920134983127109, 0.8895120583286595])\n",
      "('great - time', [0.8750199742047439, 0.7756813417190775, 0.925, 0.8736717827626919])\n",
      "('part - well', [0.8739787191842415, 0.7754891864057673, 0.9017964071856287, 0.8735498839907193])\n",
      "('first - well', [0.8717375096954464, 0.7722165474974464, 0.8936170212765957, 0.8714697406340057])\n",
      "('part - time', [0.8715312802735642, 0.7715163934426229, 0.9017964071856287, 0.8710237131289763])\n",
      "('time - upon', [0.8668423411061288, 0.762993762993763, 0.9152119700748129, 0.8655660377358491])\n",
      "('made - time', [0.8659710520967363, 0.7619047619047619, 0.9108910891089109, 0.8648648648648649])\n",
      "('made - well', [0.8601436102534457, 0.753099173553719, 0.9022277227722773, 0.8591632292280496])\n",
      "('time - way', [0.8587130526621549, 0.7486855941114616, 0.9258777633289987, 0.8562838244137102])\n",
      "('great - well', [0.8525758297986199, 0.7412371134020619, 0.89875, 0.8513913558318532])\n",
      "('time - two', [0.8516531147689896, 0.738860103626943, 0.9094387755102041, 0.8498212157330155])\n",
      "('first - great', [0.8496635754752357, 0.7381203801478353, 0.87375, 0.8493317132442284])\n",
      "('first - part', [0.8471329500591671, 0.7347781217750258, 0.8526946107784431, 0.8471148126115408])\n",
      "('great - upon', [0.8464426071989732, 0.7337662337662337, 0.8475, 0.846441947565543])\n",
      "('upon - well', [0.8444063007100567, 0.7290388548057259, 0.8890274314214464, 0.8432879952690716])\n",
      "('new - time', [0.8426043886803956, 0.7239583333333334, 0.9132720105124835, 0.8398791540785498])\n",
      "('first - two', [0.8410994686753256, 0.7248677248677249, 0.8737244897959183, 0.8404907975460123])\n",
      "('way - well', [0.8357261605209715, 0.7145811789038262, 0.8985695708712613, 0.8335343787696019])\n",
      "('time - us', [0.8356830587881752, 0.7104984093319194, 0.9318497913769124, 0.8307501549907006])\n",
      "('two - well', [0.8348796325377852, 0.7141393442622951, 0.889030612244898, 0.8332337118947998])\n",
      "('first - made', [0.8345612749178964, 0.7157676348547718, 0.8539603960396039, 0.8343409915356711])\n",
      "('great - part', [0.8344419771162359, 0.7156348373557188, 0.8525, 0.8342507645259939])\n",
      "('first - upon', [0.8340351831233119, 0.7148803329864725, 0.8566084788029925, 0.8337378640776699])\n",
      "('new - well', [0.8340285296776385, 0.7116182572614108, 0.9014454664914586, 0.8315151515151515])\n",
      "('also - time', [0.8334531292676132, 0.7104446742502585, 0.9039473684210526, 0.8307134220072552])\n",
      "('made - upon', [0.8323039163313574, 0.7127659574468085, 0.8354114713216958, 0.8322981366459627])\n",
      "('also - well', [0.8321438830333017, 0.7088082901554404, 0.9, 0.8295936931473621])\n",
      "('made - part', [0.8315182501568241, 0.7114583333333333, 0.8452970297029703, 0.8314059646987219])\n",
      "('first - new', [0.8312818991605966, 0.7095744680851064, 0.8764783180026281, 0.8301182327317984])\n",
      "('great - made', [0.8296122573375785, 0.7088204038257173, 0.83375, 0.8296019900497512])\n",
      "('hong - kong', [0.8275159265510557, 0.7, 0.9130434782608695, 0.8235294117647058])\n",
      "('many - well', [0.8260965966014737, 0.6969376979936642, 0.9192200557103064, 0.8214063472308649])\n",
      "('part - upon', [0.8260689037839015, 0.7034339229968782, 0.8428927680798005, 0.8259010384850336])\n",
      "('great - new', [0.8253697455201358, 0.7022900763358778, 0.8462549277266754, 0.8251121076233184])\n",
      "('part - way', [0.8248881254758217, 0.7009544008483564, 0.8595578673602081, 0.8241895261845387])\n",
      "('first - way', [0.8232272313983153, 0.6982124079915878, 0.8634590377113134, 0.8222910216718267])\n",
      "('great - us', [0.8174896272623292, 0.6896551724137931, 0.8623087621696801, 0.8163265306122449])\n",
      "('states - united', [0.8172555056551057, 0.6895368782161235, 0.8589743589743589, 0.8162436548223351])\n",
      "('first - us', [0.8167512458791478, 0.6864224137931034, 0.885952712100139, 0.8140575079872204])\n",
      "('many - time', [0.816294305405888, 0.6826722338204593, 0.9108635097493036, 0.8114143920595533])\n",
      "('made - way', [0.8144532821221113, 0.6866310160427808, 0.834850455136541, 0.8142041851616995])\n",
      "('great - way', [0.8134156339154353, 0.6852846401718582, 0.8296488946684005, 0.8132568514977693])\n",
      "('part - two', [0.8120150909202334, 0.682952182952183, 0.8380102040816326, 0.8116121062384187])\n",
      "('also - first', [0.8118747055512925, 0.6816753926701571, 0.8565789473684211, 0.8107098381070984])\n",
      "('new - part', [0.8116498533916031, 0.6817702845100105, 0.8501971090670171, 0.8107769423558897])\n",
      "('order - time', [0.8115401066760078, 0.6730158730158731, 0.925764192139738, 0.8045540796963947])\n",
      "('time - without', [0.8109131701957265, 0.6705756929637526, 0.9346210995542348, 0.8028079132099554])\n",
      "('upon - way', [0.8098540559849684, 0.6802139037433155, 0.8270481144343304, 0.8096753660089115])\n",
      "('first - many', [0.8096213564471805, 0.6763129689174705, 0.8788300835654597, 0.8069053708439897])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top_50)):\n",
    "    print(top_50[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "top_50f1 = f1Result.takeOrdered(100, key=lambda x: -x[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('commentary - lady', [1.0, 1.0, 1.0, 1.0])\n",
      "('commentary - learn', [1.0, 1.0, 1.0, 1.0])\n",
      "('commentary - owe', [1.0, 1.0, 1.0, 1.0])\n",
      "('commentary - really', [1.0, 1.0, 1.0, 1.0])\n",
      "('commentary - tone', [1.0, 1.0, 1.0, 1.0])\n",
      "('curious - lady', [1.0, 1.0, 1.0, 1.0])\n",
      "('curious - owe', [1.0, 1.0, 1.0, 1.0])\n",
      "('curious - reply', [1.0, 1.0, 1.0, 1.0])\n",
      "('curious - tone', [1.0, 1.0, 1.0, 1.0])\n",
      "('lady - owe', [1.0, 1.0, 1.0, 1.0])\n",
      "('lady - toes', [1.0, 1.0, 1.0, 1.0])\n",
      "('lady - tone', [1.0, 1.0, 1.0, 1.0])\n",
      "('learn - really', [1.0, 1.0, 1.0, 1.0])\n",
      "('learn - reply', [1.0, 1.0, 1.0, 1.0])\n",
      "('learn - toes', [1.0, 1.0, 1.0, 1.0])\n",
      "('learn - tone', [1.0, 1.0, 1.0, 1.0])\n",
      "('owe - really', [1.0, 1.0, 1.0, 1.0])\n",
      "('owe - reply', [1.0, 1.0, 1.0, 1.0])\n",
      "('really - reply', [1.0, 1.0, 1.0, 1.0])\n",
      "('really - tone', [1.0, 1.0, 1.0, 1.0])\n",
      "('employment - partly', [1.0, 1.0, 1.0, 1.0])\n",
      "('employment - relatively', [1.0, 1.0, 1.0, 1.0])\n",
      "('employment - skilled', [1.0, 1.0, 1.0, 1.0])\n",
      "('occupations - ordinary', [1.0, 1.0, 1.0, 1.0])\n",
      "('occupations - partly', [1.0, 1.0, 1.0, 1.0])\n",
      "('occupations - skilled', [1.0, 1.0, 1.0, 1.0])\n",
      "('occupations - unemployment', [1.0, 1.0, 1.0, 1.0])\n",
      "('ordinary - partly', [1.0, 1.0, 1.0, 1.0])\n",
      "('ordinary - relatively', [1.0, 1.0, 1.0, 1.0])\n",
      "('ordinary - unemployment', [1.0, 1.0, 1.0, 1.0])\n",
      "('ordinary - v', [1.0, 1.0, 1.0, 1.0])\n",
      "('partly - relatively', [1.0, 1.0, 1.0, 1.0])\n",
      "('partly - skilled', [1.0, 1.0, 1.0, 1.0])\n",
      "('partly - v', [1.0, 1.0, 1.0, 1.0])\n",
      "('relatively - unemployment', [1.0, 1.0, 1.0, 1.0])\n",
      "('relatively - v', [1.0, 1.0, 1.0, 1.0])\n",
      "('unemployment - v', [1.0, 1.0, 1.0, 1.0])\n",
      "('marrow - needle', [1.0, 1.0, 1.0, 1.0])\n",
      "('patriotic - reward', [1.0, 1.0, 1.0, 1.0])\n",
      "('patriotic - splendour', [1.0, 1.0, 1.0, 1.0])\n",
      "('reward - splendour', [1.0, 1.0, 1.0, 1.0])\n",
      "('curiosity - settled', [1.0, 1.0, 1.0, 1.0])\n",
      "('seated - settled', [1.0, 1.0, 1.0, 1.0])\n",
      "('resort - securing', [1.0, 1.0, 1.0, 1.0])\n",
      "('resort - thousands', [1.0, 1.0, 1.0, 1.0])\n",
      "('scheme - securing', [1.0, 1.0, 1.0, 1.0])\n",
      "('scheme - thousands', [1.0, 1.0, 1.0, 1.0])\n",
      "('consciousness - overcome', [1.0, 1.0, 1.0, 1.0])\n",
      "('legality - overcome', [1.0, 1.0, 1.0, 1.0])\n",
      "('legality - persist', [1.0, 1.0, 1.0, 1.0])\n",
      "('overcome - veracity', [1.0, 1.0, 1.0, 1.0])\n",
      "('persist - veracity', [1.0, 1.0, 1.0, 1.0])\n",
      "('barn - file', [1.0, 1.0, 1.0, 1.0])\n",
      "('barn - protocol', [1.0, 1.0, 1.0, 1.0])\n",
      "('farewell - papers', [1.0, 1.0, 1.0, 1.0])\n",
      "('papers - protocol', [1.0, 1.0, 1.0, 1.0])\n",
      "('papers - removed', [1.0, 1.0, 1.0, 1.0])\n",
      "('protocol - removed', [1.0, 1.0, 1.0, 1.0])\n",
      "('harbor - sells', [1.0, 1.0, 1.0, 1.0])\n",
      "('harbor - wealth', [1.0, 1.0, 1.0, 1.0])\n",
      "('sells - wealth', [1.0, 1.0, 1.0, 1.0])\n",
      "('remained - storms', [1.0, 1.0, 1.0, 1.0])\n",
      "('dictated - suggests', [1.0, 1.0, 1.0, 1.0])\n",
      "('interested - suggests', [1.0, 1.0, 1.0, 1.0])\n",
      "('catholic - neighboring', [1.0, 1.0, 1.0, 1.0])\n",
      "('consistent - observations', [1.0, 1.0, 1.0, 1.0])\n",
      "('contrast - observations', [1.0, 1.0, 1.0, 1.0])\n",
      "('alone - mercy', [1.0, 1.0, 1.0, 1.0])\n",
      "('mercy - wounds', [1.0, 1.0, 1.0, 1.0])\n",
      "('quickly - wounds', [1.0, 1.0, 1.0, 1.0])\n",
      "('intensity - realization', [1.0, 1.0, 1.0, 1.0])\n",
      "('explain - usage', [1.0, 1.0, 1.0, 1.0])\n",
      "('groups - support', [1.0, 1.0, 1.0, 1.0])\n",
      "('judge - outward', [1.0, 1.0, 1.0, 1.0])\n",
      "('forces - incidence', [1.0, 1.0, 1.0, 1.0])\n",
      "('marketing - societies', [1.0, 1.0, 1.0, 1.0])\n",
      "('program - societies', [1.0, 1.0, 1.0, 1.0])\n",
      "('friendship - intimate', [1.0, 1.0, 1.0, 1.0])\n",
      "('friendship - lifted', [1.0, 1.0, 1.0, 1.0])\n",
      "('friendship - wrote', [1.0, 1.0, 1.0, 1.0])\n",
      "('graduate - intimate', [1.0, 1.0, 1.0, 1.0])\n",
      "('graduate - organized', [1.0, 1.0, 1.0, 1.0])\n",
      "('intimate - organized', [1.0, 1.0, 1.0, 1.0])\n",
      "('lifted - organized', [1.0, 1.0, 1.0, 1.0])\n",
      "('federation - player', [1.0, 1.0, 1.0, 1.0])\n",
      "('federation - playing', [1.0, 1.0, 1.0, 1.0])\n",
      "('player - playing', [1.0, 1.0, 1.0, 1.0])\n",
      "('player - team', [1.0, 1.0, 1.0, 1.0])\n",
      "('playing - team', [1.0, 1.0, 1.0, 1.0])\n",
      "('histories - studying', [1.0, 1.0, 1.0, 1.0])\n",
      "('centuries - methods', [1.0, 1.0, 1.0, 1.0])\n",
      "('excessive - sign', [1.0, 1.0, 1.0, 1.0])\n",
      "('excessive - viii', [1.0, 1.0, 1.0, 1.0])\n",
      "('sign - viii', [1.0, 1.0, 1.0, 1.0])\n",
      "('acute - infectious', [1.0, 1.0, 1.0, 1.0])\n",
      "('gesture - simpler', [1.0, 1.0, 1.0, 1.0])\n",
      "('simple - simpler', [1.0, 1.0, 1.0, 1.0])\n",
      "('ample - luck', [1.0, 1.0, 1.0, 1.0])\n",
      "('ample - stoop', [1.0, 1.0, 1.0, 1.0])\n",
      "('covering - makes', [1.0, 1.0, 1.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(top_50f1)):\n",
    "    print(top_50f1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "hw3_Workbook_revF20",
   "notebookOrigID": 2162291293013809,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
